<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[restful 设计总结]]></title>
    <url>%2F2017%2F11%2F20%2Frestful-%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Restful浅析在做restful接口设计的时候发现自己所知甚少，在网络上找到一篇文章发现写的不错，希望自己可以设计出来一组完美的接口。转载一下原文地址：http://blog.csdn.net/andycooler/article/details/49951533 概述 做出一个好的API设计很难。API表达的是你的数据和你的数据使用者之间的契约。打破这个契约将会招致很多愤怒的邮件，和一大堆伤心的用户-因为他们手机上的App不工作了。而文档化只能达到一半的效果，并且也很难找到一个愿意写文档的程序员。 你所能做的最重要一件事来提高服务的价值就是创建一个API。因为随着其他服务的成长，有这样一个API会使你的服务或者核心应用将有机会变成一个平台。环顾一下现有的这些大公司：Facebook，Twitter，Google，Github，Amazon，Netflix等。如果当时他们没有通过API来开放数据的话，也不可能成长到如今的规模。事实上，整个行业存在的唯一目的就是消费所谓平台上的数据。 你的API越容易使用，那么就会有越多的人去用它 本文提到的这些原则，如果你的API能严格按照这些原则来设计，使用者就可以知道它接下来要做什么，并且能减少大量不必要的疑惑或者是愤怒的邮件。我已经把所有内容都整理到不同的主题里了，你无需按顺序去阅读它。 定义这里有一些非常重要的术语，我将在本文里面一直用到它们： 资源：一个对象的单独实例，如一只动物 集合：一群同种对象，如动物 HTTP：跨网络的通信协议 客户端：可以创建HTTP请求的客户端应用程序 第三方开发者：这个开发者不属于你的项目但是有想使用你的数据 服务器：一个HTTP服务器或者应用程序，客户端可以跨网络访问它 端点：这个API在服务器上的URL用于表达一个资源或者一个集合 幂等：无边际效应，多次操作得到相同的结果 URL段：在URL里面已斜杠分隔的内容 数据设计与抽象规划好你的API的外观要先于开发它实际的功能。首先你要知道数据该如何设计和核心服务/应用程序会如何工作。如果你纯粹新开发一个API，这样会比较容易一些。但如果你是往已有的项目中增加API，你可能需要提供更多的抽象。 有时候一个集合可以表达一个数据库表，而一个资源可以表达成里面的一行记录，但是这并不是常态。事实上，你的API应该尽可能通过抽象来分离数据与业务逻辑。这点非常重要，只有这样做你才不会打击到那些拥有复杂业务的第三方开发者，否则他们是不会使用你的API的。 当然你的服务可能很多部分是不应该通过API暴露出去的。比较常见的例子就是很多API是不允许第三方来创建用户的。 动词显然你了解GET和POST请求。当你用浏览器去访问不同页面的时候，这两个是最常见的请求。POST术语如此流行以至于开始侵扰通俗用语。即使是那些不知道互联网如何工作的人们也能“post”一些东西到朋友的Facebook墙上。 这里至少有四个半非常重要的HTTP动词需要你知道。我之所以说“半个”的意思是PATCH这个动词非常类似于PUT，并且它们俩也常常被开发者绑定到同一个API上。 GET (选择)：从服务器上获取一个具体的资源或者一个资源列表。 POST （创建）： 在服务器上创建一个新的资源。 PUT （更新）：以整体的方式更新服务器上的一个资源。 PATCH （更新）：只更新服务器上一个资源的一个属性。 DELETE （删除）：删除服务器上的一个资源。 还有两个不常用的HTTP动词： HEAD ： 获取一个资源的元数据，如数据的哈希值或最后的更新时间。 OPTIONS：获取客户端能对资源做什么操作的信息。 一个好的RESTful API只允许第三方调用者使用这四个半HTTP动词进行数据交互，并且在URL段里面不出现任何其他的动词。 一般来说，GET请求可以被浏览器缓存（通常也是这样的）。例如，缓存请求头用于第二次用户的POST请求。HEAD请求是基于一个无响应体的GET请求，并且也可以被缓存的。 版本化无论你正在构建什么，无论你在入手前做了多少计划，你核心的应用总会发生变化，数据关系也会变化，资源上的属性也会被增加或删除。只要你的项目还活着，并且有大量的用户在用，这种情况总是会发生。 请谨记一点，API是服务器与客户端之间的一个公共契约。如果你对服务器上的API做了一个更改，并且这些更改无法向后兼容，那么你就打破了这个契约，客户端又会要求你重新支持它。为了避免这样的事情，你既要确保应用程序逐步的演变，又要让客户端满意。那么你必须在引入新版本API的同时保持旧版本API仍然可用。 注：如果你只是简单的增加一个新的特性到API上，如资源上的一个新属性或者增加一个新的端点，你不需要增加API的版本。因为这些并不会造成向后兼容性的问题，你只需要修改文档即可。 随着时间的推移，你可能声明不再支持某些旧版本的API。申明不支持一个特性并不意味着关闭或者破坏它。而是告诉客户端旧版本的API将在某个特定的时间被删除，并且建议他们使用新版本的API。 一个好的RESTful API会在URL中包含版本信息。另一种比较常见的方案是在请求头里面保持版本信息。但是跟很多不同的第三方开发者一起工作后，我可以很明确的告诉你，在请求头里面包含版本信息远没有放在URL里面来的容易。 分析所谓API分析就是持续跟踪那些正为人使用的API的版本和端点信息。而这可能就跟每次请求都往数据库增加一个整数那样简单。有很多的原因显示API跟踪分析是一个好主意，例如，对那些使用最广泛的API来说效率是最重要的。 第三方开发者通常会关注API的构建目的，其中最重要的一个目的是你决定什么时候不再支持某个版本。你需要明确的告知开发者他们正在使用那些即将被移除的API特性。这是一个很好的方式在你准备删除旧的API之前去提醒他们进行升级。 当然第三方开发者的通知流程可以以某种条件被自动触发，例如每当一个过时的特性上发生10000次请求时就发邮件通知开发者。 API根URL无论你信不信，API的根地址很重要。当一个开发者接手了一个旧项目（如进行代码考古时）。而这个项目正在使用你的API，同时开发者还想构建一个新的特性，但他们完全不知道你的服务。幸运的是他们知道客户端对外调用的那些URL列表。让你的API根入口点保持尽可能的简单是很重要的，因为开发者很可能一看到那些冗长而又复杂的URL就转身而走。 这里有两个常见的URL根例子： 12https://example.org/api/v1/* (适合使用相同架构支持站点和API的小型应用)https://api.example.com/v1/* (适合比较庞大的API应用) 如果你的应用很庞大或者你预期它将会变的很庞大，那么将API放到子域下通常是一个好选择。这种做法可以保持某些规模化上的灵活性。 但如果你觉得你的API不会变的很庞大，或是你只是想让应用安装更简单些（如你想用相同的框架来支持站点和API），将你的API放到根域名下也是可以的。 让API根拥有一些内容通常也是个好主意。Github的API根就是一个典型的例子。从个人角度来说我是一个通过根URL发布信息的粉丝，这对很多人来说是有用的，例如如何获取API相关的开发文档。 同样也请注意HTTPS前缀，一个好的RESTful API总是基于HTTPS来发布的。 端点一个端点就是指向特定资源或资源集合的URL。 如果你正在构建一个虚构的API来展现几个不同的动物园，每一个动物园又包含很多动物，员工和每个动物的物种，你可能会有如下的端点信息： 1234https://api.example.com/v1/zooshttps://api.example.com/v1/animalshttps://api.example.com/v1/animal_typeshttps://api.example.com/v1/employees 针对每一个端点来说，你可能想列出所有可行的HTTP动词和端点的组合。如下所示，请注意我把HTTP动词都放在了虚构的API之前，正如将同样的注解放在每一个HTTP请求头里一样。 1234567891011121314151617181920GET /zoos: 获取所有动物园列表POST /zoos: 创建一个新的动物园GET /zoos/ZID: 获取一个完整的动物园对象PUT /zoos/ZID: 更新一个动物园对象 (完整对象)PATCH /zoos/ZID: 更新一个动物园对象 (局部对象)DELETE /zoos/ZID: 删除一个动物GET /zoos/ZID/animals: 获取一个动物园中的动物列表GET /animals: 获取所有动物列表POST /animals: 新建一个动物GET /animals/AID: 获取一个动物对象PUT /animals/AID: 更新一个动物对象 (完整对象)PATCH /animals/AID: 更新一个动物对象 (局部对象)GET /animal_types: 获取一个动物类型列表GET /animal_types/ATID: 获取一个动物类型GET /employees: 获取所有员工列表GET /employees/EID: 获取指定员工对象GET /zoos/ZID/employees: 获取指定动物园里的员工列表POST /employees: 新建一个员工POST /zoos/ZID/employees: 指定动物园雇佣员工DELETE /zoos/ZID/employees/EID: 解雇指定动物园里的指定员工 在上面的列表里，ZID表示动物园的ID， AID表示动物的ID，EID表示雇员的ID，还有ATID表示物种的ID。让文档里所有的东西都有一个关键字是一个好主意。 为了简洁起见，我已经省略了所有API共有的URL前缀。作为沟通方式这没什么问题，但是如果你真要写到API文档中，那就必须包含完整的路径（如，GET http://api.example.com/v1/animal_type/ATID）。 请注意如何展示数据之间的关系，特别是雇员与动物园之间的多对多关系。通过添加一个额外的URL段就可以实现更多的交互能力。当然没有一个HTTP动词能表示正在解雇一个人，但是你可以使用DELETE一个动物园里的雇员来达到相同的效果。 过滤器当客户端创建了一个请求来获取一个对象列表时，很重要一点就是你要返回给他们一个符合查询条件的所有对象的列表。这个列表可能会很大。但你不能随意给返回数据的数量做限制。因为这些无谓的限制会导致第三方开发者不知道发生了什么。如果他们请求一个确切的集合并且要遍历结果，然而他们发现只拿到了100条数据。接下来他们就不得不去查找这个限制条件的出处。到底是ORM的bug导致的，还是因为网络截断了大数据包？ 尽可能减少那些会影响到第三方开发者的无谓限制 这点很重要，但你可以让客户端自己对结果做一些具体的过滤或限制。这么做最重要的一个原因是可以最小化网络传输，并让客户端尽可能快的得到查询结果。其次是客户端可能比较懒，如果这时服务器能对结果做一些过滤或分页，对大家都是好事。另外一个不那么重要的原因是（从客户端角度来说），对服务器来说响应请求的负载越少越好。 过滤器是最有效的方式去处理那些获取资源集合的请求。所以只要出现GET的请求，就应该通过URL来过滤信息。以下有一些过滤器的例子，可能是你想要填加到API中的： 1234?limit=10: 减少返回给客户端的结果数量（用于分页）?offset=10: 发送一堆信息给客户端（用于分页）?animal_type_id=1: 使用条件匹配来过滤记录?sortby=name&amp;order=asc: 对结果按特定属性进行排序 有些过滤器可能会与端点URL的效果重复。例如我之前提到的GET /zoo/ZID/animals。它也同样可以通过GET /animals?zoo_id=ZID来实现。独立的端点会让客户端更好过一些，因为他们的需求往往超出你的预期。本文中提到这种冗余差异可能对第三方开发者并不可见。 无论怎么说，当你准备过滤或排序数据时，你必须明确的将那些客户端可以过滤或排序的列放到白名单中，因为我们不想将任何的数据库错误发送给客户端。 状态码对于一个RESTful API来说很重要的一点就是要使用HTTP的状态码，因为它们是HTTP的标准。很多的网络设备都可以识别这些状态码，例如负载均衡器可能会通过配置来避免发送请求到一台web服务器，如果这台服务器已经发送了很多的50x错误回来。这里有大量的HTTP状态码可以选择，但是下面的列表只给出了一些重要的代码作为一个参考： 123456789101112131415161718200 OK – [GET] The Consumer requested data from the Server, and the Server found it for them (Idempotent) 客户端向服务器请求数据，服务器成功找到它们201 CREATED – [POST/PUT/PATCH] The Consumer gave the Server data, and the Server created a resource 客户端向服务器提供数据，服务器根据要求创建了一个资源204 NO CONTENT – [DELETE] The Consumer asked the Server to delete a Resource, and the Server deleted it 客户端要求服务器删除一个资源，服务器删除成功400 INVALID REQUEST – [POST/PUT/PATCH] The Consumer gave bad data to the Server, and the Server did nothing with it (Idempotent) 客户端向服务器提供了不正确的数据，服务器什么也没做404 NOT FOUND – [*] The Consumer referenced an inexistant Resource or Collection, and the Server did nothing (Idempotent) 客户端引用了一个不存在的资源或集合，服务器什么也没做500 INTERNAL SERVER ERROR – [*] The Server encountered an error, and the Consumer has no knowledge if the request was successful 服务器发生内部错误，客户端无法得知结果，即便请求已经处理成功 状态码范围1xx范围的状态码是保留给底层HTTP功能使用的，并且估计在你的职业生涯里面也用不着手动发送这样一个状态码出来。 2xx范围的状态码是保留给成功消息使用的，你尽可能的确保服务器总发送这些状态码给用户。 3xx范围的状态码是保留给重定向用的。大多数的API不会太常使用这类状态码，但是在新的超媒体样式的API中会使用更多一些。 4xx范围的状态码是保留给客户端错误用的。例如，客户端提供了一些错误的数据或请求了不存在的内容。这些请求应该是幂等的，不会改变任何服务器的状态。 5xx范围的状态码是保留给服务器端错误用的。这些错误常常是从底层的函数抛出来的，并且开发人员也通常没法处理。发送这类状态码的目的是确保客户端能得到一些响应。收到5xx响应后，客户端没办法知道服务器端的状态，所以这类状态码是要尽可能的避免。 预期的返回文档当使用不同的HTTP动词向服务器请求时，客户端需要在返回结果里面拿到一系列的信息。下面的列表是非常经典的RESTful API定义： 123456GET /collection: 返回一系列资源对象GET /collection/resource: 返回单独的资源对象POST /collection: 返回新创建的资源对象PUT /collection/resource: 返回完整的资源对象PATCH /collection/resource: 返回完整的资源对象DELETE /collection/resource: 返回一个空文档 请注意当一个客户端创建一个资源时，她们常常不知道新建资源的ID（也许还有其他的属性，如创建和修改的时间戳等）。这些属性将在随后的请求中返回，并且作为刚才POST请求的一个响应结果。 认证服务器在大多数情况下是想确切的知道谁创建了什么请求。当然，有些API是提供给公共用户（匿名用户）的，但是大部分时间里也是代表某人的利益。 OAuth2.0提供了一个非常好的方法去做这件事。在每一个请求里，你可以明确知道哪个客户端创建了请求，哪个用户提交了请求，并且提供了一种标准的访问过期机制或允许用户从客户端注销，所有这些都不需要第三方的客户端知道用户的登陆认证信息。 还有OAuth1.0和xAuth同样适用这样的场景。无论你选择哪个方法，请确保它为多种不同语言/平台上的库提供了一些通用的并且设计良好文档，因为你的用户可能会使用这些语言和平台来编写客户端。 内容类型目前，大多数“精彩”的API都为RESTful接口提供JSON数据。诸如Facebook，Twitter，Github等等你所知的。XML曾经也火过一把（通常在一个大企业级环境下）。这要感谢SOAP，不过它已经挂了，并且我们也没看到太多的API把HTML作为结果返回给客户端（除非你在构建一个爬虫程序）。 只要你返回给他们有效的数据格式，开发者就可以使用流行的语言和框架进行解析。如果你正在构建一个通用的响应对象，通过使用一个不同的序列化器，你也可以很容易的提供之前所提到的那些数据格式（不包括SOAP）。而你所要做的就是把使用方式放在响应数据的接收头里面。 有些API的创建者会推荐把.json, .xml, .html等文件的扩展名放在URL里面来指示返回内容类型，但我个人并不习惯这么做。我依然喜欢通过接收头来指示返回内容类型（这也是HTTP标准的一部分），并且我觉得这么做也比较适当一些。 超媒体API超媒体API很可能就是RESTful API设计的将来。超媒体是一个非常棒的概念，它回归到了HTTP和HTML如何运作的“本质”。 在非超媒体RESTful API的情景中，URL端点是服务器与客户端契约的一部分。这些端点必须让客户端事先知道，并且修改它们也意味着客户端可能再也无法与服务器通信了。你可以先假定这是一个限制。 时至今日，英特网上的API客户端已经不仅仅只有那些创建HTTP请求的用户代理了。大多数HTTP请求是由人们通过浏览器产生的。人们不会被哪些预先定义好的RESTful API端点URL所束缚。是什么让人们变的如此与众不同？因为人们可以阅读内容，可以点击他们感兴趣的链接，并浏览一下网站，然后跳到他们关注的内容那里。即使一个URL改变了，人们也不会受到影响（除非他们事先给某个页面做了书签，这时他们回到主页并发现原来有一条新的路径可以去往之前的页面）。 超媒体API概念的运作跟人们的行为类似。通过请求API的根来获得一个URL的列表，这个列表里面的每一个URL都指向一个集合，并且提供了客户端可以理解的信息来描述每一个集合。是否为每一个资源提供ID并不重要（或者不是必须的），只要提供URL即可。 一个超媒体API一旦具有了客户端，那么它就可以爬行链接并收集信息，而URL总是在响应中被更新，并且不需要如契约的一部分那样事先被知晓。如果一个URL曾经被缓存过，并且在随后的请求中返回404错误，那么客户端可以很简单的回退到根URL并重新发现内容。 在获取集合中的一个资源列表时会返回一个属性，这个属性包含了各个资源的完整URL。当实施一个POST/PATCH/PUT请求后，响应可以被一个3xx的状态码重定向到完整的资源上。 JSON不仅告诉了我们需要定义哪些属性作为URL，也告诉了我们如何将URL与当前文档关联的语义。正如你猜的那样，HTML就提供了这样的信息。我们可能很乐意看到我们的API走完了完整的周期，并回到了处理HTML上来。想一下我们与CSS一起前行了多远，有一天我们可能再次看到它变成了一个通用实践让API和网站可以去使用相同的URL和内容。 文档老实说，即使你不能百分之百的遵循指南中的条款，你的API也不是那么糟糕。但是，如果你不为API准备文档的话，没有人会知道怎么使用它，那它真的会成为一个糟糕的API。 12345让你的文档对那些未经认证的开发者也可用不要使用文档自动化生成器，即便你用了，你也要保证自己审阅过并让它具有更好的版式。不要截断示例中请求与响应的内容，要展示完整的东西。并在文档中使用高亮语法。文档化每一个端点所预期的响应代码和可能的错误消息，和在什么情况下会产生这些的错误消息12345 如果你有富余的时间，那就创建一个控制台来让开发者可以立即体验一下API的功能。创建一个控制台并没有想象中那么难，并且开发者们（内部或者第三方）也会因此而拥戴你。 另外确保你的文档能够被打印。CSS是个强大的工具可以帮助到你。而且在打印的时候也不用太担心边侧栏的问题。即便没有人会打印到纸上，你也会惊奇的发现很多开发者愿意转化成PDF格式进行离线阅读。 勘误：原始的HTTP封包因为我们所做的都是基于HTTP协议，所以我将展示给你一个解析了的HTTP封包。我经常很惊讶的发现有多少人不知道这些东西。当客户端发送一个请求到服务器时，他们会提供一个键值对集，先是一个头，紧跟着是两个回车换行符，然后才是请求体。所有这些都是在一个封包里被发送。 服务器响应也是同样的键值对集，带两个回车换行符，然后是响应体。HTTP就是一个请求/响应协议；它不支持“推送”模式（服务器直接发送数据给客户端），除非你采用其他协议，如Websockets。 当你设计API时，你应该能够使用工具去查看原始的HTTP封包。Wireshark是个不错的选择。同时，你也该采用一个框架/web服务器，使你能够在必要时修改某些字段的值。 Example HTTP Request 12345678910POST /v1/animal HTTP/1.1Host: api.example.orgAccept: application/jsonContent-Type: application/jsonContent-Length: 24&#123; &quot;name&quot;: &quot;Gir&quot;, &quot;animal_type&quot;: 12&#125; Example HTTP Response 12345678910111213HTTP/1.1 200 OKDate: Wed, 18 Dec 2013 06:08:22 GMTContent-Type: application/jsonAccess-Control-Max-Age: 1728000Cache-Control: no-cache&#123; &quot;id&quot;: 12, &quot;created&quot;: 1386363036, &quot;modified&quot;: 1386363036, &quot;name&quot;: &quot;Gir&quot;, &quot;animal_type&quot;: 12&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[spring boot使用redis]]></title>
    <url>%2F2017%2F11%2F20%2Fspring-boot%E4%BD%BF%E7%94%A8redis%2F</url>
    <content type="text"><![CDATA[关于redis就不多介绍了。就介绍一下spring-data-redis的使用。 在用spring boot 开发项目的时候用到了redis。故对spring boot 使用redis数据库做一个简单的记录。 使用spring-data-redis来对redis数据库进行操作 pom中加入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; spring boot 配置文件没做集群的话可以直接连接不要哨兵 1234567891011121314151617181920212223# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=192.168.99.100# Redis服务器连接端口spring.redis.port=16379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 #配置的是redis哨兵 spring.redis.sentinel.master=mymaster spring.redis.sentinel.nodes=192.168.99.100:16383,192.168.99.100:16384,192.168.99.100:16385 redis配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Configurationpublic class RedisConfig &#123; /** * 注入 RedisConnectionFactory */ @Autowired RedisConnectionFactory redisConnectionFactory; /** * 实例化 RedisTemplate 对象 * * @return */ @Bean public RedisTemplate&lt;String, Object&gt; functionDomainRedisTemplate() &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); initDomainRedisTemplate(redisTemplate, redisConnectionFactory); return redisTemplate; &#125; /** * 设置数据存入 redis 的序列化方式 * * @param redisTemplate * @param factory */ private void initDomainRedisTemplate(RedisTemplate&lt;String, Object&gt; redisTemplate, RedisConnectionFactory factory) &#123; redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setConnectionFactory(factory); &#125; /** * 实例化 HashOperations 对象,可以使用 Hash 类型操作 * * @param redisTemplate * @return */ @Bean public HashOperations&lt;String, String, Object&gt; hashOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForHash(); &#125; /** * 实例化 ValueOperations 对象,可以使用 String 操作 * * @param redisTemplate * @return */ @Bean public ValueOperations&lt;String, Object&gt; valueOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForValue(); &#125; /** * 实例化 ListOperations 对象,可以使用 List 操作 * * @param redisTemplate * @return */ @Bean public ListOperations&lt;String, Object&gt; listOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForList(); &#125; /** * 实例化 SetOperations 对象,可以使用 Set 操作 * * @param redisTemplate * @return */ @Bean public SetOperations&lt;String, Object&gt; setOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForSet(); &#125; /** * 实例化 ZSetOperations 对象,可以使用 ZSet 操作 * * @param redisTemplate * @return */ @Bean public ZSetOperations&lt;String, Object&gt; zSetOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForZSet(); &#125;&#125; 定义IRredisService接口下面定义一个与redis交互的接口，简单的写了两个例子 1234567891011121314151617@Servicepublic interface IRedisService&lt;K extends String,V&gt; &#123; /** * * @param key * @param value */ void set(K key, V value); /** * * @param key * @param value * @param timeout 设置过时时间 * @param unit */ void set(K key, V value, long timeout, TimeUnit unit);&#125; 接口实现类 1234567891011121314public class IRedisServiceImpl implements IRedisService &#123; @Autowired private RedisTemplate&lt;String,Object&gt; redisTemplate; @Override public void set(String key, Object value) &#123; redisTemplate.opsForValue().set(key,value); &#125; @Override public void set(String key, Object value, long timeout, TimeUnit unit) &#123; redisTemplate.opsForValue().set(key,value,timeout,unit); &#125;&#125; 测试保存字符串12345@Testpublic void test() throws Exception &#123; // 保存字符串 iRedisService.set("aaa", "111");&#125; 保存对象创建对象 12345678@Data@AllArgsConstructor@NoArgsConstructorpublic class User implements Serializable &#123; private static final long serialVersionUID = -1L; private String username; private Integer age;&#125; 1234@Testpublic void test1()&#123; iRedisService.set("bcv",new User());&#125; 成功。 总结spring-data-redis 中封装了许多对redis的操作。上述只是简单的入门。]]></content>
      <categories>
        <category>spring boot</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring clpoud 系列之Eureka]]></title>
    <url>%2F2017%2F11%2F19%2Fspring-clpoud-%E7%B3%BB%E5%88%97%E4%B9%8BEureka%2F</url>
    <content type="text"><![CDATA[###spring cloud 服务治理Eureka 微服务过程中我们会开发会许多服务，不管怎样来将服务进行划分，服务与服务之间必定会有千丝万缕的联系。怎样来把这些单个的服务连接起来？ 在微服务开发过程中有许多开源的项目可以用来将这些服务进行关联起来，比如：Netflix Eureka、Consul、Zookeeper。它们都可以当作服务注册中心来使用。由于我所接触的项目使用Eureka来做的。所以本次就将着重介绍一下eureka 的使用。 简介Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。而Spring Cloud Netflix项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。 构建Eureka-server pom文件 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker搭建redis集群]]></title>
    <url>%2F2017%2F11%2F15%2Fdocker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[docker 构建 redis 集群由于最近项目用到redis,考虑到redis的高可用故用docker搭建redis集群镜像。把原先散落各处的redis服务器统一管理起来，并且保障高可用和故障自动迁移。 redis 集群分类:大家都知道redis集群有两种，一种是redis sentinel，高可用集群，同时只有一个master，各实例数据保持一致；一种是redis cluster，分布式集群，同时有多个master，数据分片部署在各个master上。基于我们的需求和redis本身技术的成熟度，本次要搭建的是redis sentinel。 关于它的介绍： Redis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下四个任务： 不时地监控redis是否按照预期良好地运行 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave 的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的 新地址。 哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 制作镜像整个集群可以分为一个master，N个slave，M个sentinel，本次以2个slave和3个sentinel为例： 增加redis.conf 12345678910##redis.conf##redis-0,默认为masterport $redis_port##授权密码，请各个配置保持一致##暂且禁用指令重命名##rename-command##开启AOF，禁用snapshotappendonly yes#slaveof redis-master $master_port #redis-master master主机域名slave-read-only yes 增加sentinel.conf 1234567port $sentinel_portdir "/tmp"sentinel monitor mymaster redis-master $master_port 2##选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。sentinel config-epoch mymaster 1sentinel leader-epoch mymaster 1sentinel current-epoch 1 增加启动脚本，根据入参判断启动master，slave，sentinel 123456789101112131415161718192021cd /dataredis_role=$1echo $redis_roleif [ $redis_role = "master" ] ; then echo "master" sed -i "s/\$redis_port/$redis_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "slave" ] ; then echo "slave" sed -i "s/\$redis_port/$redis_port/g" redis.conf sed -i "s/#slaveof/slaveof/g" redis.conf sed -i "s/\$master_port/$master_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "sentinel" ] ; then echo "sentinel" sed -i "s/\$sentinel_port/$sentinel_port/g" sentinel.conf sed -i "s/\$master_port/$master_port/g" sentinel.conf redis-sentinel /data/sentinel.confelse echo "unknow role!" fi #ifend 其中$redis_port和$master_port,$sentinel_port都是取自环境变量，通过Docker启动时候传入。 编写Dockerfile 123456789FROM redis:3-alpineMAINTAINER yanhl &lt;yanhl&gt;COPY redis.conf /data/redis.confCOPY sentinel.conf /data/sentinel.confCOPY start.sh /data/start.shRUN chmod +x /data/start.shRUN chown redis:redis /data/*ENTRYPOINT ["sh","/data/start.sh"] CMD ["master"] 选取redis-alpine镜像作为基础镜像，因为它非常小，只有9M，修改时区和把一些配置拷贝进去后，变更下权限和用户组，因为基础镜像是redis用户组。ENTRYPOINT和CMD组合，默认以master方式启动。build完成后，镜像只有15M。 启动采用docker-compose格式： 12345678910111213141516171819202122232425262728293031323334353637redis-master-host: environment: redis_port: '16379' labels: io.rancher.container.pull_image: always tty: true image: #镜像id stdin_open: true net: hostredis-slaves: environment: master_port: '16379' redis_port: '16380' labels: io.rancher.scheduler.affinity:container_label_soft_ne: name=slaves io.rancher.container.pull_image: always name: slaves tty: true command: - slave image: #镜像id stdin_open: true net: hostredis-sentinels: environment: master_port: '16379' sentinel_port: '16381' labels: io.rancher.container.pull_image: always name: sentinels io.rancher.scheduler.affinity:container_label_ne: name=sentinels tty: true command: - sentinel image: #镜像id stdin_open: true net: host 首先启动master，传入端口16379，host模式，在启动slave，成为16379 master 的slave，并且设置调度策略为尽可能分散的方式，sentinels也类似。 测试启动 redis集群： java访问redis 123456789@Test public void test() throws Exception &#123; // 保存字符串 int i=0; while (true) &#123; stringRedisTemplate.opsForValue().set("a" + i, "111"); i++; &#125; &#125; 此时停掉一台哨兵 可以正常存储 1redis.clients.jedis.JedisSentinelPool : Lost connection to Sentinel at 192.168.99.100:16383. Sleeping 5000ms and retrying. 停掉所有哨兵 1Invocation of init method failed; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: All sentinels down, cannot determine where is mymaster master is running... 停掉一台slave 其中一台哨兵日志 1237:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.954 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.795 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 16379 重新启动会重新从主服务器加载数据 1234567891011121314151617181920218:S 15 Nov 13:00:04.461 * DB loaded from append only file: 0.619 seconds8:S 15 Nov 13:00:04.461 * The server is now ready to accept connections on port 163818:S 15 Nov 13:00:04.461 * Connecting to MASTER 192.168.99.100:163798:S 15 Nov 13:00:04.461 * MASTER &lt;-&gt; SLAVE sync started8:S 15 Nov 13:00:04.461 * Non blocking connect for SYNC fired the event.8:S 15 Nov 13:00:04.461 * Master replied to PING, replication can continue...8:S 15 Nov 13:00:04.461 * Partial resynchronization not possible (no cached master)8:S 15 Nov 13:00:04.468 * Full resync from master: 6cc2e4e7bbb4680ac0a8d9f7e5390f96eb1b1d76:384084118:S 15 Nov 13:00:05.291 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master8:S 15 Nov 13:00:05.314 * MASTER &lt;-&gt; SLAVE sync: Flushing old data8:S 15 Nov 13:00:05.354 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory8:S 15 Nov 13:00:06.422 * MASTER &lt;-&gt; SLAVE sync: Finished with success8:S 15 Nov 13:00:06.424 * Background append only file rewriting started by pid 118:S 15 Nov 13:00:07.703 * AOF rewrite child asks to stop sending diffs.11:C 15 Nov 13:00:07.703 * Parent agreed to stop sending diffs. Finalizing AOF...11:C 15 Nov 13:00:07.703 * Concatenating 0.00 MB of AOF diff received from parent.11:C 15 Nov 13:00:07.703 * SYNC append only file rewrite performed11:C 15 Nov 13:00:07.703 * AOF rewrite: 8 MB of memory used by copy-on-write8:S 15 Nov 13:00:07.739 * Background AOF rewrite terminated with success8:S 15 Nov 13:00:07.740 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)8:S 15 Nov 13:00:07.740 * Background AOF rewrite finished successfully 挂掉master 哨兵日志 哨兵会投票重新选取master 12345678910111213141516177:X 15 Nov 12:41:31.885 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.7:X 15 Nov 12:41:31.887 # Sentinel ID is 558ea99046801b4451dd49945d405f63e125f11e7:X 15 Nov 12:41:31.887 # +monitor master mymaster 192.168.99.100 16379 quorum 27:X 15 Nov 12:41:31.887 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.929 * +sentinel sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.922 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.809 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.517 * +reboot slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.584 # -sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.005 # +sdown master mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.119 # +new-epoch 27:X 15 Nov 13:04:19.119 # +vote-for-leader 8acf7f07765409e85e932c3baea249537f24f94c 27:X 15 Nov 13:04:19.611 # +config-update-from sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.611 # +switch-master mymaster 192.168.99.100 16379 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16379 192.168.99.100 16379 @ mymaster 192.168.99.100 16381 启动master 发现成为了一个从服务器 1234567891011121314151617181920212223242526276:M 15 Nov 13:08:18.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.6:M 15 Nov 13:08:18.767 # Server started, Redis version 3.2.116:M 15 Nov 13:08:18.767 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.6:M 15 Nov 13:08:18.767 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.6:M 15 Nov 13:08:21.409 * DB loaded from append only file: 2.642 seconds6:M 15 Nov 13:08:21.409 * The server is now ready to accept connections on port 163796:S 15 Nov 13:08:28.852 * SLAVE OF 192.168.99.100:16381 enabled (user request from 'id=2 addr=192.168.99.100:59528 fd=8 name= age=10 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')6:S 15 Nov 13:08:28.853 # CONFIG REWRITE executed with success.6:S 15 Nov 13:08:29.457 * Connecting to MASTER 192.168.99.100:163816:S 15 Nov 13:08:29.457 * MASTER &lt;-&gt; SLAVE sync started6:S 15 Nov 13:08:29.457 * Non blocking connect for SYNC fired the event.6:S 15 Nov 13:08:29.458 * Master replied to PING, replication can continue...6:S 15 Nov 13:08:29.458 * Partial resynchronization not possible (no cached master)6:S 15 Nov 13:08:29.463 * Full resync from master: 8cf78a3d6fe25eb719901e129627cc5f7556c6d4:525026:S 15 Nov 13:08:30.107 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master6:S 15 Nov 13:08:30.136 * MASTER &lt;-&gt; SLAVE sync: Flushing old data6:S 15 Nov 13:08:30.573 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory6:S 15 Nov 13:08:31.579 * MASTER &lt;-&gt; SLAVE sync: Finished with success6:S 15 Nov 13:08:31.581 * Background append only file rewriting started by pid 96:S 15 Nov 13:08:32.494 * AOF rewrite child asks to stop sending diffs.9:C 15 Nov 13:08:32.495 * Parent agreed to stop sending diffs. Finalizing AOF...9:C 15 Nov 13:08:32.495 * Concatenating 0.00 MB of AOF diff received from parent.9:C 15 Nov 13:08:32.495 * SYNC append only file rewrite performed9:C 15 Nov 13:08:32.496 * AOF rewrite: 2 MB of memory used by copy-on-write6:S 15 Nov 13:08:32.584 * Background AOF rewrite terminated with success6:S 15 Nov 13:08:32.584 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)6:S 15 Nov 13:08:32.584 * Background AOF rewrite finished successfully 测试通过。]]></content>
      <categories>
        <category>docker</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-stream-rabbitmq]]></title>
    <url>%2F2017%2F11%2F14%2Fspring-cloud-stream-rabbitmq%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 使用 rabbitmq 在使用spring cloud 构建微服务的时候用到的消息队列rabbitmq 综合了一下感觉用spring cloud stream 整合比较简单后期如果更换其它消息队列也比较简单 spring cloud stream 整合rabbitmq 概述 Spring Cloud Stream（以下简称SCS）是一个用于构建消息驱动微服务的框架。简单来说，通过SCS我们可以快速地在微服务之间传递异步消息，这对于一些刚起步时需求简单的消息应用是很方便的。 入门尽管很方便，但必要的准备工作还是要做的。SCS本身并不提供消息服务器，因此我们还是要安装像RabbitMQ或Kafka这样的消息服务器，本文会使用RabbitMQ来做讲解，具体如何安装Erlang和RabbitMQ这里不再赘述。安装好以后可以暂时不对RabbitMQ做配置。但要记得运行rabbitmq-plugins enable rabbitmq_management来激活管理平台以方便后续使用 。 生产者创建一个rabbitmq-producer微服务，默认端口8080 创建一个接口作为通道，举例： 123456789//生产者//创建一个rabbitmq-producer微服务，默认端口8080；//创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String OUTPUT = "test"; @Output(OUTPUT) MessageChannel output();&#125; @Output注解代表这是一个输出通道，而通道名就是我们定义的test，一个接口中可以定义多个输入和输出通道。实际上SCS本身提供了三个预定义接口通道，即Source.class单向输出通道，Sink.class单向输入通道，以及继承了它们两个的Processor.class，你可以在源码org.springframework.cloud.stream.messaging包中找到它们。但它们都只是简单示例，真正开发时我们肯定还是要自定义接口作为通道； 1234567891011121314151617//创建用于发送消息的接口（或直接在启动类中编写）：@RestController@EnableBinding(MyChannel.class)public class SendController &#123; @Autowired private MyChannel sender; @RequestMapping("/send") public String send()&#123; try &#123; sender.output().send(MessageBuilder.withPayload("Hello World").build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125; &#125;&#125; 需要注意的是，@EnableBinding注解是必须要加的（即使你只使用JUnit测试），但并不是必须添加在启动类上，其实你可以把它放在任何一个Spring能够扫描到的类。但为了方便查找，还是推荐放在启动类或者消息类上。 生产者至此告一段落，接下来我们看一下消费者。 消费者 12345678//创建一个consumer微服务，为防止与生产者冲突，端口号设为8081；//和生产者一样，创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String INPUT = "test"; @Input(INPUT) SubscribableChannel input();&#125; @Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息，因此我们也定义为test； 创建用于接收消息的类（或直接在启动类中编写）： 12345678@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;String&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; @StreamListener注解用于监听通道，由于我们在生产者发送的是一个”Hello World”字符串，因此在这里我们用string来接收它，注意Message用的是org.springframework.messaging.Message；与生产者一样，在启动类上添加@EnableBinding(MyChannel.class)。 测试 首先启动消费者微服务，如果你激活了RabbitMQ管理平台，那么此时就可以在上面看到test通道的相关信息了，包括Exchange和Queue 访问消息提供者的接口 http://localhost:8082/send在监听方会有消息 修改配置 至此我们就完成了简单的消息发送与接收服务，是不是感觉很快就能起飞了呢？手动配置在开头我提到可以暂时不对RabbitMQ做配置，这是为了我们可以快速开发调试。但现实中我们不可能不去修改RabbitMQ的配置（哪怕只是改改密码，毕竟guest相当于裸奔），那么如何让SCS去匹配修改过的配置呢？单就YAML配置来说，有两种方式（使用@Configuration类做配置的朋友请自行对照）： 直接配置spring.rabbitmq，比如我使用另外一个用户连接 12345spring: rabbitmq: username: “用户名” password: ”密码“ virtual-host: /test 使用spring.cloud.stream.binders和spring.cloud.stream.bindings组合配置，同样是上面的情况： 123456789101112131415spring: cloud: stream: bindings: test: binder: rabbit binders: rabbit: type: rabbit environment: spring: rabbitmq: username: ”用户名“ password: ”密码“ virtual-host: /test 乍一看感觉好麻烦呀，而且environment下面的配置不就是上面spring.rabbitmq的配置吗？ 实际上这种写法是有它的好处的，首先我们注意到，binders里面可以配置不同环境的binder，而通过bindings我们可以把channel和binder绑定起来。 假设我这个微服务现在要连两个RabbitMQ，那么我们就可以这样配置： 1234567891011121314151617181920212223242526272829spring: cloud: stream: bindings: test1: binder: rabbit1 test2: binder: rabbit2 binders: rabbit1: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5672 username: password: virtual-host: /test1 rabbit2: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5673 username: password: virtual-host: /test2 注：spring.cloud.stream.bindings.里面有许多有用的配置，比如destination、group等等。” 进阶好了简单的消息发送与接收已经实现了 如何像消息队列传递一个对象呢？ 上一节中我们发送的消息是一个字符串，那如果我想发送POJO怎么办呢？是直接发送和接收就可以了吗？下面我们可以试验一下： 首先创建一个User POJO，然后修改生产者的send()方法： 12345678910111213@GetMapping("/send")public String send() &#123; try &#123; User user = new User(); user.setId("1"); user.setName("yhl"); sender.output().send(MessageBuilder.withPayload(user).build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125;&#125; 修改消费者sc-stream-consumer的receive()方法： 123456789@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;User&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; 访问send 结果 接收方接到了一个user对象 如果你的User是分别在生产者和消费者中定义的，并且包路径不同，那么会报错反序列化失败。原因是SCS会默认将POJO转换成二进制发送，并且携带包路径等信息； 如果生产者和消费者使用的User是同一定义，或分别定义但包路径相同，那么就不会报错。 看起来略微有点不爽，那么有没有别的转换方式呢？ 有，而且官方还提供了很多： 下面我会举例用JSON字符串来传递POJO，其实只要在生产者中加上一条配置即可： 123456spring cloud: stream: bindings: test: content-type: application/json 此时消费者sc-stream-consumer接收的消息实体实际上是字符串了，我们可以用Message来测试一下： 此时收到的就是json数据了 既然接收的是JSON字符串了，那Spring怎么可能不提供自动反射呢XD，再次把消息实体换回User就行了。 负载均衡实际生产中，我们一般都会启动多个消费者实例来做负载均衡，既然是负载均衡，我们肯定希望一条消息在一组负载均衡实例中只被其中一个消费者接收。那么SCS是如何处理这种情况的呢？ 假设我们现在已经启动了生产者和消费者实例各一个，然后再修改消费者的端口为8082，再启动一个消费者实例。 随后发送消息测试，我们会发现两个消费者实例都接收到了消息： 这显然不是我们希望的，那么现在就来分析一下为什么会出现这种情况。 关键点在headers中的amqp_consumerQueue这个属性上，我们看到8081和8082的amqp_consumerQueue前面都是test.anonymous，但后面却是不一样的。这其实表示他们被分到了不同的匿名组（即group），而同一条消息会被test中的每个组都接收到。这个也很好理解，我们把group比喻成现实中的公司各部门，现在我要发一个通知，我会发给所有的部门，但同一部门中只要有一个人收到了，我就认为这个部门收到了通知。 所以只要把要负载均衡的实例分在同一个group下就好了，我们给消费者添加如下配置： 123456spring: cloud: stream: bindings: test: group: yhl 有一个test.yhl 队列这时调用发送者会发现两个消费者循环接受消息。]]></content>
      <categories>
        <category>消息队列</category>
        <category>rabbitMq</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudStream]]></title>
    <url>%2F2017%2F11%2F14%2FSpringCloudStream%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 翻译 （还没翻译完） 原文地址： https://docs.spring.io/spring-cloud-stream/docs/current-SNAPSHOT/reference/htmlsingle/#_introducing_spring_cloud_stream 1.简介Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的工业级spring应用，使用spring integration提供与消息代理之间的连接。本文提供不同代理中的中间件配置，介绍了持久化发布订阅机制，以及消费组以及分割的概念。将注解@EnableBinding加到应用上就可以实现与消息代理的连接，@StreamListener注解加到方法上，使之可以接收处理流的事件。 1234567891011121314151617@SpringBootApplicationpublic class StreamApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamApplication.class, args); &#125;&#125;@EnableBinding(Sink.class)public class TimerSource &#123; ... @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125;123456789101112131415161718 @EnableBinding注解使用一个或者多个接口作为参数（本例子中，参数是单独的Sink接口）。接口声明了输入和／或输出通道。 Spring Cloud Stream提供了Source, Sink, 和 Processor三个接口；你也可以定义你自己的接口。下面是Sink接口的定义： 123456public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;123456 @Input注解定义了一个输入通道，应用通过该输入通道接收进入应用的消息；@Output注解定义了一个输出通道，发布的消息通过该通道离开应用。input和output注解可以使用通道名称作为参数；如果没有名称，会使用带注解的方法的名字作为参数（也就是说，如果没有定义单独的名字，这里的通道名就是方法名input）。Spring Cloud Stream会为你创建一个接口的实现(这里注意，一定要在application里面加上@EnableBinding注解，不然会出现自动注入失败，因为缺少这个注解的话stream就不会创建接口的实例)。你可以通过自动装配在应用中使用它，如下面测试用例所示： 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = StreamApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125;1234567891011121314 2.主要概念Spring Cloud Stream提供了很多抽象和基础组件来简化消息驱动型微服务应用。包含以下内容： Spring Cloud Stream的应用模型 绑定抽象 持久化发布／订阅支持 消费者组支持 分片支持（Partitioning Support） 可插拔绑定api 应用模型 2.1应用模型Spring Cloud Stream由一个中间件中立的核组成。应用通过Spring Cloud Stream插入的input和output通道与外界交流。通道通过指定中间件的Binder实现与外部代理连接。 2.1.1 胖JAR测试的话，Spring Cloud Stream可以在ide中运行一个单独的实例。在生产环境中，可以通过Maven 或者 Gradle提供的Spring Boot 工具创建可执行JAR（或者胖JAR）。 2.2绑定抽象Spring Cloud Stream提供对 Kafka, Rabbit MQ,Redis, 和 Gemfire的绑定实现。Spring Cloud Stream使用Spring Boot做配置，绑定抽象使得stream可以灵活的连接到中间件。比如，开发者可以在运行时动态的选择通道连接的目标（可以是kafka主题或者RabbitMQ 交换机）。该配置可以通过spring boot支持的任何配置形式实现。在sink的例子中，将属性spring.cloud.stream.bindings.input.destination设置为raw-sensor-data，程序会从命名为raw-sensor-data的kafka主题中读取数据，或者从一个绑定到raw-sensor-data的rabbitmq交换机的队列中读取数据（这里的input是通道名，raw-sensor-data则是exchange的名字，通过使用同一个名字，可以将输入输出通道进行绑定）。Spring Cloud Stream自动检测和使用在class path中找到的binder。可以在build的时候引入不同的binder来使用不同类型的中间件。更复杂的情况下，可以在应用中打包多个binder使之按需选择，甚至可以在运行时根据不同的通道选择不同的binder。 2.3持久化发布／订阅支持应用间通信遵照发布-订阅模型，消息通过共享主题进行广播。下图所示，显示了交互的Spring Cloud Stream 应用的典型布局。sensor传给http端点的数据传给名为raw-sensor-data的目标。发布订阅模型简化了生产者和消费者的复杂程度，并且新的应用可以在不对当前数据流造成影响的情况下加入到拓扑中。由于发布－订阅模型并非一个新的概念，Spring Cloud Stream将其作为应用模型中的可选项。通过使用原生中间件支持，Spring Cloud Stream也简化了不同平台之间使用发布－订阅模型的复杂程度。 2.4消费者组由于发布－订阅模型使得共享主题的应用之间连接更简便，创建给定应用的不同实例来进行弹性扩张的能力也同样重要。如果存在多个应用实例，那么同一应用的额不同实例便会成为相互竞争的消费者，其中应该只有一个实例处理给定消息。Spring Cloud Stream通过消费者组的概念给这种情况进行建模。每一个单独的消费者可以使用spring.cloud.stream.bindings.input.group属性来指定一个组名字。下图中展示的消费者们，这一属性被设置为spring.cloud.stream.bindings.input.group=hdfsWrite或者spring.cloud.stream.bindings.input.group=average。所有订阅给定目标的组都会收到发布消息的一个拷贝，但是每一个组内只有一个成员会收到该消息。默认情况下，如果没有指定组，Spring Cloud Stream 会将该应用指定给一个匿名的独立的单成员消费者组，后者与所有其他组都处于一个发布－订阅关系中。持久性与Spring Cloud Stream中的可选应用模型一样，消费者组订阅是持久的。也就是说，一个绑定的实现确保组的订阅者是持久的，一旦组中至少有一个成员创建了订阅，这个组就会收到消息，即使组中所有的应用都被停止了，组仍然会收到消息。注：自然情况下，匿名订阅者是非持久化的。对于某些绑定实现（如rabbitmq），可以创建非持久化（non－durable）组订阅。一般来说，将应用绑定到给定目标的时候，最好指定一个消费者组。扩展Spring Cloud Stream应用的时候，对于它的每一个输入绑定，都必须要指定一个消费者组。 这样可以防止应用实例收到重复的消息。（除非存在重复收到的需求，但实际上很少会有这样的需求）。 2.5分片支持（Partitioning Support）Spring Cloud Stream对给定应用的多个实例之间分隔数据予以支持。在分隔方案中，物理交流媒介（如：代理主题）被视为分隔成了多个片（partitions）。一个或者多个生产者应用实例给多个消费者应用实例发送消息并确保相同特征的数据被同一消费者实例处理。Spring Cloud Stream对分割的进程实例实现进行了抽象。因此分片可以用于自带分隔的代理（如kafka）或者不带分隔的代理（如rabbitmq）。分割在有状态处理中是一个很重要的概念，在性能和一致性上，分割都是重要的概念。例如，在时间窗平均计算的例子中，给定传感器测量结果应该都由同一应用实例进行计算。注：如果要设置分割处理方案，需要配置数据处理和数据消费端点。 3.编程模型这一部分描述Spring Cloud Stream的编程模型。Spring Cloud Stream提供很多预先定一的注解来声明约束输入和输出通道以及如何监听这些通道。 3.1声明和绑定通道3.1.1通过@EnableBinding触发绑定将@EnableBinding应用到spring应用的一个配置类中，可以将spring应用变成Spring Cloud Stream应用。@EnableBinding注解本身就包含@Configuration注解，并且会触发Spring Cloud Stream 基本配置。@EnableBinding注解可以接收一个或多个接口类作为对象，后者包含代表了可绑定构件（一般来说是消息通道）的方法。注：在Spring Cloud Stream1.0中，仅有的可绑定构件是Spring 消息 MessageChannel以及它的扩展SubscribableChannel 和 PollableChannel. 未来版本会使用相同的机制扩展对其他类型构件的支持。在本文档中，会继续饮用通道。3.1.2@Input 和 @Output一个Spring Cloud Stream应用可以有任意数目的input和output通道，后者通过@Input and @Output方法在进口中定义。 1234567891011public interface Barista &#123; @Input SubscribableChannel orders(); @Output MessageChannel hotDrinks(); @Output MessageChannel coldDrinks();&#125;1234567891011 将该接口作为@EnableBinding的参数，会相应的触发三个名为orders, hotDrinks, 和 coldDrinks的绑定好的通道。 12345@EnableBinding(Barista.class)public class CafeConfiguration &#123; ...&#125;12345 定制通道名字使用@Input 和 @Output注解，可以自己指定通道的名字，如下所示： 12345public interface Barista &#123; ... @Input("inboundOrders") SubscribableChannel orders();&#125;12345 这个例子中，创建的绑定队列会被命名为inboundOrders。Source, Sink, and Processor在大多数用例中，包含一个输入通道或者一个输出通道或者二者都包含，为了更简单的定位，Spring Cloud Stream创造性的提供了三个预定义的接口。Source用于有单个输出（outbound）通道的应用。 12345678public interface Source &#123; String OUTPUT = "output"; @Output(Source.OUTPUT) MessageChannel output();&#125;12345678 Sink用于有单个输入（inbound）通道的应用。 12345678public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;12345678 Processor用于单个应用同时包含输入和输出通道的情况。 12public interface Processor extends Source, Sink &#123;&#125;12 Spring Cloud Stream对这三个接口没有提供任何特殊处理。他们只是用于创造性的提供。 3.1.3访问绑定通道 1.注入已绑定接口对于每一个已绑定的接口， Spring Cloud Stream会生成一个bean实现该接口。唤起这些由@Input或者 @Output注解的方法生成的bean，其中一个bean会返回相应的通道。下面例子中，当hello方法被唤起的时候，bean会在output通道上发送一个消息。在注入的Source bean上提供唤醒output()来检索到目标通道。 1234567891011121314@Componentpublic class SendingBean &#123; private Source source; @Autowired public SendingBean(Source source) &#123; this.source = source; &#125; public void sayHello(String name) &#123; source.output().send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 2.直接注入到通道绑定的通道也可以直接注入。 1234567891011121314@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; output.send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 如果通道名称是在声明的注解上指定的，则不能使用方法名称，而要使用通道名称。举例如下： 12345public interface CustomSource &#123; ... @Output("customOutput") MessageChannel output();&#125;12345 通道会按照下面方式注入： 123456789101112131415@Componentpublic class SendingBean &#123; @Autowired private MessageChannel output; @Autowired @Qualifier("customOutput") public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; customOutput.send(MessageBuilder.withPayload(body).build()); &#125;&#125;123456789101112131415 3.1.4生产和消费消息 可以使用Spring Integration 的注解或者Spring Cloud Stream的 @StreamListener 注解来实现一个Spring Cloud Stream应用。@StreamListener注解模仿其他spring消息注解（例如@MessageMapping, @JmsListener, @RabbitListener等），但是它增加了内容类型管理和类型强制特性。1.原生Spring Integration支持因为 Spring Cloud Stream是基于Spring Integration构建，Stream完全继承了Integration的基础设施以及构件本身。例如，可以将Source的output通道连接到一个MessageSource： 123456789101112@EnableBinding(Source.class)public class TimerSource &#123; @Value("$&#123;format&#125;") private String format; @Bean @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay = "$&#123;fixedDelay&#125;", maxMessagesPerPoll = "1")) public MessageSource&lt;String&gt; timerMessageSource() &#123; return () -&gt; new GenericMessage&lt;&gt;(new SimpleDateFormat(format).format(new Date())); &#125;&#125;123456789101112 或者可以在transformer中使用处理器的通道。 1234567@EnableBinding(Processor.class)public class TransformProcessor &#123; @Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT) public Object transform(String message) &#123; return message.toUpper(); &#125;&#125;1234567 2.使用 @StreamListener进行自动内容类型处理作为原生Spring Integration的补充，Spring Cloud Stream提供了自己的@StreamListener注解，该注解模仿spring的其它消息注解（如@MessageMapping, @JmsListener, @RabbitListener等）。@StreamListener注解提供了一种更简单的模型来处理输入消息，尤其是处理包含内容类型管理和类型强制的用例的情况。Spring Cloud Stream提供了一个扩展的MessageConverter机制，该机制提供绑定通道实现数据处理，本例子中，数据会分发给带@StreamListener注解的方法。下面例子展示了处理外部Vote事件的应用： 1234567891011@EnableBinding(Sink.class)public class VoteHandler &#123; @Autowired VotingService votingService; @StreamListener(Sink.INPUT) public void handle(Vote vote) &#123; votingService.record(vote); &#125;&#125;1234567891011 在输入消息内容头为application/json的情况下，@StreamListener和Spring Integration的@ServiceActivator之间会体现出差异。使用@StreamListener的情况下，MessageConverter机制会使用contentType头将string负载解析为Vote对象（也就是如果传输的是对象，应该选用@StreamListener注解）。在其它Spring Messaging方法中，消息机制可以使用@Payload, @Headers 和 @Header这些注解。 注：对于那些有返回数据的方法，必须使用@SendTo注解来指定返回数据的输出绑定目标。 123456789101112@EnableBinding(Processor.class)public class TransformProcessor &#123; @Autowired VotingService votingService; @StreamListener(Processor.INPUT) @SendTo(Processor.OUTPUT) public VoteResult handle(Vote vote) &#123; return votingService.record(vote); &#125;&#125;123456789101112 注：在RabbitMQ中，内容类型头可以由外部应用设定。 3.1.5聚合Aggregation Spring Cloud Stream可以支持多种应用的聚合，可以实现多种应用输入输出通道直接连接，而无需额外代价。在1.0版本中，只有以下类型应用支持聚合： sources：带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Source sinks：带有名为input的单一输入通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Sink processors：带有名为input的单一输入通道和带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定type org.springframework.cloud.stream.messaging.Processor. 可以通过创建一系列相互连接的应用将它们聚合到一起，其中，序列中一个元素的输出通道与下一个元素的输入通道连接在一起。序列可以由一个cource或者一个processor开始，可以包含任意数目的processors，并由processors或者sink结束。取决于开始和结束元素的特性，序列可以有一个或者多个可绑定的通道，如下： 如果序列由source开始，sink结束，应用之间直接通信并且不会绑定通道 如果序列由processor开始，它的输入通道会变成聚合的input通道并进行相应的绑定 如果序列由processor结束，它的输出通道会变成聚合的output通道并进行相应的绑定 使用AggregateApplicationBuilder功能类来实现聚合，如下例子所示。考虑一个包含source,processor 和 sink的工程，它们可以示包含在工程中，或者包含在工程的依赖中。 1234567891011@SpringBootApplication@EnableBinding(Sink.class)public class SinkApplication &#123; private static Logger logger = LoggerFactory.getLogger(SinkModuleDefinition.class); @ServiceActivator(inputChannel=Sink.INPUT) public void loggerSink(Object payload) &#123; logger.info("Received: " + payload); &#125;&#125;1234567891011 123456789@SpringBootApplication@EnableBinding(Processor.class)public class ProcessorApplication &#123; @Transformer public String loggerSink(String payload) &#123; return payload.toUpperCase(); &#125;&#125;123456789 12345678910@SpringBootApplication@EnableBinding(Source.class)public class SourceApplication &#123; @Bean @InboundChannelAdapter(value = Source.OUTPUT) public String timerMessageSource() &#123; return new SimpleDateFormat().format(new Date()); &#125;&#125;12345678910 每一个配置可用于运行一个独立的组件，在这个例子中，它们可以这样实现聚合： 12345678910@SpringBootApplicationpublic class SampleAggregateApplication &#123; public static void main(String[] args) &#123; new AggregateApplicationBuilder() .from(SourceApplication.class).args("--fixedDelay=5000") .via(ProcessorApplication.class) .to(SinkApplication.class).args("--debug=true").run(args); &#125;&#125;12345678910 序列的开始组件被提供作为from()方法的参数，序列的结束组件被提供作为to()方法的参数，中间处理器组件则作为via()方法的参数。同一类型的多个processors可以链在一起（例如，可以使用不同配置的管道传输方式）。对于每一个组件，编译器可以为Spring Boot 提供运行时参数。 3.1.6RxJava支持 4.绑定器（Binders）Spring Cloud Stream提供绑定抽象用于与外部中间件中的物理目标进行连接。本章主要介绍Binder SPI背后的主要概念，主要组件以及实现细节。 4.1生产者和消费者任何往通道中发布消息的组件都可称作生产者。通道可以通过代理的Binder实现与外部消息代理进行绑定。调用bindProducer()方法，第一个参数是代理名称，第二个参数是生产者向其中发送消息的本地通道目标名称，第三个参数包含通道创建的适配器的属性信息（比如：分片key表达式）。任何从通道中接收消息的组件都可称作消费者。与生产者一起，消费者通道可以与外部消息代理进行绑定。调用bindConsumer()方法，第一个参数是目标名称，第二个参数提供了消费者逻辑组的名称。]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈 Spring Cloud]]></title>
    <url>%2F2017%2F11%2F13%2F%E6%B5%85%E8%B0%88-Spring-Cloud%2F</url>
    <content type="text"><![CDATA[背景2008年以后，国内互联网行业飞速发展，我们对软件系统的需求已经不再是过去”能用就行”这种很low的档次了，像抢红包、双十一这样的活动不断逼迫我们去突破软件系统的性能上限，传统的IT企业”能用就行”的开发思想已经不能满足互联网高并发、大流量的性能要求。系统架构走向分布式已经是服务器开发领域解决该问题唯一的出路，然而分布式系统由于天生的复杂度，并不像开发单体应用一样把框架一堆就能搞定，因此各大互联网公司都在投入技术力量研发自己的基础设施。这里面比较有名的如阿里的开源项目dubbo, Netflix开发的一系列服务框架。在这种“百花齐放”、重复造轮子的状况下，必然要出现一种统一的标准来简化分布式系统的开发，Spring Cloud应运而生。 Spring Cloud是什么SpringCloud架构Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 Spring Cloud正是对Netflix的多个开源组件进一步的封装而成，同时又实现了和云端平台，和Spring Boot开发框架很好的集成。 Spring Cloud是一个相对比较新的微服务框架，2016年才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。 Spring Cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。 Spring Cloud组成 Spring Cloud的子项目，大致可分成两类，一类是对现有成熟框架”Spring Boot化”的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色。对于我们想快速实践微服务的开发者来说，第一类子项目就已经足够使用，如：Spring Cloud Netflix，是对Netflix开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST客户端、请求路由等。该项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。 通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。 Spring Cloud Eureka 服务发现服务中心，云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是SpringCloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。 Spring Cloud Eureka提供在分布式环境下的服务发现，服务注册的功能。 一个RESTful服务，用来定位运行在AWS地区（Region）中的中间层服务。由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 Spring Cloud Ribbon 客户端负载均衡Ribbon，主要提供客户侧的软件负载均衡算法。 Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略： 简单轮询负载均衡 加权响应时间负载均衡 区域感知轮询负载均衡 随机负载均衡 Ribbon中还包括以下功能： 易于与服务发现组件（比如Netflix的Eureka）集成 使用Archaius完成运行时配置 使用JMX暴露运维指标，使用Servo发布 多种可插拔的序列化选择 异步和批处理操作（即将推出） 自动SLA框架（即将推出） 系统管理/指标控制台（即将推出） Spring Cloud Config俗称的配置中心，配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。就是以后大家武器、枪火什么的东西都集中放到一起，别随便自己带，方便以后统一管理、升级装备。 将配置信息中央化保存, 配置Spring Cloud Bus可以实现动态修改配置文件。这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。 Spring Cloud Config就是我们通常意义上的配置中心。Spring Cloud Config-把应用原本放在本地文件的配置抽取出来放在中心服务器，本质是配置信息从本地迁移到云端。从而能够提供更好的管理、发布能力。 Spring Cloud Config分服务端和客户端，服务端负责将git（svn）中存储的配置文件发布成REST接口，客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化，从而主动去获取新的配置，这需要每个客户端通过POST方法触发各自的/refresh。 Spring cloud Hystrix 熔断器熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。 断路器(Cricuit Breaker)是一种能够在远程服务不可用时自动熔断(打开开关)，并在远程服务恢复时自动恢复(闭合开关)的设施，Spring Cloud通过Netflix的Hystrix组件提供断路器、资源隔离与自我修复功能。断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正，应用程序可以尝试调用操作。 断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。 Spring Cloud Zuul 服务网关，智能路由Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。 类似Nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。 Spring Netflix Archaius配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置， 原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。 Spring Cloud Bus事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。相当于水浒传中日行八百里的神行太保戴宗，确保各个小弟之间消息保持畅通。分布式消息队列，是对Kafka, MQ的封装；事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。 Spring cloud bus被国内很多都翻译为消息总线，也挺形象的。大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。 Spring Cloud Bus做配置更新的步骤: 提交代码触发post给客户端A发送bus/refresh客户端A接收到请求从Server端更新配置并且发送给Spring Cloud BusSpring Cloud bus接到消息并通知给其它客户端其它客户端接收到通知，请求Server端获取最新配置全部客户端均获取到最新的配置 Spring Cloud Security对Spring Security的封装，并能配合Netflix使用，安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 基于spring security的安全工具包，为你的应用程序添加安全控制。这个小弟很牛鼻专门负责整个帮派的安全问题，设置不同的门派访问特定的资源，不能把秘籍葵花宝典泄漏了。 Spring Cloud Zookeeper对Zookeeper的封装，使之能配置其它Spring Cloud的子项目使用；操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理，抱了Zookeeper的大腿。 Spring Cloud Stream数据流；数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的／工业级spring应用，使用spring integration提供与消息代理之间的连接。数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 一个业务会牵扯到多个任务，任务之间是通过事件触发的，这就是Spring Cloud stream要干的事了。 Spring Cloud Sleuth服务跟踪；日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。 Spring Cloud Feign 使用HTTP请求远程服务在Spring Cloud Netflix栈中，各个微服务都是以HTTP接口的形式暴露自身服务的，因此在调用远程服务时就必须使用HTTP客户端。我们可以使用JDK原生的URLConnection、Apache的Http Client、Netty的异步HTTP Client, Spring的RestTemplate。但是，用起来最方便、最优雅的还是要属Feign了。 Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。 通过Feign， 我们能把HTTP远程调用对开发者完全透明，得到与调用本地方法一致的编码体验。这一点与阿里Dubbo中暴露远程服务的方式类似，区别在于Dubbo是基于私有二进制协议，而Feign本质上还是个HTTP客户端。如果是在用Spring Cloud Netflix搭建微服务，那么Feign无疑是最佳选择。 Spring Cloud for Cloud FoundryCloud Foundry是VMware推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题 其实就是与CloudFoundry进行集成的一套解决方案，抱了Cloud Foundry的大腿。 Spring Cloud ClusterSpring Cloud Cluster将取代Spring Integration。提供在分布式系统中的集群所需要的基础功能支持，如：选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现。 如果把不同的帮派组织成统一的整体，Spring Cloud Cluster已经帮你提供了很多方便组织成统一的工具。 Spring Cloud ConsulConsul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件,由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源. Consul 支持健康检查,并允许 HTTP 和 DNS 协议调用 API 存储键值对. Spring Cloud Consul 封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Data FlowData flow 是一个用于开发和执行大范围数据处理其模式包括ETL，批量运算和持续运算的统一编程模型和托管服务。 对于在现代运行环境中可组合的微服务程序来说，Spring Cloud data flow是一个原生云可编配的服务。使用Spring Cloud data flow，开发者可以为像数据抽取，实时分析，和数据导入/导出这种常见用例创建和编配数据通道 （data pipelines）。 Spring Cloud data flow 是基于原生云对 spring XD的重新设计，该项目目标是简化大数据应用的开发。Spring XD 的流处理和批处理模块的重构分别是基于 spring boot的stream 和 task/batch 的微服务程序。这些程序现在都是自动部署单元而且他们原生的支持像 Cloud Foundry、Apache YARN、Apache Mesos和Kubernetes 等现代运行环境。 Spring Cloud data flow 为基于微服务的分布式流处理和批处理数据通道提供了一系列模型和最佳实践。 Spring Cloud TaskSpring Cloud Task 主要解决短命微服务的任务管理，任务调度的工作，比如说某些定时任务晚上就跑一次，或者某项数据分析临时就跑几次。 Spring Cloud ConnectorsSpring Cloud Connectors 简化了连接到服务的过程和从云平台获取操作的过程，有很强的扩展性，可以利用Spring Cloud Connectors来构建你自己的云平台。 便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。 Spring Cloud StartersSpring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。 Spring Cloud CLI基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Netflix TurbineTurbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。 和Spring Boot 是什么关系Spring boot 是 Spring 的一套快速配置脚手架，可以基于spring boot 快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring boot专注于快速、方便集成的单个个体，Spring Cloud是关注全局的服务治理框架；spring boot使用了默认大于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置，Spring Cloud很大的一部分是基于Spring boot来实现,可以不基于Spring boot吗？不可以。 Spring boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring boot，属于依赖的关系。 Spring -&gt; Spring Boot &gt; Spring Cloud 这样的关系。 Spring Cloud的优势微服务的框架那么多比如：dubbo、Kubernetes，为什么就要使用Spring Cloud的呢？ 产出于Spring大家族，Spring在企业级开发框架中无人能敌，来头很大，可以保证后续的更新、完善。比如dubbo现在就差不多死了有Spring Boot 这个独立干将可以省很多事，大大小小的活spring boot都搞的挺不错。 作为一个微服务治理的大家伙，考虑的很全面，几乎服务治理的方方面面都考虑到了，方便开发开箱即用。Spring Cloud 活跃度很高，教程很丰富，遇到问题很容易找到解决方案轻轻松松几行代码就完成了熔断、均衡负责、服务中心的各种平台功能Spring Cloud 也有一个缺点，只能使用Java开发,不适合小型独立的项目。 个人总结上面的一些组件介绍是综合了网上给出的介绍和自己的一些理解来写的,在实际工作中也用到了大多的组件。后续会结合自己的使用情况来总结每个组件的详细内容以及具体的使用情况。 ##]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
</search>
