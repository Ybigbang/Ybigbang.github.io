<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker搭建redis集群]]></title>
    <url>%2F2017%2F11%2F15%2Fdocker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[docker 构建 redis 集群由于最近项目用到redis,考虑到redis的高可用故用docker搭建redis集群镜像。把原先散落各处的redis服务器统一管理起来，并且保障高可用和故障自动迁移。 redis 集群分类:大家都知道redis集群有两种，一种是redis sentinel，高可用集群，同时只有一个master，各实例数据保持一致；一种是redis cluster，分布式集群，同时有多个master，数据分片部署在各个master上。基于我们的需求和redis本身技术的成熟度，本次要搭建的是redis sentinel。 关于它的介绍： Redis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下四个任务： 不时地监控redis是否按照预期良好地运行 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave 的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的 新地址。 哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 制作镜像整个集群可以分为一个master，N个slave，M个sentinel，本次以2个slave和3个sentinel为例： 增加redis.conf 12345678910##redis.conf##redis-0,默认为masterport $redis_port##授权密码，请各个配置保持一致##暂且禁用指令重命名##rename-command##开启AOF，禁用snapshotappendonly yes#slaveof redis-master $master_port #redis-master master主机域名slave-read-only yes 增加sentinel.conf 1234567port $sentinel_portdir "/tmp"sentinel monitor mymaster redis-master $master_port 2##选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。sentinel config-epoch mymaster 1sentinel leader-epoch mymaster 1sentinel current-epoch 1 增加启动脚本，根据入参判断启动master，slave，sentinel 123456789101112131415161718192021cd /dataredis_role=$1echo $redis_roleif [ $redis_role = "master" ] ; then echo "master" sed -i "s/\$redis_port/$redis_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "slave" ] ; then echo "slave" sed -i "s/\$redis_port/$redis_port/g" redis.conf sed -i "s/#slaveof/slaveof/g" redis.conf sed -i "s/\$master_port/$master_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "sentinel" ] ; then echo "sentinel" sed -i "s/\$sentinel_port/$sentinel_port/g" sentinel.conf sed -i "s/\$master_port/$master_port/g" sentinel.conf redis-sentinel /data/sentinel.confelse echo "unknow role!" fi #ifend 其中$redis_port和$master_port,$sentinel_port都是取自环境变量，通过Docker启动时候传入。 编写Dockerfile 123456789FROM redis:3-alpineMAINTAINER yanhl &lt;yanhl&gt;COPY redis.conf /data/redis.confCOPY sentinel.conf /data/sentinel.confCOPY start.sh /data/start.shRUN chmod +x /data/start.shRUN chown redis:redis /data/*ENTRYPOINT ["sh","/data/start.sh"] CMD ["master"] 选取redis-alpine镜像作为基础镜像，因为它非常小，只有9M，修改时区和把一些配置拷贝进去后，变更下权限和用户组，因为基础镜像是redis用户组。ENTRYPOINT和CMD组合，默认以master方式启动。build完成后，镜像只有15M。 启动采用docker-compose格式： 12345678910111213141516171819202122232425262728293031323334353637redis-master-host: environment: redis_port: '16379' labels: io.rancher.container.pull_image: always tty: true image: #镜像id stdin_open: true net: hostredis-slaves: environment: master_port: '16379' redis_port: '16380' labels: io.rancher.scheduler.affinity:container_label_soft_ne: name=slaves io.rancher.container.pull_image: always name: slaves tty: true command: - slave image: #镜像id stdin_open: true net: hostredis-sentinels: environment: master_port: '16379' sentinel_port: '16381' labels: io.rancher.container.pull_image: always name: sentinels io.rancher.scheduler.affinity:container_label_ne: name=sentinels tty: true command: - sentinel image: #镜像id stdin_open: true net: host 首先启动master，传入端口16379，host模式，在启动slave，成为16379 master 的slave，并且设置调度策略为尽可能分散的方式，sentinels也类似。 测试启动 redis集群： java访问redis 123456789@Test public void test() throws Exception &#123; // 保存字符串 int i=0; while (true) &#123; stringRedisTemplate.opsForValue().set("a" + i, "111"); i++; &#125; &#125; 此时停掉一台哨兵 可以正常存储 1redis.clients.jedis.JedisSentinelPool : Lost connection to Sentinel at 192.168.99.100:16383. Sleeping 5000ms and retrying. 停掉所有哨兵 1Invocation of init method failed; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: All sentinels down, cannot determine where is mymaster master is running... 停掉一台slave 其中一台哨兵日志 1237:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.954 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.795 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 16379 重新启动会重新从主服务器加载数据 1234567891011121314151617181920218:S 15 Nov 13:00:04.461 * DB loaded from append only file: 0.619 seconds8:S 15 Nov 13:00:04.461 * The server is now ready to accept connections on port 163818:S 15 Nov 13:00:04.461 * Connecting to MASTER 192.168.99.100:163798:S 15 Nov 13:00:04.461 * MASTER &lt;-&gt; SLAVE sync started8:S 15 Nov 13:00:04.461 * Non blocking connect for SYNC fired the event.8:S 15 Nov 13:00:04.461 * Master replied to PING, replication can continue...8:S 15 Nov 13:00:04.461 * Partial resynchronization not possible (no cached master)8:S 15 Nov 13:00:04.468 * Full resync from master: 6cc2e4e7bbb4680ac0a8d9f7e5390f96eb1b1d76:384084118:S 15 Nov 13:00:05.291 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master8:S 15 Nov 13:00:05.314 * MASTER &lt;-&gt; SLAVE sync: Flushing old data8:S 15 Nov 13:00:05.354 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory8:S 15 Nov 13:00:06.422 * MASTER &lt;-&gt; SLAVE sync: Finished with success8:S 15 Nov 13:00:06.424 * Background append only file rewriting started by pid 118:S 15 Nov 13:00:07.703 * AOF rewrite child asks to stop sending diffs.11:C 15 Nov 13:00:07.703 * Parent agreed to stop sending diffs. Finalizing AOF...11:C 15 Nov 13:00:07.703 * Concatenating 0.00 MB of AOF diff received from parent.11:C 15 Nov 13:00:07.703 * SYNC append only file rewrite performed11:C 15 Nov 13:00:07.703 * AOF rewrite: 8 MB of memory used by copy-on-write8:S 15 Nov 13:00:07.739 * Background AOF rewrite terminated with success8:S 15 Nov 13:00:07.740 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)8:S 15 Nov 13:00:07.740 * Background AOF rewrite finished successfully 挂掉master 哨兵日志 哨兵会投票重新选取master 12345678910111213141516177:X 15 Nov 12:41:31.885 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.7:X 15 Nov 12:41:31.887 # Sentinel ID is 558ea99046801b4451dd49945d405f63e125f11e7:X 15 Nov 12:41:31.887 # +monitor master mymaster 192.168.99.100 16379 quorum 27:X 15 Nov 12:41:31.887 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.929 * +sentinel sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.922 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.809 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.517 * +reboot slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.584 # -sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.005 # +sdown master mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.119 # +new-epoch 27:X 15 Nov 13:04:19.119 # +vote-for-leader 8acf7f07765409e85e932c3baea249537f24f94c 27:X 15 Nov 13:04:19.611 # +config-update-from sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.611 # +switch-master mymaster 192.168.99.100 16379 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16379 192.168.99.100 16379 @ mymaster 192.168.99.100 16381 启动master 发现成为了一个从服务器 1234567891011121314151617181920212223242526276:M 15 Nov 13:08:18.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.6:M 15 Nov 13:08:18.767 # Server started, Redis version 3.2.116:M 15 Nov 13:08:18.767 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.6:M 15 Nov 13:08:18.767 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.6:M 15 Nov 13:08:21.409 * DB loaded from append only file: 2.642 seconds6:M 15 Nov 13:08:21.409 * The server is now ready to accept connections on port 163796:S 15 Nov 13:08:28.852 * SLAVE OF 192.168.99.100:16381 enabled (user request from 'id=2 addr=192.168.99.100:59528 fd=8 name= age=10 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')6:S 15 Nov 13:08:28.853 # CONFIG REWRITE executed with success.6:S 15 Nov 13:08:29.457 * Connecting to MASTER 192.168.99.100:163816:S 15 Nov 13:08:29.457 * MASTER &lt;-&gt; SLAVE sync started6:S 15 Nov 13:08:29.457 * Non blocking connect for SYNC fired the event.6:S 15 Nov 13:08:29.458 * Master replied to PING, replication can continue...6:S 15 Nov 13:08:29.458 * Partial resynchronization not possible (no cached master)6:S 15 Nov 13:08:29.463 * Full resync from master: 8cf78a3d6fe25eb719901e129627cc5f7556c6d4:525026:S 15 Nov 13:08:30.107 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master6:S 15 Nov 13:08:30.136 * MASTER &lt;-&gt; SLAVE sync: Flushing old data6:S 15 Nov 13:08:30.573 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory6:S 15 Nov 13:08:31.579 * MASTER &lt;-&gt; SLAVE sync: Finished with success6:S 15 Nov 13:08:31.581 * Background append only file rewriting started by pid 96:S 15 Nov 13:08:32.494 * AOF rewrite child asks to stop sending diffs.9:C 15 Nov 13:08:32.495 * Parent agreed to stop sending diffs. Finalizing AOF...9:C 15 Nov 13:08:32.495 * Concatenating 0.00 MB of AOF diff received from parent.9:C 15 Nov 13:08:32.495 * SYNC append only file rewrite performed9:C 15 Nov 13:08:32.496 * AOF rewrite: 2 MB of memory used by copy-on-write6:S 15 Nov 13:08:32.584 * Background AOF rewrite terminated with success6:S 15 Nov 13:08:32.584 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)6:S 15 Nov 13:08:32.584 * Background AOF rewrite finished successfully 测试通过。]]></content>
      <categories>
        <category>docker</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-stream-rabbitmq]]></title>
    <url>%2F2017%2F11%2F14%2Fspring-cloud-stream-rabbitmq%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 使用 rabbitmq 在使用spring cloud 构建微服务的时候用到的消息队列rabbitmq 综合了一下感觉用spring cloud stream 整合比较简单后期如果更换其它消息队列也比较简单 spring cloud stream 整合rabbitmq 概述 Spring Cloud Stream（以下简称SCS）是一个用于构建消息驱动微服务的框架。简单来说，通过SCS我们可以快速地在微服务之间传递异步消息，这对于一些刚起步时需求简单的消息应用是很方便的。 入门尽管很方便，但必要的准备工作还是要做的。SCS本身并不提供消息服务器，因此我们还是要安装像RabbitMQ或Kafka这样的消息服务器，本文会使用RabbitMQ来做讲解，具体如何安装Erlang和RabbitMQ这里不再赘述。安装好以后可以暂时不对RabbitMQ做配置。但要记得运行rabbitmq-plugins enable rabbitmq_management来激活管理平台以方便后续使用 。 生产者创建一个rabbitmq-producer微服务，默认端口8080 创建一个接口作为通道，举例： 123456789//生产者//创建一个rabbitmq-producer微服务，默认端口8080；//创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String OUTPUT = "test"; @Output(OUTPUT) MessageChannel output();&#125; @Output注解代表这是一个输出通道，而通道名就是我们定义的test，一个接口中可以定义多个输入和输出通道。实际上SCS本身提供了三个预定义接口通道，即Source.class单向输出通道，Sink.class单向输入通道，以及继承了它们两个的Processor.class，你可以在源码org.springframework.cloud.stream.messaging包中找到它们。但它们都只是简单示例，真正开发时我们肯定还是要自定义接口作为通道； 1234567891011121314151617//创建用于发送消息的接口（或直接在启动类中编写）：@RestController@EnableBinding(MyChannel.class)public class SendController &#123; @Autowired private MyChannel sender; @RequestMapping("/send") public String send()&#123; try &#123; sender.output().send(MessageBuilder.withPayload("Hello World").build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125; &#125;&#125; 需要注意的是，@EnableBinding注解是必须要加的（即使你只使用JUnit测试），但并不是必须添加在启动类上，其实你可以把它放在任何一个Spring能够扫描到的类。但为了方便查找，还是推荐放在启动类或者消息类上。 生产者至此告一段落，接下来我们看一下消费者。 消费者 12345678//创建一个consumer微服务，为防止与生产者冲突，端口号设为8081；//和生产者一样，创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String INPUT = "test"; @Input(INPUT) SubscribableChannel input();&#125; @Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息，因此我们也定义为test； 创建用于接收消息的类（或直接在启动类中编写）： 12345678@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;String&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; @StreamListener注解用于监听通道，由于我们在生产者发送的是一个”Hello World”字符串，因此在这里我们用string来接收它，注意Message用的是org.springframework.messaging.Message；与生产者一样，在启动类上添加@EnableBinding(MyChannel.class)。 测试 首先启动消费者微服务，如果你激活了RabbitMQ管理平台，那么此时就可以在上面看到test通道的相关信息了，包括Exchange和Queue 访问消息提供者的接口 http://localhost:8082/send在监听方会有消息 修改配置 至此我们就完成了简单的消息发送与接收服务，是不是感觉很快就能起飞了呢？手动配置在开头我提到可以暂时不对RabbitMQ做配置，这是为了我们可以快速开发调试。但现实中我们不可能不去修改RabbitMQ的配置（哪怕只是改改密码，毕竟guest相当于裸奔），那么如何让SCS去匹配修改过的配置呢？单就YAML配置来说，有两种方式（使用@Configuration类做配置的朋友请自行对照）： 直接配置spring.rabbitmq，比如我使用另外一个用户连接 12345spring: rabbitmq: username: “用户名” password: ”密码“ virtual-host: /test 使用spring.cloud.stream.binders和spring.cloud.stream.bindings组合配置，同样是上面的情况： 123456789101112131415spring: cloud: stream: bindings: test: binder: rabbit binders: rabbit: type: rabbit environment: spring: rabbitmq: username: ”用户名“ password: ”密码“ virtual-host: /test 乍一看感觉好麻烦呀，而且environment下面的配置不就是上面spring.rabbitmq的配置吗？ 实际上这种写法是有它的好处的，首先我们注意到，binders里面可以配置不同环境的binder，而通过bindings我们可以把channel和binder绑定起来。 假设我这个微服务现在要连两个RabbitMQ，那么我们就可以这样配置： 1234567891011121314151617181920212223242526272829spring: cloud: stream: bindings: test1: binder: rabbit1 test2: binder: rabbit2 binders: rabbit1: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5672 username: password: virtual-host: /test1 rabbit2: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5673 username: password: virtual-host: /test2 注：spring.cloud.stream.bindings.里面有许多有用的配置，比如destination、group等等。” 进阶好了简单的消息发送与接收已经实现了 如何像消息队列传递一个对象呢？ 上一节中我们发送的消息是一个字符串，那如果我想发送POJO怎么办呢？是直接发送和接收就可以了吗？下面我们可以试验一下： 首先创建一个User POJO，然后修改生产者的send()方法： 12345678910111213@GetMapping("/send")public String send() &#123; try &#123; User user = new User(); user.setId("1"); user.setName("yhl"); sender.output().send(MessageBuilder.withPayload(user).build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125;&#125; 修改消费者sc-stream-consumer的receive()方法： 123456789@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;User&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; 访问send 结果 接收方接到了一个user对象 如果你的User是分别在生产者和消费者中定义的，并且包路径不同，那么会报错反序列化失败。原因是SCS会默认将POJO转换成二进制发送，并且携带包路径等信息； 如果生产者和消费者使用的User是同一定义，或分别定义但包路径相同，那么就不会报错。 看起来略微有点不爽，那么有没有别的转换方式呢？ 有，而且官方还提供了很多： 下面我会举例用JSON字符串来传递POJO，其实只要在生产者中加上一条配置即可： 123456spring cloud: stream: bindings: test: content-type: application/json 此时消费者sc-stream-consumer接收的消息实体实际上是字符串了，我们可以用Message来测试一下： 此时收到的就是json数据了 既然接收的是JSON字符串了，那Spring怎么可能不提供自动反射呢XD，再次把消息实体换回User就行了。 负载均衡实际生产中，我们一般都会启动多个消费者实例来做负载均衡，既然是负载均衡，我们肯定希望一条消息在一组负载均衡实例中只被其中一个消费者接收。那么SCS是如何处理这种情况的呢？ 假设我们现在已经启动了生产者和消费者实例各一个，然后再修改消费者的端口为8082，再启动一个消费者实例。 随后发送消息测试，我们会发现两个消费者实例都接收到了消息： 这显然不是我们希望的，那么现在就来分析一下为什么会出现这种情况。 关键点在headers中的amqp_consumerQueue这个属性上，我们看到8081和8082的amqp_consumerQueue前面都是test.anonymous，但后面却是不一样的。这其实表示他们被分到了不同的匿名组（即group），而同一条消息会被test中的每个组都接收到。这个也很好理解，我们把group比喻成现实中的公司各部门，现在我要发一个通知，我会发给所有的部门，但同一部门中只要有一个人收到了，我就认为这个部门收到了通知。 所以只要把要负载均衡的实例分在同一个group下就好了，我们给消费者添加如下配置： 123456spring: cloud: stream: bindings: test: group: yhl 有一个test.yhl 队列这时调用发送者会发现两个消费者循环接受消息。]]></content>
      <categories>
        <category>消息队列</category>
        <category>rabbitMq</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudStream]]></title>
    <url>%2F2017%2F11%2F14%2FSpringCloudStream%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 翻译 （还没翻译完） 原文地址： https://docs.spring.io/spring-cloud-stream/docs/current-SNAPSHOT/reference/htmlsingle/#_introducing_spring_cloud_stream 1.简介Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的工业级spring应用，使用spring integration提供与消息代理之间的连接。本文提供不同代理中的中间件配置，介绍了持久化发布订阅机制，以及消费组以及分割的概念。将注解@EnableBinding加到应用上就可以实现与消息代理的连接，@StreamListener注解加到方法上，使之可以接收处理流的事件。 1234567891011121314151617@SpringBootApplicationpublic class StreamApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamApplication.class, args); &#125;&#125;@EnableBinding(Sink.class)public class TimerSource &#123; ... @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125;123456789101112131415161718 @EnableBinding注解使用一个或者多个接口作为参数（本例子中，参数是单独的Sink接口）。接口声明了输入和／或输出通道。 Spring Cloud Stream提供了Source, Sink, 和 Processor三个接口；你也可以定义你自己的接口。下面是Sink接口的定义： 123456public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;123456 @Input注解定义了一个输入通道，应用通过该输入通道接收进入应用的消息；@Output注解定义了一个输出通道，发布的消息通过该通道离开应用。input和output注解可以使用通道名称作为参数；如果没有名称，会使用带注解的方法的名字作为参数（也就是说，如果没有定义单独的名字，这里的通道名就是方法名input）。Spring Cloud Stream会为你创建一个接口的实现(这里注意，一定要在application里面加上@EnableBinding注解，不然会出现自动注入失败，因为缺少这个注解的话stream就不会创建接口的实例)。你可以通过自动装配在应用中使用它，如下面测试用例所示： 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = StreamApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125;1234567891011121314 2.主要概念Spring Cloud Stream提供了很多抽象和基础组件来简化消息驱动型微服务应用。包含以下内容： Spring Cloud Stream的应用模型 绑定抽象 持久化发布／订阅支持 消费者组支持 分片支持（Partitioning Support） 可插拔绑定api 应用模型 2.1应用模型Spring Cloud Stream由一个中间件中立的核组成。应用通过Spring Cloud Stream插入的input和output通道与外界交流。通道通过指定中间件的Binder实现与外部代理连接。 2.1.1 胖JAR测试的话，Spring Cloud Stream可以在ide中运行一个单独的实例。在生产环境中，可以通过Maven 或者 Gradle提供的Spring Boot 工具创建可执行JAR（或者胖JAR）。 2.2绑定抽象Spring Cloud Stream提供对 Kafka, Rabbit MQ,Redis, 和 Gemfire的绑定实现。Spring Cloud Stream使用Spring Boot做配置，绑定抽象使得stream可以灵活的连接到中间件。比如，开发者可以在运行时动态的选择通道连接的目标（可以是kafka主题或者RabbitMQ 交换机）。该配置可以通过spring boot支持的任何配置形式实现。在sink的例子中，将属性spring.cloud.stream.bindings.input.destination设置为raw-sensor-data，程序会从命名为raw-sensor-data的kafka主题中读取数据，或者从一个绑定到raw-sensor-data的rabbitmq交换机的队列中读取数据（这里的input是通道名，raw-sensor-data则是exchange的名字，通过使用同一个名字，可以将输入输出通道进行绑定）。Spring Cloud Stream自动检测和使用在class path中找到的binder。可以在build的时候引入不同的binder来使用不同类型的中间件。更复杂的情况下，可以在应用中打包多个binder使之按需选择，甚至可以在运行时根据不同的通道选择不同的binder。 2.3持久化发布／订阅支持应用间通信遵照发布-订阅模型，消息通过共享主题进行广播。下图所示，显示了交互的Spring Cloud Stream 应用的典型布局。sensor传给http端点的数据传给名为raw-sensor-data的目标。发布订阅模型简化了生产者和消费者的复杂程度，并且新的应用可以在不对当前数据流造成影响的情况下加入到拓扑中。由于发布－订阅模型并非一个新的概念，Spring Cloud Stream将其作为应用模型中的可选项。通过使用原生中间件支持，Spring Cloud Stream也简化了不同平台之间使用发布－订阅模型的复杂程度。 2.4消费者组由于发布－订阅模型使得共享主题的应用之间连接更简便，创建给定应用的不同实例来进行弹性扩张的能力也同样重要。如果存在多个应用实例，那么同一应用的额不同实例便会成为相互竞争的消费者，其中应该只有一个实例处理给定消息。Spring Cloud Stream通过消费者组的概念给这种情况进行建模。每一个单独的消费者可以使用spring.cloud.stream.bindings.input.group属性来指定一个组名字。下图中展示的消费者们，这一属性被设置为spring.cloud.stream.bindings.input.group=hdfsWrite或者spring.cloud.stream.bindings.input.group=average。所有订阅给定目标的组都会收到发布消息的一个拷贝，但是每一个组内只有一个成员会收到该消息。默认情况下，如果没有指定组，Spring Cloud Stream 会将该应用指定给一个匿名的独立的单成员消费者组，后者与所有其他组都处于一个发布－订阅关系中。持久性与Spring Cloud Stream中的可选应用模型一样，消费者组订阅是持久的。也就是说，一个绑定的实现确保组的订阅者是持久的，一旦组中至少有一个成员创建了订阅，这个组就会收到消息，即使组中所有的应用都被停止了，组仍然会收到消息。注：自然情况下，匿名订阅者是非持久化的。对于某些绑定实现（如rabbitmq），可以创建非持久化（non－durable）组订阅。一般来说，将应用绑定到给定目标的时候，最好指定一个消费者组。扩展Spring Cloud Stream应用的时候，对于它的每一个输入绑定，都必须要指定一个消费者组。 这样可以防止应用实例收到重复的消息。（除非存在重复收到的需求，但实际上很少会有这样的需求）。 2.5分片支持（Partitioning Support）Spring Cloud Stream对给定应用的多个实例之间分隔数据予以支持。在分隔方案中，物理交流媒介（如：代理主题）被视为分隔成了多个片（partitions）。一个或者多个生产者应用实例给多个消费者应用实例发送消息并确保相同特征的数据被同一消费者实例处理。Spring Cloud Stream对分割的进程实例实现进行了抽象。因此分片可以用于自带分隔的代理（如kafka）或者不带分隔的代理（如rabbitmq）。分割在有状态处理中是一个很重要的概念，在性能和一致性上，分割都是重要的概念。例如，在时间窗平均计算的例子中，给定传感器测量结果应该都由同一应用实例进行计算。注：如果要设置分割处理方案，需要配置数据处理和数据消费端点。 3.编程模型这一部分描述Spring Cloud Stream的编程模型。Spring Cloud Stream提供很多预先定一的注解来声明约束输入和输出通道以及如何监听这些通道。 3.1声明和绑定通道3.1.1通过@EnableBinding触发绑定将@EnableBinding应用到spring应用的一个配置类中，可以将spring应用变成Spring Cloud Stream应用。@EnableBinding注解本身就包含@Configuration注解，并且会触发Spring Cloud Stream 基本配置。@EnableBinding注解可以接收一个或多个接口类作为对象，后者包含代表了可绑定构件（一般来说是消息通道）的方法。注：在Spring Cloud Stream1.0中，仅有的可绑定构件是Spring 消息 MessageChannel以及它的扩展SubscribableChannel 和 PollableChannel. 未来版本会使用相同的机制扩展对其他类型构件的支持。在本文档中，会继续饮用通道。3.1.2@Input 和 @Output一个Spring Cloud Stream应用可以有任意数目的input和output通道，后者通过@Input and @Output方法在进口中定义。 1234567891011public interface Barista &#123; @Input SubscribableChannel orders(); @Output MessageChannel hotDrinks(); @Output MessageChannel coldDrinks();&#125;1234567891011 将该接口作为@EnableBinding的参数，会相应的触发三个名为orders, hotDrinks, 和 coldDrinks的绑定好的通道。 12345@EnableBinding(Barista.class)public class CafeConfiguration &#123; ...&#125;12345 定制通道名字使用@Input 和 @Output注解，可以自己指定通道的名字，如下所示： 12345public interface Barista &#123; ... @Input("inboundOrders") SubscribableChannel orders();&#125;12345 这个例子中，创建的绑定队列会被命名为inboundOrders。Source, Sink, and Processor在大多数用例中，包含一个输入通道或者一个输出通道或者二者都包含，为了更简单的定位，Spring Cloud Stream创造性的提供了三个预定义的接口。Source用于有单个输出（outbound）通道的应用。 12345678public interface Source &#123; String OUTPUT = "output"; @Output(Source.OUTPUT) MessageChannel output();&#125;12345678 Sink用于有单个输入（inbound）通道的应用。 12345678public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;12345678 Processor用于单个应用同时包含输入和输出通道的情况。 12public interface Processor extends Source, Sink &#123;&#125;12 Spring Cloud Stream对这三个接口没有提供任何特殊处理。他们只是用于创造性的提供。 3.1.3访问绑定通道 1.注入已绑定接口对于每一个已绑定的接口， Spring Cloud Stream会生成一个bean实现该接口。唤起这些由@Input或者 @Output注解的方法生成的bean，其中一个bean会返回相应的通道。下面例子中，当hello方法被唤起的时候，bean会在output通道上发送一个消息。在注入的Source bean上提供唤醒output()来检索到目标通道。 1234567891011121314@Componentpublic class SendingBean &#123; private Source source; @Autowired public SendingBean(Source source) &#123; this.source = source; &#125; public void sayHello(String name) &#123; source.output().send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 2.直接注入到通道绑定的通道也可以直接注入。 1234567891011121314@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; output.send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 如果通道名称是在声明的注解上指定的，则不能使用方法名称，而要使用通道名称。举例如下： 12345public interface CustomSource &#123; ... @Output("customOutput") MessageChannel output();&#125;12345 通道会按照下面方式注入： 123456789101112131415@Componentpublic class SendingBean &#123; @Autowired private MessageChannel output; @Autowired @Qualifier("customOutput") public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; customOutput.send(MessageBuilder.withPayload(body).build()); &#125;&#125;123456789101112131415 3.1.4生产和消费消息 可以使用Spring Integration 的注解或者Spring Cloud Stream的 @StreamListener 注解来实现一个Spring Cloud Stream应用。@StreamListener注解模仿其他spring消息注解（例如@MessageMapping, @JmsListener, @RabbitListener等），但是它增加了内容类型管理和类型强制特性。1.原生Spring Integration支持因为 Spring Cloud Stream是基于Spring Integration构建，Stream完全继承了Integration的基础设施以及构件本身。例如，可以将Source的output通道连接到一个MessageSource： 123456789101112@EnableBinding(Source.class)public class TimerSource &#123; @Value("$&#123;format&#125;") private String format; @Bean @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay = "$&#123;fixedDelay&#125;", maxMessagesPerPoll = "1")) public MessageSource&lt;String&gt; timerMessageSource() &#123; return () -&gt; new GenericMessage&lt;&gt;(new SimpleDateFormat(format).format(new Date())); &#125;&#125;123456789101112 或者可以在transformer中使用处理器的通道。 1234567@EnableBinding(Processor.class)public class TransformProcessor &#123; @Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT) public Object transform(String message) &#123; return message.toUpper(); &#125;&#125;1234567 2.使用 @StreamListener进行自动内容类型处理作为原生Spring Integration的补充，Spring Cloud Stream提供了自己的@StreamListener注解，该注解模仿spring的其它消息注解（如@MessageMapping, @JmsListener, @RabbitListener等）。@StreamListener注解提供了一种更简单的模型来处理输入消息，尤其是处理包含内容类型管理和类型强制的用例的情况。Spring Cloud Stream提供了一个扩展的MessageConverter机制，该机制提供绑定通道实现数据处理，本例子中，数据会分发给带@StreamListener注解的方法。下面例子展示了处理外部Vote事件的应用： 1234567891011@EnableBinding(Sink.class)public class VoteHandler &#123; @Autowired VotingService votingService; @StreamListener(Sink.INPUT) public void handle(Vote vote) &#123; votingService.record(vote); &#125;&#125;1234567891011 在输入消息内容头为application/json的情况下，@StreamListener和Spring Integration的@ServiceActivator之间会体现出差异。使用@StreamListener的情况下，MessageConverter机制会使用contentType头将string负载解析为Vote对象（也就是如果传输的是对象，应该选用@StreamListener注解）。在其它Spring Messaging方法中，消息机制可以使用@Payload, @Headers 和 @Header这些注解。 注：对于那些有返回数据的方法，必须使用@SendTo注解来指定返回数据的输出绑定目标。 123456789101112@EnableBinding(Processor.class)public class TransformProcessor &#123; @Autowired VotingService votingService; @StreamListener(Processor.INPUT) @SendTo(Processor.OUTPUT) public VoteResult handle(Vote vote) &#123; return votingService.record(vote); &#125;&#125;123456789101112 注：在RabbitMQ中，内容类型头可以由外部应用设定。 3.1.5聚合Aggregation Spring Cloud Stream可以支持多种应用的聚合，可以实现多种应用输入输出通道直接连接，而无需额外代价。在1.0版本中，只有以下类型应用支持聚合： sources：带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Source sinks：带有名为input的单一输入通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Sink processors：带有名为input的单一输入通道和带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定type org.springframework.cloud.stream.messaging.Processor. 可以通过创建一系列相互连接的应用将它们聚合到一起，其中，序列中一个元素的输出通道与下一个元素的输入通道连接在一起。序列可以由一个cource或者一个processor开始，可以包含任意数目的processors，并由processors或者sink结束。取决于开始和结束元素的特性，序列可以有一个或者多个可绑定的通道，如下： 如果序列由source开始，sink结束，应用之间直接通信并且不会绑定通道 如果序列由processor开始，它的输入通道会变成聚合的input通道并进行相应的绑定 如果序列由processor结束，它的输出通道会变成聚合的output通道并进行相应的绑定 使用AggregateApplicationBuilder功能类来实现聚合，如下例子所示。考虑一个包含source,processor 和 sink的工程，它们可以示包含在工程中，或者包含在工程的依赖中。 1234567891011@SpringBootApplication@EnableBinding(Sink.class)public class SinkApplication &#123; private static Logger logger = LoggerFactory.getLogger(SinkModuleDefinition.class); @ServiceActivator(inputChannel=Sink.INPUT) public void loggerSink(Object payload) &#123; logger.info("Received: " + payload); &#125;&#125;1234567891011 123456789@SpringBootApplication@EnableBinding(Processor.class)public class ProcessorApplication &#123; @Transformer public String loggerSink(String payload) &#123; return payload.toUpperCase(); &#125;&#125;123456789 12345678910@SpringBootApplication@EnableBinding(Source.class)public class SourceApplication &#123; @Bean @InboundChannelAdapter(value = Source.OUTPUT) public String timerMessageSource() &#123; return new SimpleDateFormat().format(new Date()); &#125;&#125;12345678910 每一个配置可用于运行一个独立的组件，在这个例子中，它们可以这样实现聚合： 12345678910@SpringBootApplicationpublic class SampleAggregateApplication &#123; public static void main(String[] args) &#123; new AggregateApplicationBuilder() .from(SourceApplication.class).args("--fixedDelay=5000") .via(ProcessorApplication.class) .to(SinkApplication.class).args("--debug=true").run(args); &#125;&#125;12345678910 序列的开始组件被提供作为from()方法的参数，序列的结束组件被提供作为to()方法的参数，中间处理器组件则作为via()方法的参数。同一类型的多个processors可以链在一起（例如，可以使用不同配置的管道传输方式）。对于每一个组件，编译器可以为Spring Boot 提供运行时参数。 3.1.6RxJava支持 4.绑定器（Binders）Spring Cloud Stream提供绑定抽象用于与外部中间件中的物理目标进行连接。本章主要介绍Binder SPI背后的主要概念，主要组件以及实现细节。 4.1生产者和消费者任何往通道中发布消息的组件都可称作生产者。通道可以通过代理的Binder实现与外部消息代理进行绑定。调用bindProducer()方法，第一个参数是代理名称，第二个参数是生产者向其中发送消息的本地通道目标名称，第三个参数包含通道创建的适配器的属性信息（比如：分片key表达式）。任何从通道中接收消息的组件都可称作消费者。与生产者一起，消费者通道可以与外部消息代理进行绑定。调用bindConsumer()方法，第一个参数是目标名称，第二个参数提供了消费者逻辑组的名称。]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈 Spring Cloud]]></title>
    <url>%2F2017%2F11%2F13%2F%E6%B5%85%E8%B0%88-Spring-Cloud%2F</url>
    <content type="text"><![CDATA[spring cloud 简介 Spring Cloud为开发者们提供了快速构建分布式系统中一些常见模式的工具（例如：配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性token、全局锁、决策者竞选、分布式会话、集群状态等等）。分布式系统的协作产生了诸多标准模式，在Spring Cloud的帮助下，开发者能够快速地构建起实现了这些模式的服务与应用。它们在任何分布式环境中都能运行良好，包括在开发者自己的笔记本电脑、裸机数据中心以及像Cloud Foundry这样的托管平台。 特性Spring Cloud专注于为典型用例和可扩展机制提供良好的开箱即用体验。 分布式/版本化配置 服务注册与发现 路由 Service-to-service调用 负载均衡 断路器 全局锁 决策者竞选与集群状态 分布式消息传递 基础组件Spring Cloud Eureka eureka图 服务注册与调用 eureka集群高可用 服务中心，云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是springcloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。 Spring Cloud Ribbon ribbon 图标 spring cloud ribbon Ribbon，主要提供客户侧的软件负载均衡算法。 Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略： 简单轮询负载均衡 加权响应时间负载均衡 区域感知轮询负载均衡 随机负载均衡 Ribbon中还包括以下功能: 易于与服务发现组件（比如Netflix的Eureka）集成 使用Archaius完成运行时配置 使用JMX暴露运维指标，使用Servo发布 多种可插拔的序列化选择 异步和批处理操作（即将推出） 自动SLA框架（即将推出） 系统管理/指标控制台（即将推出) ​ ​]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
</search>
