<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spring-cloud-sleuth集成Zipkin]]></title>
    <url>%2F2017%2F12%2F24%2Fspring-cloud-sleuth%E9%9B%86%E6%88%90Zipkin%2F</url>
    <content type="text"><![CDATA[spring cloud sleuth 功能概述微服务架构是一个分布式架构，它按业务划分服务单元，一个分布式系统往往有很多个服务单元。由于服务单元数量众多，业务的复杂性，如果出现了错误和异常，很难去定位。主要体现在，一个请求可能需要调用很多个服务，而内部服务的调用复杂性，决定了问题难以定位。所以微服务架构中，必须实现分布式链路追踪，去跟进一个请求到底有哪些服务参与，参与的顺序又是怎样的，从而达到每个请求的步骤清晰可见，出了问题，很快定位。 举个例子，在微服务系统中，一个来自用户的请求，请求先达到前端A（如前端界面），然后通过远程调用，达到系统的中间件B、C（如负载均衡、网关等），最后达到后端服务D、E，后端经过一系列的业务逻辑计算最后将数据返回给用户。对于这样一个请求，经历了这么多个服务，怎么样将它的请求过程的数据记录下来呢？这就需要用到服务链路追踪。 Spring Cloud Sleuth采用的是Google的开源项目Dapper的专业术语。 Span：基本工作单元，发送一个远程调度任务 就会产生一个Span，Span是一个64位ID唯一标识的，Trace是用另一个64位ID唯一标识的，Span还有其他数据信息，比如摘要、时间戳事件、Span的ID、以及进度ID。 Trace：一系列Span组成的一个树状结构。请求一个微服务系统的API接口，这个API接口，需要调用多个微服务，调用每个微服务都会产生一个新的Span，所有由这个请求产生的Span组成了这个Trace。 Annotation：用来及时记录一个事件的，一些核心注解用来定义一个请求的开始和结束 。这些注解包括以下： cs - Client Sent -客户端发送一个请求，这个注解描述了这个Span的开始 sr - Server Received -服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳便可得到网络传输的时间。 ss - Server Sent （服务端发送响应）–该注解表明请求处理的完成(当请求返回客户端)，如果ss的时间戳减去sr时间戳，就可以得到服务器请求的时间。 cr - Client Received （客户端接收响应）-此时Span的结束，如果cr的时间戳减去cs时间戳便可以得到整个请求所消耗的时间。 Span和Trace在系统中与Zipkin注释一起显示的可视化： 每个音符的颜色表示一个跨度（7个spans - 从A到G）。如果你在注释中有这样的信息： 123Trace Id = XSpan Id = DClient Sent 这意味着，目前的跨度Trance-ID设置为X，Span-ID设置为d。它也发出了 Client Sent事件。 这就是spans父/子关系的可视化效果： 用Zipkin分布式跟踪总共有7个spans。如果你去Zipkin的traces ，你会看到这个数字在第二个trace： 但是，如果你选择一个特定的trace ，那么你会看到4个spans： 当选择一个特定的spans，你会看到合并spans。这意味着，如果有2个spans发送到Zipkin 有Server Received 和 Server Sent / Client Received 以及 Client Sent annotations ，那么他们将呈现为一个spans。 为什么在这种情况下，7和4spans有区别？ 2个spans来自http:/start。它具有Server Received (SR) 和 Server Sent (SS)注释。 2个spans 来自RPC调用从service1到service2到http:/foo端点。它具有 Client Sent (CS) and Client Received (CR) 注释在service1。它还具有 Server Received (SR) and Server Sent (SS) 注释在service2。物理上有2个spans ，但它们构成了与RPC调用相关的1个逻辑spans 。 2个spans 来自RPC调用从service2到service3到http:/bar端点。它具有Client Sent (CS) and Client Received (CR)注释在service2。它还具有 Server Received (SR) and Server Sent (SS) 注释service3。物理上有2个spans ，但它们构成了与RPC调用相关的1个逻辑spans 。 2个spans 来自RPC调用从service2到service4到http:/baz端点。它具有Client Sent (CS) and Client Received (CR) 注释在service2。它还具有 Server Received (SR) and Server Sent (SS) 注释service4。物理上有2个spans ，但它们构成了与RPC调用相关的1个逻辑跨度。 因此，如果我们算上物理spans ，我们有1个http:/start，2个从service1调用service2，2个service2 呼叫service3和2个service2调用service4。共有7个spans 。 从逻辑上看，我们可以看到Total Spans：4的信息，因为我们有1个与传入请求相关的跨度service1和3个与RPC调用相关的跨度。 可视化错误Zipkin允许你可视化你的踪迹中的错误。当抛出异常并且没有被捕获时，我们在Zipkin可以正确着色的跨度上设置适当的标签。您可以在轨迹列表中看到一条红色的span。那是因为抛出了一个异常。 如果你点击那个trace，你会看到一个类似的图片 然后，如果您点击其中一个跨度，您将看到以下内容 正如你所看到的，你可以很容易地看到一个错误的原因和整个堆栈跟踪相关的。 依赖分析Zipkin中的依赖关系图如下所示：]]></content>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-hystrix]]></title>
    <url>%2F2017%2F12%2F20%2Fspring-cloud-hystrix%2F</url>
    <content type="text"><![CDATA[hystrix 配置Execution(控制HystrixCommand.run()的执行策略)以下属性控制如何HystrixCommand.run())执行。 execution.isolation.strategy默认值：THREAD 该属性指示HystrixCommand.run()执行哪个隔离策略，以下两个选项之一： THREAD - 它在单独的线程上执行，并发请求受线程池中线程数的限制 SEMAPHORE - 它在调用线程上执行，并发请求受信号计数的限制 ​ 默认值 THREAD 可能的值 THREAD, SEMAPHORE 默认属性 hystrix.command.default.execution.isolation.strategy 实例属性 hystrix.command.HystrixCommandKey.execution.isolation.strategy 线程或信号量建议的设置是HystrixCommand使用线程隔离（THREAD）和HystrixObservableCommand使用信号量隔离（SEMAPHORE）来运行。 execution.isolation.thread.timeoutInMilliseconds该属性设置以毫秒为单位的时间，设置调用超时时间。超时Hystrix标记HystrixCommand为TIMEOUT，并执行回退逻辑。 默认值 1000 默认属性 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 实例属性 hystrix.command.*HystrixCommandKey*.execution.isolation.thread.timeoutInMilliseconds execution.timeout.enabled该属性指示HystrixCommand.run()执行是否应该有超时。 默认值 true 默认属性 hystrix.command.default.execution.timeout.enabled 实例属性 hystrix.command.HystrixCommandKey.execution.timeout.enabled execution.isolation.thread.interruptOnTimeout该属性指示HystrixCommand.run()在发生超时时是否应该中断执行。 默认值 false 默认属性 hystrix.command.default.execution.isolation.thread.interruptOnCancel 实例属性 hystrix.command.HystrixCommandKey.execution.isolation.thread.interruptOnCancel execution.isolation.thread.interruptOnCancel该属性指示HystrixCommand.run()在发生取消时是否应该中断执行。 默认值 false 默认属性 hystrix.command.default.execution.isolation.thread.interruptOnCancel 实例属性 hystrix.command.HystrixCommandKey.execution.isolation.thread.interruptOnCancel execution.isolation.semaphore.maxConcurrentRequests设置信号量隔离下HystrixCommand.run()方法允许的最大请求数，超过这个数后续请求将被拒绝。 当你选择一个信号量时，你使用的逻辑基本上和你选择线程池中添加多少个线程相同，但是信号量的开销要小得多，通常执行速度要快得多（亚毫秒） 信号量应该是整个容器（即Tomcat）线程池的一小部分，而不是全部或大部分，否则它不提供保护。 默认值 10 默认属性 hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 实例属性 hystrix.command.HystrixCommandKey.execution.isolation.semaphore.maxConcurrentRequests Fallback(设置当fallback降级发生时的策略)以下属性控制如何HystrixCommand.getFallback()执行。这些属性适用于ExecutionIsolationStrategy.THREAD和ExecutionIsolationStrategy.SEMAPHORE。 fallback.isolation.semaphore.maxConcurrentRequests该属性设置HystrixCommand.getFallback()方法允许从调用线程进行请求的最大数量。 如果命中最大并发限制，则随后的请求将被拒绝，并抛出异常，因为不可能检索到回退。 默认值 10 默认属性 hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests 实例属性 hystrix.command.HystrixCommandKey.fallback.isolation.semaphore.maxConcurrentRequests fallback.enabled默认值：true 设置发生故障时是否尝试呼叫fallback。 默认值 true 默认属性 hystrix.command.default.fallback.enabled 实例属性 hystrix.command.HystrixCommandKey.fallback.enabled Circuit Breaker(配置熔断的策略)断路器属性控制行为HystrixCircuitBreaker circuitBreaker.enabled是否启用断路器。 默认值 true 默认属性 hystrix.command.default.circuitBreaker.enabled 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.enabled circuitBreaker.requestVolumeThreshold该属性设置滚动窗口中将使断路器打开的最小请求数量。 例如，如果值是20，那么如果在滚动窗口中接收到19个请求（例如10秒的窗口），则即使所有19个请求都失败，断路器也不会打开。 默认值 20 默认属性 hystrix.command.default.circuitBreaker.requestVolumeThreshold 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.requestVolumeThreshold circuitBreaker.sleepWindowInMilliseconds该属性设置断路器打开的时间，拒绝请求，然后再次尝试确定断路器是否应再次闭合。 默认值 5000 默认属性 hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.sleepWindowInMilliseconds circuitBreaker.errorThresholdPercentage该属性设置错误百分比，在该值以上，电路应断开，并开始将请求短路到回退逻辑。 默认值 50 默认属性 hystrix.command.default.circuitBreaker.errorThresholdPercentage 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.errorThresholdPercentage circuitBreaker.forceOpen默认值：false 如果这个属性true强制断路器进入一个打开（跳闸）状态，在这个状态下它将拒绝所有的请求。 该属性优先circuitBreaker.forceClosed。 默认值 false 默认属性 hystrix.command.default.circuitBreaker.forceOpen 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.forceOpen circuitBreaker.forceClosed如果该属性true强制断路器进入关闭状态，在这种状态下，不管错误百分比如何，都将允许请求。 该circuitBreaker.forceOpen属性优先，所以如果它被设置为true这个属性什么也不做。 默认值 false 默认属性 hystrix.command.default.circuitBreaker.forceClosed 实例属性 hystrix.command.HystrixCommandKey.circuitBreaker.forceClosed Metrics(关于HystrixCommand执行需要的统计信息)Hystrix的Metrics中保存了当前服务的健康状况, 包括服务调用总次数和服务调用失败次数等. 根据Metrics的计数, 熔断器从而能计算出当前服务的调用失败率, 用来和设定的阈值比较从而决定熔断器的状态切换逻辑. 因此Metrics的实现非常重要. 以下属性与捕获指标HystrixCommand和HystrixObservableCommand执行相关。 metrics.rollingStats.timeInMilliseconds默认值：10000 该属性设置统计滚动窗口的持续时间，以毫秒为单位。 窗口被分成桶和“卷”这些增量。 例如，如果将此属性设置为10秒（10000），并显示十个1秒的存储桶，则下图显示了如何将新存储桶和旧存储桶关闭： 默认值 10000 默认属性 hystrix.command.default.metrics.rollingStats.timeInMilliseconds 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingStats.timeInMilliseconds metrics.rollingStats.numBuckets默认值：10 该属性设置滚动统计窗口分成的桶的数量。 设置的时候要注意，这个值必须能能被滚动窗口的持续时间整除否则会报错。 换句话说，10000/10是可以的，10000/20也是，但是10000/7不是。 默认值 10 可能的值 metric.rollingStats.timeInMilliseconds可以平分的任何值。结果应该是数百或数千毫秒的桶。 默认属性 hystrix.command.default.metrics.rollingStats.numBuckets 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingStats.numBuckets metrics.rollingPercentile.enabled默认值：true 设置执行时间是否被跟踪，并且计算各个百分比。如果他们被禁用，则所有汇总统计（平均值，百分位数）返回为-1。 默认值 true 默认属性 hystrix.command.default.metrics.rollingPercentile.enabled 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingPercentile.enabled metrics.rollingPercentile.timeInMilliseconds此属性设置滚动窗口的持续时间，在该窗口中保留执行时间以允许百分数计算（以毫秒为单位）。 默认值 60000 默认属性 hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingPercentile.timeInMilliseconds metrics.rollingPercentile.numBuckets该属性设置rollingPercentile窗口将被分成的桶的数量。 默认值 6 可能的值 metric.rollingPercentile.timeInMilliseconds可以被任何值均分。结果应该是数千毫秒的桶。 默认属性 hystrix.command.default.metrics.rollingPercentile.numBuckets 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingPercentile.numBuckets metrics.rollingPercentile.bucketSize该属性设置每个存储桶的最大执行次数。如果在执行期间执行更多的执行，他们将环绕并开始在桶的开头重写。 例如，如果存储区大小设置为100，并表示10秒的存储区窗口，但是在此期间发生500次执行，则只有最后100次执行将保留在该10秒存储区中。 如果增加这个大小，这也增加了存储值所需的内存量，并增加了对列表进行排序以进行百分比计算所需的时间。 默认值 100 默认属性 hystrix.command.default.metrics.rollingPercentile.bucketSize 实例属性 hystrix.command.HystrixCommandKey.metrics.rollingPercentile.bucketSize metrics.healthSnapshot.intervalInMilliseconds默认值：500 此属性设置允许执行运行成功和错误百分比并影响断路器状态的健康快照之间等待的时间（以毫秒为单位）。 ，连续计算误差百分比可能会消耗CPU过多，因此这个属性允许你控制计算的频率。 默认值 500 默认属性 hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 实例属性 hystrix.command.HystrixCommandKey.metrics.healthSnapshot.intervalInMilliseconds requestCache.enabled默认值：true 此属性指示是否HystrixCommand.getCacheKey()应该使用此属性HystrixRequestCache来通过请求范围的缓存提供重复数据删除功能。 默认值 true 默认属性 hystrix.command.default.requestCache.enabled 实例属性 hystrix.command.HystrixCommandKey.requestCache.enabled requestLog.enabled默认值：true 该属性指示是否HystrixCommand应执行和事件记录HystrixRequestLog。 默认值 真正 默认属性 hystrix.command.default.requestLog.enabled 实例属性 hystrix.command.HystrixCommandKey.requestLog.enabled Collapser属性以下属性控制HystrixCollapser行为。 maxRequestsInBatch此属性设置批处理允许的最大请求数量，然后触发批处理执行。 默认值 Integer.MAX_VALUE 默认属性 hystrix.collapser.default.maxRequestsInBatch 实例属性 hystrix.collapser.HystrixCollapserKey.maxRequestsInBatch timerDelayInMilliseconds此属性设置创建触发执行的批处理之后的毫秒数。 默认值 10 默认属性 hystrix.collapser.default.timerDelayInMilliseconds 实例属性 hystrix.collapser.HystrixCollapserKey.timerDelayInMilliseconds requestCache.enabled此属性指示请求缓存是否启用HystrixCollapser.execute()和HystrixCollapser.queue()调用。 默认值 true 默认属性 hystrix.collapser.default.requestCache.enabled 实例属性 hystrix.collapser.HystrixCollapserKey.requestCache.enabled ThreadPool属性以下属性控制Hystrix命令执行的线程池的行为。请注意，这些名称与ThreadPoolExecutor Javadoc中的名称相匹配 大多数情况下，10个线程的默认值都可以（通常可以做得更小）。 要确定是否需要更大，计算大小的基本公式是： requests per second at peak when healthy × 99th percentile latency in seconds + some breathing room 每秒最大支撑的请求数 (99%平均响应时间 + 缓存值)比如：每秒能处理1000个请求，99%的请求响应时间是60ms，那么公式是：1000 （0.060+0.012） 总体原则是尽可能保持池的小，因为它是减少负载的主要工具，并防止延迟发生时资源被阻塞。 当性能特征发生变化或发现问题时，您可以根据需要实时更改配置，而且如果出现问题或配置错误，则无需关闭整个应用程序。 coreSize该属性设置核心线程池大小。 默认值 10 默认属性 hystrix.threadpool.default.coreSize 实例属性 hystrix.threadpool.HystrixThreadPoolKey.coreSize MAXIMUMSIZE在1.5.9中添加。该属性设置最大的线程池大小。这是可以支持而不开始拒绝HystrixCommand的最大并发数量。请注意，这个设置只有在你设置的时候才会生效allowMaximumSizeToDivergeFromCoreSize。在1.5.9之前，核心和最大尺寸总是相等的。 默认值 10 默认属性 hystrix.threadpool.default.maximumSize 实例属性 hystrix.threadpool.HystrixThreadPoolKey.maximumSize maxQueueSize BlockingQueue的最大队列数，当设为－1，会使用SynchronousQueue，否则使用LinkedBlcokingQueue。该设置只会在初始化时有效。 默认值 -1 默认属性 hystrix.threadpool.default.maxQueueSize 实例属性 hystrix.threadpool.HystrixThreadPoolKey.maxQueueSize queueSizeRejectionThreshold此属性设置队列大小拒绝阈值 - 即使maxQueueSize还没有达到拒绝将发生的最大队列大小。这个属性的存在是因为maxQueueSize BlockingQueue不能被动态改变，我们希望允许你动态地改变影响拒绝的队列大小。 这是通过使用HystrixCommand排队要执行的线程时。 注意：如果这个属性不适用maxQueueSize == -1。 默认值 5 默认属性 hystrix.threadpool.default.queueSizeRejectionThreshold 实例属性 hystrix.threadpool.HystrixThreadPoolKey.queueSizeRejectionThreshold keepAliveTimeMinutes该属性设置保持活动时间，以分钟为单位。 在1.5.9之前，所有的线程池都是固定大小的coreSize == maximumSize。在1.5.9和之后，设置allowMaximumSizeToDivergeFromCoreSize为true允许这两个值分开，这样池可以获取/释放线程。如果coreSize &lt; maximumSize，那么这个属性控制一个线程在被释放之前将会被使用多久。 默认值 1 默认属性 hystrix.threadpool.default.keepAliveTimeMinutes 实例属性 hystrix.threadpool.HystrixThreadPoolKey.keepAliveTimeMinutes allowMaximumSizeToDivergeFromCoreSize在1.5.9中添加。该属性允许配置maximumSize生效。这个值可以等于或高于coreSize。设置coreSize &lt; maximumSize创建一个可以维持maximumSize并发的线程池，但会在相对不活动期间返回线程到系统。（受keepAliveTimeInMinutes） 默认值 false 默认属性 hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize 实例属性 hystrix.threadpool.HystrixThreadPoolKey.allowMaximumSizeToDivergeFromCoreSize metrics.rollingStats.timeInMilliseconds该属性设置统计滚动窗口的持续时间，以毫秒为单位。这是为线程池保留多长时间的指标。 窗口被分成桶和“滚”这些增量。 默认值 10000 默认属性 hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds 实例属性 hystrix.threadpool.HystrixThreadPoolKey.metrics.rollingStats.timeInMilliseconds metrics.rollingStats.numBuckets该属性设置滚动统计窗口分成的桶的数量。 注意：以下必须为真 - “ metrics.rollingStats.timeInMilliseconds % metrics.rollingStats.numBuckets == 0” - 否则会引发异常。 换句话说，10000/10是可以的，10000/20也是，但是10000/7不是。 默认值 10 可能的值 metric.rollingStats.timeInMilliseconds可以平分的任何值。结果应该是数百或数千毫秒的桶。大容量的性能还没有经过100ms以上的测试。 默认属性 hystrix.threadpool.default.metrics.rollingStats.numBuckets 实例属性 hystrix.threadpool.HystrixThreadPoolProperties.metrics.rollingStats.numBuckets ###]]></content>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot-admin]]></title>
    <url>%2F2017%2F12%2F18%2Fspring-boot-admin%2F</url>
    <content type="text"><![CDATA[Spring Boot AdminSpring Boot Admin是一个管理和监视Spring Boot应用程序的简单应用程序。应用程序注册到我们的Spring Boot Admin Client（通过http）或者使用Spring Cloud（例如Eureka）发现。UI只是Spring Boot Actuator端点上的一个Angular.js应用程序。如果您想要使用更高级的功能（例如jmx-，loglevel-management），则Jolokia必须包含在客户端应用程序中。 spring boot admin 功能 显示健康状态 显示详细信息 JVM和内存指标 计数器和衡量指标 数据源指标 缓存指标 显示编译信息编号 关注并下载日志文件 查看jvm system-＆environment-properties 支持Spring Cloud的postable / env-＆/ refresh-endpoint 简单的loglevel管理（目前仅适用于Logback） 与JMX-beans进行交互 查看线程转储 查看痕迹 Hystrix-Dashboard集成 下载heapdump 通知状态改变（通过邮件，Slack，Hipchat …） 状态更改的事件日志（非持久性） Spring Boot Admin Client 关于配置项的描述 Property Name Description Default Value spring.boot.admin.client.enabled 启用Spring Boot Admin Client true spring.boot.admin.url 这是一个必填的属性，将当前程序的信息注册到Admin Server中，你需要给出Server URL地址，如果需要注册到多个Admin Server，可以用逗号分隔开来。 spring.boot.admin.api-path 当客户端程序发起注册的时候，需要一个请求地址。 “api/application” spring.boot.admin.usernamespring.boot.admin.password 如果Admin端设置了用户名密码访问，你也需要在客户端配置它们。 spring.boot.admin.period 注册间隔（程序启动后多久发出注册请求） 10.000 spring.boot.admin.auto-registration 如果设置成true，那么上面那个属性就不需要设置了，程序会自动在启动成功后立刻发出注册申请。 true spring.boot.admin.auto-deregistration 当Admin server关闭的时候，自动注销。 false spring.boot.admin.register-once 如果你注册到了多个Admin Server，当他为true的时候，则只会向一个admin server进行注册，否则会同时向所有的admin server进行注册 true spring.boot.admin.client.health-url 客户端的健康监测URL，可以重写（例如Docker中），但是必须唯一。 spring.boot.admin.client.management-url 参考上面 spring.boot.admin.client.service-url 参考上面 spring.boot.admin.client.name 当前程序的名字 如果设置了${spring.application.name}这里就不需要再设置了 spring.boot.admin.client.prefer-ip 默认是false，意味着注册的时候，将会使用机器名进行注册，当设置为true的时候，将会用ip进行注册。 false Spring Boot Admin Server 的相关配置 Property Name Description Default Value spring.boot.admin.context-path 配置API的前缀路径 spring.boot.admin.monitor.period 更新程序状态的时间周期 10.000 spring.boot.admin.monitor.status-lifetime 更新状态的生命周期，在这个时间段内，将不会再次发起请求，直到过期。 10.000 spring.boot.admin.routes.endpoints 监控点的命名，如果你不想使用Admin自带的UI，你可能需要在这里重新定义他们的名字。 “env, metrics, trace, dump, jolokia, info, configprops, trace, activiti, logfile, refresh, flyway, liquibase” 可以在客户端程序中添加描述信息，例如： 12info.version=@project.version@info.owner=人名字 这里可以自定义，最终会显示在Admin的描述项中。]]></content>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker构建rabbitmq集群]]></title>
    <url>%2F2017%2F12%2F12%2Fdocker%E6%9E%84%E5%BB%BArabbitmq%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[部署步骤基本概念 内存节点 1只保存状态到内存，例外情况是：持久的 queue 的内容将被保存到磁盘。 磁盘节点 1保存状态到内存和磁盘。 内存节点由于不进行磁盘读写，它的性能比磁盘节点高。 集群中可以存在多个磁盘节点，磁盘节点越多整个集群可用性越好，但是集群整体性能不会线性增加，需要权衡考虑。 如果集群中只有内存节点，那么不能停止它们，否则所有状态和消息都会丢失。 构建RabbitMQ 基础镜像 mq-base 1234FROM centosFROM hub.c.163.com/library/rabbitmq:latestRUN /usr/sbin/rabbitmq-plugins enable rabbitmq_mqtt rabbitmq_stomp rabbitmq_management rabbitmq_management_agent rabbitmq_management_visualiser rabbitmq_federation rabbitmq_federation_management sockjs#CMD /usr/sbin/rabbitmq-server 构建RabbitMQ 基础镜像 mq-server 写erlang.cookie rabbitmq基于erlang mq之间通信要有相同的erlang.cookie （内容不固定） 1JHWMKVOYFWWBXWXOYXFQ rabbitmq.config 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. startrabbit.sh 12345678910111213141516171819202122232425262728293031#!/bin/bashchown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookiechmod 400 /var/lib/rabbitmq/.erlang.cookieRABBITMQ_NODENAME=$RABBITMQ_NODENAME /usr/sbin/rabbitmq-server if [ -z "$CLUSTERED" ]; then# # if not clustered then start it normally as if it is a single server RABBITMQ_NODENAME=$RABBITMQ_NODENAME /usr/sbin/rabbitmq-server else if [ -z "$CLUSTER_WITH" -o -z "$CLUSTER_NODENAME" ]; then # If clustered, but cluster with is not specified then again start normally, could be the first server in the # cluster RABBITMQ_NODENAME=$RABBITMQ_NODENAME /usr/sbin/rabbitmq-server else RABBITMQ_NODENAME=$RABBITMQ_NODENAME /usr/sbin/rabbitmq-server -detached /usr/sbin/rabbitmqctl stop_app if [ -z "$RAM_NODE" ]; then /usr/sbin/rabbitmqctl join_cluster $RABBITMQ_NODENAME@$CLUSTER_WITH else /usr/sbin/rabbitmqctl join_cluster --ram $RABBITMQ_NODENAME@$CLUSTER_WITH fi /usr/sbin/rabbitmqctl start_app # /usr/sbin/rabbitmq-plugins enable rabbitmq_mqtt rabbitmq_stomp rabbitmq_management rabbitmq_management_agent rabbitmq_management_visualiser rabbitmq_federation rabbitmq_federation_management sockjs # Tail to keep the a foreground process active.. #tail -f /var/log/rabbitmq/rabbit\@$HOSTNAME.log tail -f /etc/hosts fi fi dockerfile 构建镜像 123456789101112131415161718192021222324252627282930313233343536373839FROM mq-base:latestADD rabbitmq.config /etc/rabbitmq/RUN chmod u+rw /etc/rabbitmq/rabbitmq.configADD erlang.cookie /var/lib/rabbitmq/.erlang.cookieRUN chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookieRUN chmod 400 /var/lib/rabbitmq/.erlang.cookieRUN mkdir /opt/rabbitADD startrabbit.sh /opt/rabbit/RUN chmod a+x /opt/rabbit/startrabbit.shEXPOSE 5672EXPOSE 15672EXPOSE 25672EXPOSE 4369EXPOSE 9100EXPOSE 9101EXPOSE 9102EXPOSE 9103EXPOSE 9104EXPOSE 9105CMD /opt/rabbit/startrabbit.sh 写docker-compose.yml构建rabbitmq集群 12345678910111213141516171819202122232425262728293031323334rabbit1: image: mq-server:latest hostname: rabbit1 ports: - "5672:5672" - "15672:15672" environment: - RABBITMQ_DEFAULT_USER=guest - RABBITMQ_DEFAULT_PASS=guestrabbit2: image: mq-server:latest hostname: rabbit2 links: - rabbit1 environment: - CLUSTERED=true - CLUSTER_WITH=rabbit1 - RAM_NODE=true ports: - "5673:5672" - "15673:15672"rabbit3: image: mq-server:latest hostname: rabbit3 links: - rabbit1 - rabbit2 environment: - CLUSTERED=true - CLUSTER_WITH=rabbit1 ports: - "5674:5672" - "15674:15672" 启动compose启动3个节点 进入rabbitmq2节点 1docker exec -it &apos;id&apos; bash 停止rabbitmq2 连接rabbit1 启动 123./rabbitmqctl stop_app./rabbitmqctl join_cluster rabbit@rabbit1./rabbitmqctl start_app 进入rabbitmq3节点 停止rabbitmq3 连接rabbit1启动 123./rabbitmqctl stop_app./rabbitmqctl join_cluster rabbit@rabbit1./rabbitmqctl start_app 结果：]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[eureka学习笔记]]></title>
    <url>%2F2017%2F12%2F11%2Feureka%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[背景介绍Eureka是Netflix开源的一款提供服务注册和发现的产品。 其官方文档中对自己的定义是： Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers. We call this service, the Eureka Server. Eureka also comes with a Java-based client component,the Eureka Client, which makes interactions with the service much easier. The client also has a built-in load balancer that does basic round-robin load balancing. Why Eureka?那么为什么我们在项目中使用了Eureka呢？ 1）它提供了完整的Service Registry和Service Discovery实现 首先是提供了完整的实现，并且也经受住了Netflix自己的生产环境考验，相对使用起来会比较省心。 2）和Spring Cloud无缝集成 我们的项目本身就使用了Spring Cloud和Spring Boot，同时Spring Cloud还有一套非常完善的开源代码来整合Eureka，所以使用起来非常方便。 另外，Eureka还支持在我们应用自身的容器中启动，也就是说我们的应用启动完之后，既充当了Eureka的角色，同时也是服务的提供者。这样就极大的提高了服务的可用性。 3）Open Source 最后一点是开源，由于代码是开源的，所以非常便于我们了解它的实现原理和排查问题。 Dive into Eureka相信大家看到这里，已经对Eureka有了一个初步的认识，接下来我们就来深入了解下它吧~ OverviewBasic Architecture 图1 上图简要描述了Eureka的基本架构，由3个角色组成： Eureka Server 提供服务注册和发现 Service Provider 服务提供方 将自身服务注册到Eureka，从而使服务消费方能够找到 Service Consumer 服务消费方 从Eureka获取注册服务列表，从而能够消费服务 需要注意的是，上图中的3个角色都是逻辑角色。在实际运行中，这几个角色甚至可以是同一个实例，比如在我们项目中，Eureka Server和Service Provider就是同一个JVM进程。 More in depth 图2 上图更进一步的展示了3个角色之间的交互。 Service Provider会向Eureka Server做Register（服务注册）、Renew（服务续约）、Cancel（服务下线）等操作。 Eureka Server之间会做注册服务的同步，从而保证状态一致 Service Consumer会向Eureka Server获取注册服务列表，并消费服务 Eureka Server实现细节看了前面的demo，我们已经初步领略到了Spring Cloud和Eureka的强大之处，通过短短几行配置就实现了服务注册和发现！ 相信大家一定想了解Eureka是如何实现的吧，所以接下来我们继续Dive！首先来看下Eureka Server的几个对外接口实现。 Register首先来看Register（服务注册），这个接口会在Service Provider启动时被调用来实现服务注册。同时，当Service Provider的服务状态发生变化时（如自身检测认为Down的时候），也会调用来更新服务状态。 接口实现比较简单，如下图所示。 ApplicationResource类接收Http服务请求，调用PeerAwareInstanceRegistryImpl的register方法 PeerAwareInstanceRegistryImpl完成服务注册后，调用replicateToPeers向其它Eureka Server节点（Peer）做状态同步（异步操作） 图5 注册的服务列表保存在一个嵌套的hash map中： 第一层hash map的key是app name，也就是应用名字 第二层hash map的key是instance name，也就是实例名字 RenewRenew（服务续约）操作由Service Provider定期调用，类似于heartbeat。主要是用来告诉Eureka Server Service Provider还活着，避免服务被剔除掉。接口实现如下图所示。 可以看到，接口实现方式和register基本一致：首先更新自身状态，再同步到其它Peer。 图6 CancelCancel（服务下线）一般在Service Provider shut down的时候调用，用来把自身的服务从Eureka Server中删除，以防客户端调用不存在的服务。接口实现如下图所示。 图7 Fetch RegistriesFetch Registries由Service Consumer调用，用来获取Eureka Server上注册的服务。 为了提高性能，服务列表在Eureka Server会缓存一份，同时每30秒更新一次。 图8 EvictionEviction（失效服务剔除）用来定期（默认为每60秒）在Eureka Server检测失效的服务，检测标准就是超过一定时间没有Renew的服务。 默认失效时间为90秒，也就是如果有服务超过90秒没有向Eureka Server发起Renew请求的话，就会被当做失效服务剔除掉。 失效时间可以通过eureka.instance.leaseExpirationDurationInSeconds进行配置，定期扫描时间可以通过eureka.server.evictionIntervalTimerInMs进行配置。 接口实现逻辑见下图： 图9 How Peer Replicates在前面的Register、Renew、Cancel接口实现中，我们看到了都会有replicateToPeers操作，这个就是用来做Peer之间的状态同步。 通过这种方式，Service Provider只需要通知到任意一个Eureka Server后就能保证状态会在所有的Eureka Server中得到更新。 具体实现方式其实很简单，就是接收到Service Provider请求的Eureka Server，把请求再次转发到其它的Eureka Server，调用同样的接口，传入同样的参数，除了会在header中标记isReplication=true，从而避免重复的replicate。 Peer之间的状态是采用异步的方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。 结合服务发现的场景，实际上也并不需要节点间的状态强一致。在一段时间内（比如30秒），节点A比节点B多一个服务实例或少一个服务实例，在业务上也是完全可以接受的（Service Consumer侧一般也会实现错误重试和负载均衡机制）。 所以按照CAP理论，Eureka的选择就是放弃C，选择AP。 How Peer Nodes are Discovered那大家可能会有疑问，Eureka Server是怎么知道有多少Peer的呢？ Eureka Server在启动后会调用EurekaClientConfig.getEurekaServerServiceUrls来获取所有的Peer节点，并且会定期更新。定期更新频率可以通过eureka.server.peerEurekaNodesUpdateIntervalMs配置。 这个方法的默认实现是从配置文件读取，所以如果Eureka Server节点相对固定的话，可以通过在配置文件中配置来实现。 如果希望能更灵活的控制Eureka Server节点，比如动态扩容/缩容，那么可以override getEurekaServerServiceUrls方法，提供自己的实现，比如我们的项目中会通过数据库读取Eureka Server列表。 具体实现如下图所示： 图10 How New Peer Initializes最后再来看一下一个新的Eureka Server节点加进来，或者Eureka Server重启后，如何来做初始化，从而能够正常提供服务。 具体实现如下图所示，简而言之就是启动时把自己当做是Service Consumer从其它Peer Eureka获取所有服务的注册信息。然后对每个服务，在自己这里执行Register，isReplication=true，从而完成初始化。 图11 Service Provider实现细节现在来看下Service Provider的实现细节，主要就是Register、Renew、Cancel这3个操作。 RegisterService Provider要对外提供服务，一个很重要的步骤就是把自己注册到Eureka Server上。 这部分的实现比较简单，只需要在启动时和实例状态变化时调用Eureka Server的接口注册即可。需要注意的是，需要确保配置eureka.client.registerWithEureka=true。 图12 RenewRenew操作会在Service Provider端定期发起，用来通知Eureka Server自己还活着。 这里有两个比较重要的配置需要注意一下： instance.leaseRenewalIntervalInSeconds Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。 instance.leaseExpirationDurationInSeconds 服务失效时间。默认是90秒，也就是如果Eureka Server在90秒内没有接收到来自Service Provider的Renew操作，就会把Service Provider剔除。 具体实现如下： 图13 Cancel在Service Provider服务shut down的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务。 逻辑本身比较简单，通过对方法标记@PreDestroy，从而在服务shut down的时候会被触发。 图14 How Eureka Servers are Discovered这里大家疑问又来了，Service Provider是怎么知道Eureka Server的地址呢？ 其实这部分的主体逻辑和How Peer Nodes are Discovered几乎是一样的。 也是默认从配置文件读取，如果需要更灵活的控制，可以通过override getEurekaServerServiceUrls方法来提供自己的实现。定期更新频率可以通过eureka.client.eurekaServiceUrlPollIntervalSeconds配置。 图15 Service Consumer实现细节Service Consumer这块的实现相对就简单一些，因为它只涉及到从Eureka Server获取服务列表和更新服务列表。 Fetch Service RegistriesService Consumer在启动时会从Eureka Server获取所有服务列表，并在本地缓存。需要注意的是，需要确保配置eureka.client.shouldFetchRegistry=true。 图16 Update Service Registries由于在本地有一份缓存，所以需要定期更新，定期更新频率可以通过eureka.client.registryFetchIntervalSeconds配置。 图17 How Eureka Servers are DiscoveredService Consumer和Service Provider一样，也有一个如何知道Eureka Server地址的问题。 其实由于Service Consumer和Service Provider本质上是同一个Eureka客户端，所以这部分逻辑是一样的，这里就不再赘述了。 eureka 常用配置 配置参数 默认值 说明 服务注册中心配置 Bean类：org.springframework.cloud.netflix.eureka. server.EurekaServerConfigBean eureka.server.enable-self-preservation false 关闭注册中心的保护机制，Eureka 会统计15分钟之内心跳失败的比例低于85%将会触发保护机制，不剔除服务提供者，如果关闭服务注册中心将不可用的实例正确剔除 服务实例类配置 Bean类：org.springframework.cloud.netflix.eureka. EurekaInstanceConfigBean eureka.instance.prefer-ip-address false 不使用主机名来定义注册中心的地址，而使用IP地址的形式，如果设置了eureka.instance.ip-address 属性，则使用该属性配置的IP，否则自动获取除环路IP外的第一个IP地址 eureka.instance.ip-address IP地址 eureka.instance.hostname 设置当前实例的主机名称 eureka.instance.appname 服务名，默认取 spring.application.name 配置值，如果没有则为 unknown eureka.instance.lease-renewal-interval-in-seconds 30 定义服务续约任务（心跳）的调用间隔，单位：秒 eureka.instance.lease-expiration-duration-in-seconds 90 定义服务失效的时间，单位：秒 eureka.instance.status-page-url-path /info 状态页面的URL，相对路径，默认使用 HTTP 访问，如果需要使用 HTTPS则需要使用绝对路径配置 eureka.instance.status-page-url 状态页面的URL，绝对路径 eureka.instance.health-check-url-path /health 健康检查页面的URL，相对路径，默认使用 HTTP 访问，如果需要使用 HTTPS则需要使用绝对路径配置 eureka.instance.health-check-url 健康检查页面的URL，绝对路径 服务注册类配置 Bean类：org.springframework.cloud.netflix.eureka. EurekaClientConfigBean eureka.client.service-url. 指定服务注册中心地址，类型为 HashMap，并设置有一组默认值，默认的Key为 defaultZone；默认的Value为http://localhost:8761/eureka ，如果服务注册中心为高可用集群时，多个注册中心地址以逗号分隔。如果服务注册中心加入了安全验证，这里配置的地址格式为：http://:@localhost:8761/eureka其中 为安全校验的用户名； 为该用户的密码 eureka.client.fetch-registery true 检索服务 eureka.client.registery-fetch-interval-seconds 30 从Eureka服务器端获取注册信息的间隔时间，单位：秒 eureka.client.register-with-eureka true 启动服务注册 eureka.client.eureka-server-connect-timeout-seconds 5 连接 Eureka Server 的超时时间，单位：秒 eureka.client.eureka-server-read-timeout-seconds 8 读取 Eureka Server 信息的超时时间，单位：秒 eureka.client.filter-only-up-instances true 获取实例时是否过滤，只保留UP状态的实例 eureka.client.eureka-connection-idle-timeout-seconds 30 Eureka 服务端连接空闲关闭时间，单位：秒 eureka.client.eureka-server-total-connections 200 从Eureka 客户端到所有Eureka服务端的连接总数 eureka.client.eureka-server-total-connections-per-host 50 从Eureka客户端到每个Eureka服务主机的连接总数 常见问题如何解决Eureka注册服务慢的问题使用配置项： 1eureka.instance.leaseRenewalIntervalInSeconds Eureka的自我保护模式如果在Eureka Server的首页看到以下这段提示，则说明Eureka已经进入了保护模式。 EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY&#39;RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据（也就是不会注销任何微服务）。 如何解决Eureka Server不踢出已关停的节点的问题在开发过程中，我们常常希望Eureka Server能够迅速有效地踢出已关停的节点，但是新手由于Eureka自我保护模式，以及心跳周期长的原因，常常会遇到Eureka Server不踢出已关停的节点的问题。解决方法如下： (1) Eureka Server端：配置关闭自我保护，并按需配置Eureka Server清理无效节点的时间间隔。 12eureka.server.enable-self-preservation # 设为false，关闭自我保护eureka.server.eviction-interval-timer-in-ms # 清理间隔（单位毫秒，默认是60*1000） (2) Eureka Client端：配置开启健康检查，并按需配置续约更新时间和到期时间。 123eureka.client.healthcheck.enabled # 开启健康检查（需要spring-boot-starter-actuator依赖）eureka.instance.lease-renewal-interval-in-seconds # 续约更新时间间隔（默认30秒）eureka.instance.lease-expiration-duration-in-seconds # 续约到期时间（默认90秒）]]></content>
      <tags>
        <tag>spring cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq详解]]></title>
    <url>%2F2017%2F12%2F10%2Frabbitmq%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[rabbitmq 学习记录RabbitMQ 特点RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。具体特点包括： 可靠性（Reliability） RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。灵活的路由（Flexible Routing） 在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。 消息集群（Clustering） 多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。 高可用（Highly Available Queues） 队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。 多种协议（Multi-protocol） RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。 多语言客户端（Many Clients） RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等。管理界面（Management UI） RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。 跟踪机制（Tracing） 如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。插件机制（Plugin System） RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。 RabbitMQ 中的概念模型消息模型所有 MQ 产品从模型抽象上来说都是一样的过程：消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。 RabbitMQ 基本概念上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念： Message 消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。 Publisher 消息的生产者，也是一个向交换器发布消息的客户端应用程序。 Exchange 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。 Binding 绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。 Queue 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。 Connection 网络连接，比如一个TCP连接。 Channel 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。 Consumer 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。 Virtual Host 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。 Broker 表示消息队列服务器实体。 AMQP 中的消息路由AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。 Exchange 类型Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型： 1 direct 消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。 2 fanout 每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。 topic topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“”。#匹配0个或多个单词，匹配不多不少一个单词。]]></content>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 消息发布订阅]]></title>
    <url>%2F2017%2F11%2F21%2Fredis-%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%2F</url>
    <content type="text"><![CDATA[了解redis的都知道。redis本身提供了消息发布与订阅的功能，我们怎么在java中使用这一功能呢？下面就来说一下如何在java中使用redis的消息发布与订阅功能。 spring data redis 官方介绍Sending/Publishing messages (发送/发布消息)要发布消息，与其他操作一样，可以使用低级RedisConnection或高级RedisTemplate。这两个实体提供的publish方法接受作为参数需要发送的消息以及目标通道。当RedisConnection需要原始数据（字节数组）时，RedisTemplate允许任意对象作为消息传入： 123456// send message through connection RedisConnection con = ...byte[] msg = ...byte[] channel = ...con.publish(msg, channel); // send message through RedisTemplateRedisTemplate template = ...template.convertAndSend("hello!", "world"); Receiving/Subscribing for messages(接收/订阅消息)在接收方，可以通过直接命名或使用模式匹配来订阅一个或多个频道。后一种方法非常有用，因为它不仅允许使用一个命令创建多个订阅，而且还可以在订阅时尚未创建的频道上进行侦听（只要它们与模式匹配）。 在底层，按照模式分别映射Redis命令用于订阅的RedisConnection提供subscribe和pSubscribe方法。请注意，多个通道或模式可以用作参数。要更改连接的认购或简单地询问其是否正在监听，RedisConnection提供getSubscription和isSubscribed方法。 Spring Data Redis中的订阅命令是阻塞的。也就是说，要求订阅的连接，将导致当前线程阻塞，因为它会开始等待消息-只有在订购被取消的线程将被释放，这是一个额外的线程调用unsubscribe或pUnsubscribe在上相同的连接。有关此问题的解决方案，请参阅下面的消息监听器容器。 如上所述，一旦订阅连接开始等待消息。除了添加新订阅或修改/取消现有订阅之外，不能调用其他命令。也就是说，调用其他任何东西，然后subscribe，pSubscribe，unsubscribe，或者pUnsubscribe是非法的，将抛出一个异常。 为了订阅消息，需要实现MessageListener回调：每当新消息到达时，回调被调用，用户代码通过onMessage方法执行。该界面不仅可以访问实际的消息，而且还可以访问已经接收到的通道以及订阅所使用的模式（如果有）以匹配通道。该信息允许被叫方区分各种消息，不仅仅是内容，而且还通过数据。 消息监听器容器由于其阻塞性质，低级订阅没有吸引力，因为它需要为每个单独的监听者进行连接和线程管理。为了缓解这个问题，Spring Data提供RedisMessageListenerContainer了代表用户的所有繁重工作 - 熟悉EJB和JMS的用户应该找到熟悉的概念，因为它尽可能地接近Spring框架中的支持和消息驱动POJO（MDP） RedisMessageListenerContainer充当消息监听器容器; 它用于接收来自Redis通道的消息，并驱动MessageListener注入其中的s。侦听器容器负责所有的消息接收线程，并派发到侦听器进行处理。消息监听器容器是MDP和消息提供者之间的中介，负责注册接收消息，资源获取和释放，异常转换等。这使您可以作为应用程序开发人员编写与接收消息（并对其作出响应）相关的（可能是复杂的）业务逻辑，并将模板化的Redis基础架构问题委托给框架。 此外，为了最大限度地减少应用程序的空间，RedisMessageListenerContainer允许一个连接和一个线程被多个监听器共享，即使它们不共享订阅。因此，无论应用程序跟踪多少个监听器或通道，运行时成本在其整个生命周期中都将保持不变。此外，容器允许运行时配置更改，以便在应用程序运行时添加或删除侦听器，而无需重新启动。另外，容器使用一种懒惰的订阅方式，RedisConnection只在需要的时候使用a - 如果所有的监听器都被取消订阅，自动执行清理并释放使用的线程。 为了帮助消息的异步方式，容器需要一个java.util.concurrent.Executor（或Spring TaskExecutor）分派消息。根据负载，监听器数量或运行时环境，应该更改或调整执行程序以更好地满足其需求 - 特别是在托管环境（如应用程序服务器）中，强烈建议选择适当的TaskExecutor方式以利用它的运行时间。 MessageListenerAdapter这个MessageListenerAdapter类是Spring异步消息传递支持中的最后一个组件：简而言之，它允许您将几乎任何类作为MDP 公开（当然还有一些限制）。 考虑下面的接口定义。请注意，虽然接口不扩展MessageListener接口，但仍然可以通过使用MessageListenerAdapter该类作为MDP使用。还要注意如何使用各种消息处理方法是根据强类型的内容不同的Message，他们可以接收和处理类型。另外，消息发送到的通道或模式可以作为String类型的第二个参数传递给方法： 1234567public interface MessageDelegate &#123; void handleMessage(String message); void handleMessage(Map message); void handleMessage(byte[] message); void handleMessage(Serializable message); // pass the channel/pattern as well void handleMessage(Serializable message, String channel); &#125; 123public class DefaultMessageDelegate implements MessageDelegate &#123; // implementation elided for clarity...&#125; 尤其要注意MessageDelegate接口的上述实现（上面的DefaultMessageDelegate类）是否完全没有 Redis依赖关系。这是一个POJO，我们将通过以下配置将其制作成MDP。 12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:redis="http://www.springframework.org/schema/redis" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/redis http://www.springframework.org/schema/redis/spring-redis.xsd"&gt;&lt;!-- the default ConnectionFactory --&gt;&lt;redis:listener-container&gt; &lt;!-- the method attribute can be skipped as the default method name is "handleMessage" --&gt; &lt;redis:listener ref="listener" method="handleMessage" topic="chatroom" /&gt;&lt;/redis:listener-container&gt;&lt;bean id="listener" class="redisexample.DefaultMessageDelegate"/&gt; ...&lt;beans&gt; 听众话题可以是一个频道（例如topic=&quot;chatroom&quot;）或一个模式（例如topic=&quot;*room&quot;） 上面的示例使用Redis名称空间来声明消息侦听器容器，并自动将POJO注册为侦听器。完整的bean定义如下所示： 123456789101112131415161718&lt;bean id="messageListener" class="org.springframework.data.redis.listener.adapter.MessageListenerAdapter"&gt; &lt;constructor-arg&gt; &lt;bean class="redisexample.DefaultMessageDelegate"/&gt; &lt;/constructor-arg&gt;&lt;/bean&gt;&lt;bean id="redisContainer" class="org.springframework.data.redis.listener.RedisMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;property name="messageListeners"&gt; &lt;map&gt; &lt;entry key-ref="messageListener"&gt; &lt;bean class="org.springframework.data.redis.listener.ChannelTopic"&gt; &lt;constructor-arg value="chatroom"&gt; &lt;/bean&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; 每次接收到消息时，适配器将自动执行RedisSerializer低级格式与所需对象类型之间的透明转换（使用配置）。由方法调用引起的任何异常都会被容器捕获并处理（默认情况下会被记录）。 spring boot 中使用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.example.redis.redis.config;import java.util.concurrent.CountDownLatch;import com.example.redis.redis.service.Receiver;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.SpringApplication;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.listener.PatternTopic;import org.springframework.data.redis.listener.RedisMessageListenerContainer;import org.springframework.data.redis.listener.adapter.MessageListenerAdapter;/** * Created by hailin on 2017/11/17. */@Configurationpublic class RedisConfig &#123; @Bean RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory, MessageListenerAdapter listenerAdapter) &#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(connectionFactory); container.addMessageListener(listenerAdapter, new PatternTopic("chat")); return container; &#125; @Bean MessageListenerAdapter listenerAdapter(Receiver receiver) &#123; return new MessageListenerAdapter(receiver, "receiveMessage"); &#125; @Bean Receiver receiver(CountDownLatch latch) &#123; return new Receiver(latch); &#125; @Bean CountDownLatch latch() &#123; return new CountDownLatch(1); &#125; @Bean StringRedisTemplate template(RedisConnectionFactory connectionFactory) &#123; return new StringRedisTemplate(connectionFactory); &#125;&#125; 定义reciver 123456789101112131415public class Receiver &#123; private static final Logger LOGGER = LoggerFactory.getLogger(Receiver.class); private CountDownLatch latch; @Autowired public Receiver(CountDownLatch latch) &#123; this.latch = latch; &#125; public void receiveMessage(String message) &#123; LOGGER.info("Received &lt;" + message + "&gt;"); latch.countDown(); &#125;&#125; 测试 123456789101112131415161718192021package com.example.redis.redis;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTest(classes = RedisApplication.class)public class RedisApplicationTests &#123; @Autowired StringRedisTemplate stringRedisTemplate; @Test public void test2() &#123; for(int i=0;i&lt;10;i++)&#123; stringRedisTemplate.convertAndSend("chat", "Hello from Redis!"); &#125; &#125;&#125; 完成。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[restful 设计总结]]></title>
    <url>%2F2017%2F11%2F20%2Frestful-%E8%AE%BE%E8%AE%A1%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Restful浅析在做restful接口设计的时候发现自己所知甚少，在网络上找到一篇文章发现写的不错，希望自己可以设计出来一组完美的接口。转载一下原文地址：http://blog.csdn.net/andycooler/article/details/49951533 概述 做出一个好的API设计很难。API表达的是你的数据和你的数据使用者之间的契约。打破这个契约将会招致很多愤怒的邮件，和一大堆伤心的用户-因为他们手机上的App不工作了。而文档化只能达到一半的效果，并且也很难找到一个愿意写文档的程序员。 你所能做的最重要一件事来提高服务的价值就是创建一个API。因为随着其他服务的成长，有这样一个API会使你的服务或者核心应用将有机会变成一个平台。环顾一下现有的这些大公司：Facebook，Twitter，Google，Github，Amazon，Netflix等。如果当时他们没有通过API来开放数据的话，也不可能成长到如今的规模。事实上，整个行业存在的唯一目的就是消费所谓平台上的数据。 你的API越容易使用，那么就会有越多的人去用它 本文提到的这些原则，如果你的API能严格按照这些原则来设计，使用者就可以知道它接下来要做什么，并且能减少大量不必要的疑惑或者是愤怒的邮件。我已经把所有内容都整理到不同的主题里了，你无需按顺序去阅读它。 定义这里有一些非常重要的术语，我将在本文里面一直用到它们： 资源：一个对象的单独实例，如一只动物 集合：一群同种对象，如动物 HTTP：跨网络的通信协议 客户端：可以创建HTTP请求的客户端应用程序 第三方开发者：这个开发者不属于你的项目但是有想使用你的数据 服务器：一个HTTP服务器或者应用程序，客户端可以跨网络访问它 端点：这个API在服务器上的URL用于表达一个资源或者一个集合 幂等：无边际效应，多次操作得到相同的结果 URL段：在URL里面已斜杠分隔的内容 数据设计与抽象规划好你的API的外观要先于开发它实际的功能。首先你要知道数据该如何设计和核心服务/应用程序会如何工作。如果你纯粹新开发一个API，这样会比较容易一些。但如果你是往已有的项目中增加API，你可能需要提供更多的抽象。 有时候一个集合可以表达一个数据库表，而一个资源可以表达成里面的一行记录，但是这并不是常态。事实上，你的API应该尽可能通过抽象来分离数据与业务逻辑。这点非常重要，只有这样做你才不会打击到那些拥有复杂业务的第三方开发者，否则他们是不会使用你的API的。 当然你的服务可能很多部分是不应该通过API暴露出去的。比较常见的例子就是很多API是不允许第三方来创建用户的。 动词显然你了解GET和POST请求。当你用浏览器去访问不同页面的时候，这两个是最常见的请求。POST术语如此流行以至于开始侵扰通俗用语。即使是那些不知道互联网如何工作的人们也能“post”一些东西到朋友的Facebook墙上。 这里至少有四个半非常重要的HTTP动词需要你知道。我之所以说“半个”的意思是PATCH这个动词非常类似于PUT，并且它们俩也常常被开发者绑定到同一个API上。 GET (选择)：从服务器上获取一个具体的资源或者一个资源列表。 POST （创建）： 在服务器上创建一个新的资源。 PUT （更新）：以整体的方式更新服务器上的一个资源。 PATCH （更新）：只更新服务器上一个资源的一个属性。 DELETE （删除）：删除服务器上的一个资源。 还有两个不常用的HTTP动词： HEAD ： 获取一个资源的元数据，如数据的哈希值或最后的更新时间。 OPTIONS：获取客户端能对资源做什么操作的信息。 一个好的RESTful API只允许第三方调用者使用这四个半HTTP动词进行数据交互，并且在URL段里面不出现任何其他的动词。 一般来说，GET请求可以被浏览器缓存（通常也是这样的）。例如，缓存请求头用于第二次用户的POST请求。HEAD请求是基于一个无响应体的GET请求，并且也可以被缓存的。 版本化无论你正在构建什么，无论你在入手前做了多少计划，你核心的应用总会发生变化，数据关系也会变化，资源上的属性也会被增加或删除。只要你的项目还活着，并且有大量的用户在用，这种情况总是会发生。 请谨记一点，API是服务器与客户端之间的一个公共契约。如果你对服务器上的API做了一个更改，并且这些更改无法向后兼容，那么你就打破了这个契约，客户端又会要求你重新支持它。为了避免这样的事情，你既要确保应用程序逐步的演变，又要让客户端满意。那么你必须在引入新版本API的同时保持旧版本API仍然可用。 注：如果你只是简单的增加一个新的特性到API上，如资源上的一个新属性或者增加一个新的端点，你不需要增加API的版本。因为这些并不会造成向后兼容性的问题，你只需要修改文档即可。 随着时间的推移，你可能声明不再支持某些旧版本的API。申明不支持一个特性并不意味着关闭或者破坏它。而是告诉客户端旧版本的API将在某个特定的时间被删除，并且建议他们使用新版本的API。 一个好的RESTful API会在URL中包含版本信息。另一种比较常见的方案是在请求头里面保持版本信息。但是跟很多不同的第三方开发者一起工作后，我可以很明确的告诉你，在请求头里面包含版本信息远没有放在URL里面来的容易。 分析所谓API分析就是持续跟踪那些正为人使用的API的版本和端点信息。而这可能就跟每次请求都往数据库增加一个整数那样简单。有很多的原因显示API跟踪分析是一个好主意，例如，对那些使用最广泛的API来说效率是最重要的。 第三方开发者通常会关注API的构建目的，其中最重要的一个目的是你决定什么时候不再支持某个版本。你需要明确的告知开发者他们正在使用那些即将被移除的API特性。这是一个很好的方式在你准备删除旧的API之前去提醒他们进行升级。 当然第三方开发者的通知流程可以以某种条件被自动触发，例如每当一个过时的特性上发生10000次请求时就发邮件通知开发者。 API根URL无论你信不信，API的根地址很重要。当一个开发者接手了一个旧项目（如进行代码考古时）。而这个项目正在使用你的API，同时开发者还想构建一个新的特性，但他们完全不知道你的服务。幸运的是他们知道客户端对外调用的那些URL列表。让你的API根入口点保持尽可能的简单是很重要的，因为开发者很可能一看到那些冗长而又复杂的URL就转身而走。 这里有两个常见的URL根例子： 12https://example.org/api/v1/* (适合使用相同架构支持站点和API的小型应用)https://api.example.com/v1/* (适合比较庞大的API应用) 如果你的应用很庞大或者你预期它将会变的很庞大，那么将API放到子域下通常是一个好选择。这种做法可以保持某些规模化上的灵活性。 但如果你觉得你的API不会变的很庞大，或是你只是想让应用安装更简单些（如你想用相同的框架来支持站点和API），将你的API放到根域名下也是可以的。 让API根拥有一些内容通常也是个好主意。Github的API根就是一个典型的例子。从个人角度来说我是一个通过根URL发布信息的粉丝，这对很多人来说是有用的，例如如何获取API相关的开发文档。 同样也请注意HTTPS前缀，一个好的RESTful API总是基于HTTPS来发布的。 端点一个端点就是指向特定资源或资源集合的URL。 如果你正在构建一个虚构的API来展现几个不同的动物园，每一个动物园又包含很多动物，员工和每个动物的物种，你可能会有如下的端点信息： 1234https://api.example.com/v1/zooshttps://api.example.com/v1/animalshttps://api.example.com/v1/animal_typeshttps://api.example.com/v1/employees 针对每一个端点来说，你可能想列出所有可行的HTTP动词和端点的组合。如下所示，请注意我把HTTP动词都放在了虚构的API之前，正如将同样的注解放在每一个HTTP请求头里一样。 1234567891011121314151617181920GET /zoos: 获取所有动物园列表POST /zoos: 创建一个新的动物园GET /zoos/ZID: 获取一个完整的动物园对象PUT /zoos/ZID: 更新一个动物园对象 (完整对象)PATCH /zoos/ZID: 更新一个动物园对象 (局部对象)DELETE /zoos/ZID: 删除一个动物GET /zoos/ZID/animals: 获取一个动物园中的动物列表GET /animals: 获取所有动物列表POST /animals: 新建一个动物GET /animals/AID: 获取一个动物对象PUT /animals/AID: 更新一个动物对象 (完整对象)PATCH /animals/AID: 更新一个动物对象 (局部对象)GET /animal_types: 获取一个动物类型列表GET /animal_types/ATID: 获取一个动物类型GET /employees: 获取所有员工列表GET /employees/EID: 获取指定员工对象GET /zoos/ZID/employees: 获取指定动物园里的员工列表POST /employees: 新建一个员工POST /zoos/ZID/employees: 指定动物园雇佣员工DELETE /zoos/ZID/employees/EID: 解雇指定动物园里的指定员工 在上面的列表里，ZID表示动物园的ID， AID表示动物的ID，EID表示雇员的ID，还有ATID表示物种的ID。让文档里所有的东西都有一个关键字是一个好主意。 为了简洁起见，我已经省略了所有API共有的URL前缀。作为沟通方式这没什么问题，但是如果你真要写到API文档中，那就必须包含完整的路径（如，GET http://api.example.com/v1/animal_type/ATID）。 请注意如何展示数据之间的关系，特别是雇员与动物园之间的多对多关系。通过添加一个额外的URL段就可以实现更多的交互能力。当然没有一个HTTP动词能表示正在解雇一个人，但是你可以使用DELETE一个动物园里的雇员来达到相同的效果。 过滤器当客户端创建了一个请求来获取一个对象列表时，很重要一点就是你要返回给他们一个符合查询条件的所有对象的列表。这个列表可能会很大。但你不能随意给返回数据的数量做限制。因为这些无谓的限制会导致第三方开发者不知道发生了什么。如果他们请求一个确切的集合并且要遍历结果，然而他们发现只拿到了100条数据。接下来他们就不得不去查找这个限制条件的出处。到底是ORM的bug导致的，还是因为网络截断了大数据包？ 尽可能减少那些会影响到第三方开发者的无谓限制 这点很重要，但你可以让客户端自己对结果做一些具体的过滤或限制。这么做最重要的一个原因是可以最小化网络传输，并让客户端尽可能快的得到查询结果。其次是客户端可能比较懒，如果这时服务器能对结果做一些过滤或分页，对大家都是好事。另外一个不那么重要的原因是（从客户端角度来说），对服务器来说响应请求的负载越少越好。 过滤器是最有效的方式去处理那些获取资源集合的请求。所以只要出现GET的请求，就应该通过URL来过滤信息。以下有一些过滤器的例子，可能是你想要填加到API中的： 1234?limit=10: 减少返回给客户端的结果数量（用于分页）?offset=10: 发送一堆信息给客户端（用于分页）?animal_type_id=1: 使用条件匹配来过滤记录?sortby=name&amp;order=asc: 对结果按特定属性进行排序 有些过滤器可能会与端点URL的效果重复。例如我之前提到的GET /zoo/ZID/animals。它也同样可以通过GET /animals?zoo_id=ZID来实现。独立的端点会让客户端更好过一些，因为他们的需求往往超出你的预期。本文中提到这种冗余差异可能对第三方开发者并不可见。 无论怎么说，当你准备过滤或排序数据时，你必须明确的将那些客户端可以过滤或排序的列放到白名单中，因为我们不想将任何的数据库错误发送给客户端。 状态码对于一个RESTful API来说很重要的一点就是要使用HTTP的状态码，因为它们是HTTP的标准。很多的网络设备都可以识别这些状态码，例如负载均衡器可能会通过配置来避免发送请求到一台web服务器，如果这台服务器已经发送了很多的50x错误回来。这里有大量的HTTP状态码可以选择，但是下面的列表只给出了一些重要的代码作为一个参考： 123456789101112131415161718200 OK – [GET] The Consumer requested data from the Server, and the Server found it for them (Idempotent) 客户端向服务器请求数据，服务器成功找到它们201 CREATED – [POST/PUT/PATCH] The Consumer gave the Server data, and the Server created a resource 客户端向服务器提供数据，服务器根据要求创建了一个资源204 NO CONTENT – [DELETE] The Consumer asked the Server to delete a Resource, and the Server deleted it 客户端要求服务器删除一个资源，服务器删除成功400 INVALID REQUEST – [POST/PUT/PATCH] The Consumer gave bad data to the Server, and the Server did nothing with it (Idempotent) 客户端向服务器提供了不正确的数据，服务器什么也没做404 NOT FOUND – [*] The Consumer referenced an inexistant Resource or Collection, and the Server did nothing (Idempotent) 客户端引用了一个不存在的资源或集合，服务器什么也没做500 INTERNAL SERVER ERROR – [*] The Server encountered an error, and the Consumer has no knowledge if the request was successful 服务器发生内部错误，客户端无法得知结果，即便请求已经处理成功 状态码范围1xx范围的状态码是保留给底层HTTP功能使用的，并且估计在你的职业生涯里面也用不着手动发送这样一个状态码出来。 2xx范围的状态码是保留给成功消息使用的，你尽可能的确保服务器总发送这些状态码给用户。 3xx范围的状态码是保留给重定向用的。大多数的API不会太常使用这类状态码，但是在新的超媒体样式的API中会使用更多一些。 4xx范围的状态码是保留给客户端错误用的。例如，客户端提供了一些错误的数据或请求了不存在的内容。这些请求应该是幂等的，不会改变任何服务器的状态。 5xx范围的状态码是保留给服务器端错误用的。这些错误常常是从底层的函数抛出来的，并且开发人员也通常没法处理。发送这类状态码的目的是确保客户端能得到一些响应。收到5xx响应后，客户端没办法知道服务器端的状态，所以这类状态码是要尽可能的避免。 预期的返回文档当使用不同的HTTP动词向服务器请求时，客户端需要在返回结果里面拿到一系列的信息。下面的列表是非常经典的RESTful API定义： 123456GET /collection: 返回一系列资源对象GET /collection/resource: 返回单独的资源对象POST /collection: 返回新创建的资源对象PUT /collection/resource: 返回完整的资源对象PATCH /collection/resource: 返回完整的资源对象DELETE /collection/resource: 返回一个空文档 请注意当一个客户端创建一个资源时，她们常常不知道新建资源的ID（也许还有其他的属性，如创建和修改的时间戳等）。这些属性将在随后的请求中返回，并且作为刚才POST请求的一个响应结果。 认证服务器在大多数情况下是想确切的知道谁创建了什么请求。当然，有些API是提供给公共用户（匿名用户）的，但是大部分时间里也是代表某人的利益。 OAuth2.0提供了一个非常好的方法去做这件事。在每一个请求里，你可以明确知道哪个客户端创建了请求，哪个用户提交了请求，并且提供了一种标准的访问过期机制或允许用户从客户端注销，所有这些都不需要第三方的客户端知道用户的登陆认证信息。 还有OAuth1.0和xAuth同样适用这样的场景。无论你选择哪个方法，请确保它为多种不同语言/平台上的库提供了一些通用的并且设计良好文档，因为你的用户可能会使用这些语言和平台来编写客户端。 内容类型目前，大多数“精彩”的API都为RESTful接口提供JSON数据。诸如Facebook，Twitter，Github等等你所知的。XML曾经也火过一把（通常在一个大企业级环境下）。这要感谢SOAP，不过它已经挂了，并且我们也没看到太多的API把HTML作为结果返回给客户端（除非你在构建一个爬虫程序）。 只要你返回给他们有效的数据格式，开发者就可以使用流行的语言和框架进行解析。如果你正在构建一个通用的响应对象，通过使用一个不同的序列化器，你也可以很容易的提供之前所提到的那些数据格式（不包括SOAP）。而你所要做的就是把使用方式放在响应数据的接收头里面。 有些API的创建者会推荐把.json, .xml, .html等文件的扩展名放在URL里面来指示返回内容类型，但我个人并不习惯这么做。我依然喜欢通过接收头来指示返回内容类型（这也是HTTP标准的一部分），并且我觉得这么做也比较适当一些。 超媒体API超媒体API很可能就是RESTful API设计的将来。超媒体是一个非常棒的概念，它回归到了HTTP和HTML如何运作的“本质”。 在非超媒体RESTful API的情景中，URL端点是服务器与客户端契约的一部分。这些端点必须让客户端事先知道，并且修改它们也意味着客户端可能再也无法与服务器通信了。你可以先假定这是一个限制。 时至今日，英特网上的API客户端已经不仅仅只有那些创建HTTP请求的用户代理了。大多数HTTP请求是由人们通过浏览器产生的。人们不会被哪些预先定义好的RESTful API端点URL所束缚。是什么让人们变的如此与众不同？因为人们可以阅读内容，可以点击他们感兴趣的链接，并浏览一下网站，然后跳到他们关注的内容那里。即使一个URL改变了，人们也不会受到影响（除非他们事先给某个页面做了书签，这时他们回到主页并发现原来有一条新的路径可以去往之前的页面）。 超媒体API概念的运作跟人们的行为类似。通过请求API的根来获得一个URL的列表，这个列表里面的每一个URL都指向一个集合，并且提供了客户端可以理解的信息来描述每一个集合。是否为每一个资源提供ID并不重要（或者不是必须的），只要提供URL即可。 一个超媒体API一旦具有了客户端，那么它就可以爬行链接并收集信息，而URL总是在响应中被更新，并且不需要如契约的一部分那样事先被知晓。如果一个URL曾经被缓存过，并且在随后的请求中返回404错误，那么客户端可以很简单的回退到根URL并重新发现内容。 在获取集合中的一个资源列表时会返回一个属性，这个属性包含了各个资源的完整URL。当实施一个POST/PATCH/PUT请求后，响应可以被一个3xx的状态码重定向到完整的资源上。 JSON不仅告诉了我们需要定义哪些属性作为URL，也告诉了我们如何将URL与当前文档关联的语义。正如你猜的那样，HTML就提供了这样的信息。我们可能很乐意看到我们的API走完了完整的周期，并回到了处理HTML上来。想一下我们与CSS一起前行了多远，有一天我们可能再次看到它变成了一个通用实践让API和网站可以去使用相同的URL和内容。 文档老实说，即使你不能百分之百的遵循指南中的条款，你的API也不是那么糟糕。但是，如果你不为API准备文档的话，没有人会知道怎么使用它，那它真的会成为一个糟糕的API。 12345让你的文档对那些未经认证的开发者也可用不要使用文档自动化生成器，即便你用了，你也要保证自己审阅过并让它具有更好的版式。不要截断示例中请求与响应的内容，要展示完整的东西。并在文档中使用高亮语法。文档化每一个端点所预期的响应代码和可能的错误消息，和在什么情况下会产生这些的错误消息12345 如果你有富余的时间，那就创建一个控制台来让开发者可以立即体验一下API的功能。创建一个控制台并没有想象中那么难，并且开发者们（内部或者第三方）也会因此而拥戴你。 另外确保你的文档能够被打印。CSS是个强大的工具可以帮助到你。而且在打印的时候也不用太担心边侧栏的问题。即便没有人会打印到纸上，你也会惊奇的发现很多开发者愿意转化成PDF格式进行离线阅读。 勘误：原始的HTTP封包因为我们所做的都是基于HTTP协议，所以我将展示给你一个解析了的HTTP封包。我经常很惊讶的发现有多少人不知道这些东西。当客户端发送一个请求到服务器时，他们会提供一个键值对集，先是一个头，紧跟着是两个回车换行符，然后才是请求体。所有这些都是在一个封包里被发送。 服务器响应也是同样的键值对集，带两个回车换行符，然后是响应体。HTTP就是一个请求/响应协议；它不支持“推送”模式（服务器直接发送数据给客户端），除非你采用其他协议，如Websockets。 当你设计API时，你应该能够使用工具去查看原始的HTTP封包。Wireshark是个不错的选择。同时，你也该采用一个框架/web服务器，使你能够在必要时修改某些字段的值。 Example HTTP Request 12345678910POST /v1/animal HTTP/1.1Host: api.example.orgAccept: application/jsonContent-Type: application/jsonContent-Length: 24&#123; &quot;name&quot;: &quot;Gir&quot;, &quot;animal_type&quot;: 12&#125; Example HTTP Response 12345678910111213HTTP/1.1 200 OKDate: Wed, 18 Dec 2013 06:08:22 GMTContent-Type: application/jsonAccess-Control-Max-Age: 1728000Cache-Control: no-cache&#123; &quot;id&quot;: 12, &quot;created&quot;: 1386363036, &quot;modified&quot;: 1386363036, &quot;name&quot;: &quot;Gir&quot;, &quot;animal_type&quot;: 12&#125;]]></content>
      <tags>
        <tag>Rest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot使用redis]]></title>
    <url>%2F2017%2F11%2F20%2Fspring-boot%E4%BD%BF%E7%94%A8redis%2F</url>
    <content type="text"><![CDATA[关于redis就不多介绍了。就介绍一下spring-data-redis的使用。 在用spring boot 开发项目的时候用到了redis。故对spring boot 使用redis数据库做一个简单的记录。 使用spring-data-redis来对redis数据库进行操作 pom中加入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; spring boot 配置文件没做集群的话可以直接连接不要哨兵 1234567891011121314151617181920212223# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=192.168.99.100# Redis服务器连接端口spring.redis.port=16379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 #配置的是redis哨兵 spring.redis.sentinel.master=mymaster spring.redis.sentinel.nodes=192.168.99.100:16383,192.168.99.100:16384,192.168.99.100:16385 redis配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Configurationpublic class RedisConfig &#123; /** * 注入 RedisConnectionFactory */ @Autowired RedisConnectionFactory redisConnectionFactory; /** * 实例化 RedisTemplate 对象 * * @return */ @Bean public RedisTemplate&lt;String, Object&gt; functionDomainRedisTemplate() &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); initDomainRedisTemplate(redisTemplate, redisConnectionFactory); return redisTemplate; &#125; /** * 设置数据存入 redis 的序列化方式 * * @param redisTemplate * @param factory */ private void initDomainRedisTemplate(RedisTemplate&lt;String, Object&gt; redisTemplate, RedisConnectionFactory factory) &#123; redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setHashValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setValueSerializer(new JdkSerializationRedisSerializer()); redisTemplate.setConnectionFactory(factory); &#125; /** * 实例化 HashOperations 对象,可以使用 Hash 类型操作 * * @param redisTemplate * @return */ @Bean public HashOperations&lt;String, String, Object&gt; hashOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForHash(); &#125; /** * 实例化 ValueOperations 对象,可以使用 String 操作 * * @param redisTemplate * @return */ @Bean public ValueOperations&lt;String, Object&gt; valueOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForValue(); &#125; /** * 实例化 ListOperations 对象,可以使用 List 操作 * * @param redisTemplate * @return */ @Bean public ListOperations&lt;String, Object&gt; listOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForList(); &#125; /** * 实例化 SetOperations 对象,可以使用 Set 操作 * * @param redisTemplate * @return */ @Bean public SetOperations&lt;String, Object&gt; setOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForSet(); &#125; /** * 实例化 ZSetOperations 对象,可以使用 ZSet 操作 * * @param redisTemplate * @return */ @Bean public ZSetOperations&lt;String, Object&gt; zSetOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForZSet(); &#125;&#125; 定义IRredisService接口下面定义一个与redis交互的接口，简单的写了两个例子 1234567891011121314151617@Servicepublic interface IRedisService&lt;K extends String,V&gt; &#123; /** * * @param key * @param value */ void set(K key, V value); /** * * @param key * @param value * @param timeout 设置过时时间 * @param unit */ void set(K key, V value, long timeout, TimeUnit unit);&#125; 接口实现类 1234567891011121314public class IRedisServiceImpl implements IRedisService &#123; @Autowired private RedisTemplate&lt;String,Object&gt; redisTemplate; @Override public void set(String key, Object value) &#123; redisTemplate.opsForValue().set(key,value); &#125; @Override public void set(String key, Object value, long timeout, TimeUnit unit) &#123; redisTemplate.opsForValue().set(key,value,timeout,unit); &#125;&#125; 测试保存字符串12345@Testpublic void test() throws Exception &#123; // 保存字符串 iRedisService.set("aaa", "111");&#125; 保存对象创建对象 12345678@Data@AllArgsConstructor@NoArgsConstructorpublic class User implements Serializable &#123; private static final long serialVersionUID = -1L; private String username; private Integer age;&#125; 1234@Testpublic void test1()&#123; iRedisService.set("bcv",new User());&#125; 成功。 总结spring-data-redis 中封装了许多对redis的操作。上述只是简单的入门。]]></content>
      <categories>
        <category>spring boot</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker搭建redis集群]]></title>
    <url>%2F2017%2F11%2F15%2Fdocker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[docker 构建 redis 集群由于最近项目用到redis,考虑到redis的高可用故用docker搭建redis集群镜像。把原先散落各处的redis服务器统一管理起来，并且保障高可用和故障自动迁移。 redis 集群分类:大家都知道redis集群有两种，一种是redis sentinel，高可用集群，同时只有一个master，各实例数据保持一致；一种是redis cluster，分布式集群，同时有多个master，数据分片部署在各个master上。基于我们的需求和redis本身技术的成熟度，本次要搭建的是redis sentinel。 关于它的介绍： Redis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下四个任务： 不时地监控redis是否按照预期良好地运行 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave 的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的 新地址。 哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 制作镜像整个集群可以分为一个master，N个slave，M个sentinel，本次以2个slave和3个sentinel为例： 增加redis.conf 12345678910##redis.conf##redis-0,默认为masterport $redis_port##授权密码，请各个配置保持一致##暂且禁用指令重命名##rename-command##开启AOF，禁用snapshotappendonly yes#slaveof redis-master $master_port #redis-master master主机域名slave-read-only yes 增加sentinel.conf 1234567port $sentinel_portdir "/tmp"sentinel monitor mymaster redis-master $master_port 2##选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。sentinel config-epoch mymaster 1sentinel leader-epoch mymaster 1sentinel current-epoch 1 增加启动脚本，根据入参判断启动master，slave，sentinel 123456789101112131415161718192021cd /dataredis_role=$1echo $redis_roleif [ $redis_role = "master" ] ; then echo "master" sed -i "s/\$redis_port/$redis_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "slave" ] ; then echo "slave" sed -i "s/\$redis_port/$redis_port/g" redis.conf sed -i "s/#slaveof/slaveof/g" redis.conf sed -i "s/\$master_port/$master_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "sentinel" ] ; then echo "sentinel" sed -i "s/\$sentinel_port/$sentinel_port/g" sentinel.conf sed -i "s/\$master_port/$master_port/g" sentinel.conf redis-sentinel /data/sentinel.confelse echo "unknow role!" fi #ifend 其中$redis_port和$master_port,$sentinel_port都是取自环境变量，通过Docker启动时候传入。 编写Dockerfile 123456789FROM redis:3-alpineMAINTAINER yanhl &lt;yanhl&gt;COPY redis.conf /data/redis.confCOPY sentinel.conf /data/sentinel.confCOPY start.sh /data/start.shRUN chmod +x /data/start.shRUN chown redis:redis /data/*ENTRYPOINT ["sh","/data/start.sh"] CMD ["master"] 选取redis-alpine镜像作为基础镜像，因为它非常小，只有9M，修改时区和把一些配置拷贝进去后，变更下权限和用户组，因为基础镜像是redis用户组。ENTRYPOINT和CMD组合，默认以master方式启动。build完成后，镜像只有15M。 启动采用docker-compose格式： 12345678910111213141516171819202122232425262728293031323334353637redis-master-host: environment: redis_port: '16379' labels: io.rancher.container.pull_image: always tty: true image: #镜像id stdin_open: true net: hostredis-slaves: environment: master_port: '16379' redis_port: '16380' labels: io.rancher.scheduler.affinity:container_label_soft_ne: name=slaves io.rancher.container.pull_image: always name: slaves tty: true command: - slave image: #镜像id stdin_open: true net: hostredis-sentinels: environment: master_port: '16379' sentinel_port: '16381' labels: io.rancher.container.pull_image: always name: sentinels io.rancher.scheduler.affinity:container_label_ne: name=sentinels tty: true command: - sentinel image: #镜像id stdin_open: true net: host 首先启动master，传入端口16379，host模式，在启动slave，成为16379 master 的slave，并且设置调度策略为尽可能分散的方式，sentinels也类似。 测试启动 redis集群： java访问redis 123456789@Test public void test() throws Exception &#123; // 保存字符串 int i=0; while (true) &#123; stringRedisTemplate.opsForValue().set("a" + i, "111"); i++; &#125; &#125; 此时停掉一台哨兵 可以正常存储 1redis.clients.jedis.JedisSentinelPool : Lost connection to Sentinel at 192.168.99.100:16383. Sleeping 5000ms and retrying. 停掉所有哨兵 1Invocation of init method failed; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: All sentinels down, cannot determine where is mymaster master is running... 停掉一台slave 其中一台哨兵日志 1237:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.954 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.795 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 16379 重新启动会重新从主服务器加载数据 1234567891011121314151617181920218:S 15 Nov 13:00:04.461 * DB loaded from append only file: 0.619 seconds8:S 15 Nov 13:00:04.461 * The server is now ready to accept connections on port 163818:S 15 Nov 13:00:04.461 * Connecting to MASTER 192.168.99.100:163798:S 15 Nov 13:00:04.461 * MASTER &lt;-&gt; SLAVE sync started8:S 15 Nov 13:00:04.461 * Non blocking connect for SYNC fired the event.8:S 15 Nov 13:00:04.461 * Master replied to PING, replication can continue...8:S 15 Nov 13:00:04.461 * Partial resynchronization not possible (no cached master)8:S 15 Nov 13:00:04.468 * Full resync from master: 6cc2e4e7bbb4680ac0a8d9f7e5390f96eb1b1d76:384084118:S 15 Nov 13:00:05.291 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master8:S 15 Nov 13:00:05.314 * MASTER &lt;-&gt; SLAVE sync: Flushing old data8:S 15 Nov 13:00:05.354 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory8:S 15 Nov 13:00:06.422 * MASTER &lt;-&gt; SLAVE sync: Finished with success8:S 15 Nov 13:00:06.424 * Background append only file rewriting started by pid 118:S 15 Nov 13:00:07.703 * AOF rewrite child asks to stop sending diffs.11:C 15 Nov 13:00:07.703 * Parent agreed to stop sending diffs. Finalizing AOF...11:C 15 Nov 13:00:07.703 * Concatenating 0.00 MB of AOF diff received from parent.11:C 15 Nov 13:00:07.703 * SYNC append only file rewrite performed11:C 15 Nov 13:00:07.703 * AOF rewrite: 8 MB of memory used by copy-on-write8:S 15 Nov 13:00:07.739 * Background AOF rewrite terminated with success8:S 15 Nov 13:00:07.740 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)8:S 15 Nov 13:00:07.740 * Background AOF rewrite finished successfully 挂掉master 哨兵日志 哨兵会投票重新选取master 12345678910111213141516177:X 15 Nov 12:41:31.885 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.7:X 15 Nov 12:41:31.887 # Sentinel ID is 558ea99046801b4451dd49945d405f63e125f11e7:X 15 Nov 12:41:31.887 # +monitor master mymaster 192.168.99.100 16379 quorum 27:X 15 Nov 12:41:31.887 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.929 * +sentinel sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.922 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.809 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.517 * +reboot slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.584 # -sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.005 # +sdown master mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.119 # +new-epoch 27:X 15 Nov 13:04:19.119 # +vote-for-leader 8acf7f07765409e85e932c3baea249537f24f94c 27:X 15 Nov 13:04:19.611 # +config-update-from sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.611 # +switch-master mymaster 192.168.99.100 16379 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16379 192.168.99.100 16379 @ mymaster 192.168.99.100 16381 启动master 发现成为了一个从服务器 1234567891011121314151617181920212223242526276:M 15 Nov 13:08:18.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.6:M 15 Nov 13:08:18.767 # Server started, Redis version 3.2.116:M 15 Nov 13:08:18.767 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.6:M 15 Nov 13:08:18.767 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.6:M 15 Nov 13:08:21.409 * DB loaded from append only file: 2.642 seconds6:M 15 Nov 13:08:21.409 * The server is now ready to accept connections on port 163796:S 15 Nov 13:08:28.852 * SLAVE OF 192.168.99.100:16381 enabled (user request from 'id=2 addr=192.168.99.100:59528 fd=8 name= age=10 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')6:S 15 Nov 13:08:28.853 # CONFIG REWRITE executed with success.6:S 15 Nov 13:08:29.457 * Connecting to MASTER 192.168.99.100:163816:S 15 Nov 13:08:29.457 * MASTER &lt;-&gt; SLAVE sync started6:S 15 Nov 13:08:29.457 * Non blocking connect for SYNC fired the event.6:S 15 Nov 13:08:29.458 * Master replied to PING, replication can continue...6:S 15 Nov 13:08:29.458 * Partial resynchronization not possible (no cached master)6:S 15 Nov 13:08:29.463 * Full resync from master: 8cf78a3d6fe25eb719901e129627cc5f7556c6d4:525026:S 15 Nov 13:08:30.107 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master6:S 15 Nov 13:08:30.136 * MASTER &lt;-&gt; SLAVE sync: Flushing old data6:S 15 Nov 13:08:30.573 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory6:S 15 Nov 13:08:31.579 * MASTER &lt;-&gt; SLAVE sync: Finished with success6:S 15 Nov 13:08:31.581 * Background append only file rewriting started by pid 96:S 15 Nov 13:08:32.494 * AOF rewrite child asks to stop sending diffs.9:C 15 Nov 13:08:32.495 * Parent agreed to stop sending diffs. Finalizing AOF...9:C 15 Nov 13:08:32.495 * Concatenating 0.00 MB of AOF diff received from parent.9:C 15 Nov 13:08:32.495 * SYNC append only file rewrite performed9:C 15 Nov 13:08:32.496 * AOF rewrite: 2 MB of memory used by copy-on-write6:S 15 Nov 13:08:32.584 * Background AOF rewrite terminated with success6:S 15 Nov 13:08:32.584 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)6:S 15 Nov 13:08:32.584 * Background AOF rewrite finished successfully 测试通过。]]></content>
      <categories>
        <category>docker</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-stream-rabbitmq]]></title>
    <url>%2F2017%2F11%2F14%2Fspring-cloud-stream-rabbitmq%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 使用 rabbitmq 在使用spring cloud 构建微服务的时候用到的消息队列rabbitmq 综合了一下感觉用spring cloud stream 整合比较简单后期如果更换其它消息队列也比较简单 spring cloud stream 整合rabbitmq 概述 Spring Cloud Stream（以下简称SCS）是一个用于构建消息驱动微服务的框架。简单来说，通过SCS我们可以快速地在微服务之间传递异步消息，这对于一些刚起步时需求简单的消息应用是很方便的。 入门尽管很方便，但必要的准备工作还是要做的。SCS本身并不提供消息服务器，因此我们还是要安装像RabbitMQ或Kafka这样的消息服务器，本文会使用RabbitMQ来做讲解，具体如何安装Erlang和RabbitMQ这里不再赘述。安装好以后可以暂时不对RabbitMQ做配置。但要记得运行rabbitmq-plugins enable rabbitmq_management来激活管理平台以方便后续使用 。 生产者创建一个rabbitmq-producer微服务，默认端口8080 创建一个接口作为通道，举例： 123456789//生产者//创建一个rabbitmq-producer微服务，默认端口8080；//创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String OUTPUT = "test"; @Output(OUTPUT) MessageChannel output();&#125; @Output注解代表这是一个输出通道，而通道名就是我们定义的test，一个接口中可以定义多个输入和输出通道。实际上SCS本身提供了三个预定义接口通道，即Source.class单向输出通道，Sink.class单向输入通道，以及继承了它们两个的Processor.class，你可以在源码org.springframework.cloud.stream.messaging包中找到它们。但它们都只是简单示例，真正开发时我们肯定还是要自定义接口作为通道； 1234567891011121314151617//创建用于发送消息的接口（或直接在启动类中编写）：@RestController@EnableBinding(MyChannel.class)public class SendController &#123; @Autowired private MyChannel sender; @RequestMapping("/send") public String send()&#123; try &#123; sender.output().send(MessageBuilder.withPayload("Hello World").build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125; &#125;&#125; 需要注意的是，@EnableBinding注解是必须要加的（即使你只使用JUnit测试），但并不是必须添加在启动类上，其实你可以把它放在任何一个Spring能够扫描到的类。但为了方便查找，还是推荐放在启动类或者消息类上。 生产者至此告一段落，接下来我们看一下消费者。 消费者 12345678//创建一个consumer微服务，为防止与生产者冲突，端口号设为8081；//和生产者一样，创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String INPUT = "test"; @Input(INPUT) SubscribableChannel input();&#125; @Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息，因此我们也定义为test； 创建用于接收消息的类（或直接在启动类中编写）： 12345678@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;String&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; @StreamListener注解用于监听通道，由于我们在生产者发送的是一个”Hello World”字符串，因此在这里我们用string来接收它，注意Message用的是org.springframework.messaging.Message；与生产者一样，在启动类上添加@EnableBinding(MyChannel.class)。 测试 首先启动消费者微服务，如果你激活了RabbitMQ管理平台，那么此时就可以在上面看到test通道的相关信息了，包括Exchange和Queue 访问消息提供者的接口 http://localhost:8082/send在监听方会有消息 修改配置 至此我们就完成了简单的消息发送与接收服务，是不是感觉很快就能起飞了呢？手动配置在开头我提到可以暂时不对RabbitMQ做配置，这是为了我们可以快速开发调试。但现实中我们不可能不去修改RabbitMQ的配置（哪怕只是改改密码，毕竟guest相当于裸奔），那么如何让SCS去匹配修改过的配置呢？单就YAML配置来说，有两种方式（使用@Configuration类做配置的朋友请自行对照）： 直接配置spring.rabbitmq，比如我使用另外一个用户连接 12345spring: rabbitmq: username: “用户名” password: ”密码“ virtual-host: /test 使用spring.cloud.stream.binders和spring.cloud.stream.bindings组合配置，同样是上面的情况： 123456789101112131415spring: cloud: stream: bindings: test: binder: rabbit binders: rabbit: type: rabbit environment: spring: rabbitmq: username: ”用户名“ password: ”密码“ virtual-host: /test 乍一看感觉好麻烦呀，而且environment下面的配置不就是上面spring.rabbitmq的配置吗？ 实际上这种写法是有它的好处的，首先我们注意到，binders里面可以配置不同环境的binder，而通过bindings我们可以把channel和binder绑定起来。 假设我这个微服务现在要连两个RabbitMQ，那么我们就可以这样配置： 1234567891011121314151617181920212223242526272829spring: cloud: stream: bindings: test1: binder: rabbit1 test2: binder: rabbit2 binders: rabbit1: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5672 username: password: virtual-host: /test1 rabbit2: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5673 username: password: virtual-host: /test2 注：spring.cloud.stream.bindings.里面有许多有用的配置，比如destination、group等等。” 进阶好了简单的消息发送与接收已经实现了 如何像消息队列传递一个对象呢？ 上一节中我们发送的消息是一个字符串，那如果我想发送POJO怎么办呢？是直接发送和接收就可以了吗？下面我们可以试验一下： 首先创建一个User POJO，然后修改生产者的send()方法： 12345678910111213@GetMapping("/send")public String send() &#123; try &#123; User user = new User(); user.setId("1"); user.setName("yhl"); sender.output().send(MessageBuilder.withPayload(user).build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125;&#125; 修改消费者sc-stream-consumer的receive()方法： 123456789@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;User&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; 访问send 结果 接收方接到了一个user对象 如果你的User是分别在生产者和消费者中定义的，并且包路径不同，那么会报错反序列化失败。原因是SCS会默认将POJO转换成二进制发送，并且携带包路径等信息； 如果生产者和消费者使用的User是同一定义，或分别定义但包路径相同，那么就不会报错。 看起来略微有点不爽，那么有没有别的转换方式呢？ 有，而且官方还提供了很多： 下面我会举例用JSON字符串来传递POJO，其实只要在生产者中加上一条配置即可： 123456spring cloud: stream: bindings: test: content-type: application/json 此时消费者sc-stream-consumer接收的消息实体实际上是字符串了，我们可以用Message来测试一下： 此时收到的就是json数据了 既然接收的是JSON字符串了，那Spring怎么可能不提供自动反射呢XD，再次把消息实体换回User就行了。 负载均衡实际生产中，我们一般都会启动多个消费者实例来做负载均衡，既然是负载均衡，我们肯定希望一条消息在一组负载均衡实例中只被其中一个消费者接收。那么SCS是如何处理这种情况的呢？ 假设我们现在已经启动了生产者和消费者实例各一个，然后再修改消费者的端口为8082，再启动一个消费者实例。 随后发送消息测试，我们会发现两个消费者实例都接收到了消息： 这显然不是我们希望的，那么现在就来分析一下为什么会出现这种情况。 关键点在headers中的amqp_consumerQueue这个属性上，我们看到8081和8082的amqp_consumerQueue前面都是test.anonymous，但后面却是不一样的。这其实表示他们被分到了不同的匿名组（即group），而同一条消息会被test中的每个组都接收到。这个也很好理解，我们把group比喻成现实中的公司各部门，现在我要发一个通知，我会发给所有的部门，但同一部门中只要有一个人收到了，我就认为这个部门收到了通知。 所以只要把要负载均衡的实例分在同一个group下就好了，我们给消费者添加如下配置： 123456spring: cloud: stream: bindings: test: group: yhl 有一个test.yhl 队列这时调用发送者会发现两个消费者循环接受消息。]]></content>
      <categories>
        <category>消息队列</category>
        <category>rabbitMq</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudStream]]></title>
    <url>%2F2017%2F11%2F14%2FSpringCloudStream%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 翻译 （还没翻译完） 原文地址： https://docs.spring.io/spring-cloud-stream/docs/current-SNAPSHOT/reference/htmlsingle/#_introducing_spring_cloud_stream 1.简介Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的工业级spring应用，使用spring integration提供与消息代理之间的连接。本文提供不同代理中的中间件配置，介绍了持久化发布订阅机制，以及消费组以及分割的概念。将注解@EnableBinding加到应用上就可以实现与消息代理的连接，@StreamListener注解加到方法上，使之可以接收处理流的事件。 1234567891011121314151617@SpringBootApplicationpublic class StreamApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamApplication.class, args); &#125;&#125;@EnableBinding(Sink.class)public class TimerSource &#123; ... @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125;123456789101112131415161718 @EnableBinding注解使用一个或者多个接口作为参数（本例子中，参数是单独的Sink接口）。接口声明了输入和／或输出通道。 Spring Cloud Stream提供了Source, Sink, 和 Processor三个接口；你也可以定义你自己的接口。下面是Sink接口的定义： 123456public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;123456 @Input注解定义了一个输入通道，应用通过该输入通道接收进入应用的消息；@Output注解定义了一个输出通道，发布的消息通过该通道离开应用。input和output注解可以使用通道名称作为参数；如果没有名称，会使用带注解的方法的名字作为参数（也就是说，如果没有定义单独的名字，这里的通道名就是方法名input）。Spring Cloud Stream会为你创建一个接口的实现(这里注意，一定要在application里面加上@EnableBinding注解，不然会出现自动注入失败，因为缺少这个注解的话stream就不会创建接口的实例)。你可以通过自动装配在应用中使用它，如下面测试用例所示： 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = StreamApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125;1234567891011121314 2.主要概念Spring Cloud Stream提供了很多抽象和基础组件来简化消息驱动型微服务应用。包含以下内容： Spring Cloud Stream的应用模型 绑定抽象 持久化发布／订阅支持 消费者组支持 分片支持（Partitioning Support） 可插拔绑定api 应用模型 2.1应用模型Spring Cloud Stream由一个中间件中立的核组成。应用通过Spring Cloud Stream插入的input和output通道与外界交流。通道通过指定中间件的Binder实现与外部代理连接。 2.1.1 胖JAR测试的话，Spring Cloud Stream可以在ide中运行一个单独的实例。在生产环境中，可以通过Maven 或者 Gradle提供的Spring Boot 工具创建可执行JAR（或者胖JAR）。 2.2绑定抽象Spring Cloud Stream提供对 Kafka, Rabbit MQ,Redis, 和 Gemfire的绑定实现。Spring Cloud Stream使用Spring Boot做配置，绑定抽象使得stream可以灵活的连接到中间件。比如，开发者可以在运行时动态的选择通道连接的目标（可以是kafka主题或者RabbitMQ 交换机）。该配置可以通过spring boot支持的任何配置形式实现。在sink的例子中，将属性spring.cloud.stream.bindings.input.destination设置为raw-sensor-data，程序会从命名为raw-sensor-data的kafka主题中读取数据，或者从一个绑定到raw-sensor-data的rabbitmq交换机的队列中读取数据（这里的input是通道名，raw-sensor-data则是exchange的名字，通过使用同一个名字，可以将输入输出通道进行绑定）。Spring Cloud Stream自动检测和使用在class path中找到的binder。可以在build的时候引入不同的binder来使用不同类型的中间件。更复杂的情况下，可以在应用中打包多个binder使之按需选择，甚至可以在运行时根据不同的通道选择不同的binder。 2.3持久化发布／订阅支持应用间通信遵照发布-订阅模型，消息通过共享主题进行广播。下图所示，显示了交互的Spring Cloud Stream 应用的典型布局。sensor传给http端点的数据传给名为raw-sensor-data的目标。发布订阅模型简化了生产者和消费者的复杂程度，并且新的应用可以在不对当前数据流造成影响的情况下加入到拓扑中。由于发布－订阅模型并非一个新的概念，Spring Cloud Stream将其作为应用模型中的可选项。通过使用原生中间件支持，Spring Cloud Stream也简化了不同平台之间使用发布－订阅模型的复杂程度。 2.4消费者组由于发布－订阅模型使得共享主题的应用之间连接更简便，创建给定应用的不同实例来进行弹性扩张的能力也同样重要。如果存在多个应用实例，那么同一应用的额不同实例便会成为相互竞争的消费者，其中应该只有一个实例处理给定消息。Spring Cloud Stream通过消费者组的概念给这种情况进行建模。每一个单独的消费者可以使用spring.cloud.stream.bindings.input.group属性来指定一个组名字。下图中展示的消费者们，这一属性被设置为spring.cloud.stream.bindings.input.group=hdfsWrite或者spring.cloud.stream.bindings.input.group=average。所有订阅给定目标的组都会收到发布消息的一个拷贝，但是每一个组内只有一个成员会收到该消息。默认情况下，如果没有指定组，Spring Cloud Stream 会将该应用指定给一个匿名的独立的单成员消费者组，后者与所有其他组都处于一个发布－订阅关系中。持久性与Spring Cloud Stream中的可选应用模型一样，消费者组订阅是持久的。也就是说，一个绑定的实现确保组的订阅者是持久的，一旦组中至少有一个成员创建了订阅，这个组就会收到消息，即使组中所有的应用都被停止了，组仍然会收到消息。注：自然情况下，匿名订阅者是非持久化的。对于某些绑定实现（如rabbitmq），可以创建非持久化（non－durable）组订阅。一般来说，将应用绑定到给定目标的时候，最好指定一个消费者组。扩展Spring Cloud Stream应用的时候，对于它的每一个输入绑定，都必须要指定一个消费者组。 这样可以防止应用实例收到重复的消息。（除非存在重复收到的需求，但实际上很少会有这样的需求）。 2.5分片支持（Partitioning Support）Spring Cloud Stream对给定应用的多个实例之间分隔数据予以支持。在分隔方案中，物理交流媒介（如：代理主题）被视为分隔成了多个片（partitions）。一个或者多个生产者应用实例给多个消费者应用实例发送消息并确保相同特征的数据被同一消费者实例处理。Spring Cloud Stream对分割的进程实例实现进行了抽象。因此分片可以用于自带分隔的代理（如kafka）或者不带分隔的代理（如rabbitmq）。分割在有状态处理中是一个很重要的概念，在性能和一致性上，分割都是重要的概念。例如，在时间窗平均计算的例子中，给定传感器测量结果应该都由同一应用实例进行计算。注：如果要设置分割处理方案，需要配置数据处理和数据消费端点。 3.编程模型这一部分描述Spring Cloud Stream的编程模型。Spring Cloud Stream提供很多预先定一的注解来声明约束输入和输出通道以及如何监听这些通道。 3.1声明和绑定通道3.1.1通过@EnableBinding触发绑定将@EnableBinding应用到spring应用的一个配置类中，可以将spring应用变成Spring Cloud Stream应用。@EnableBinding注解本身就包含@Configuration注解，并且会触发Spring Cloud Stream 基本配置。@EnableBinding注解可以接收一个或多个接口类作为对象，后者包含代表了可绑定构件（一般来说是消息通道）的方法。注：在Spring Cloud Stream1.0中，仅有的可绑定构件是Spring 消息 MessageChannel以及它的扩展SubscribableChannel 和 PollableChannel. 未来版本会使用相同的机制扩展对其他类型构件的支持。在本文档中，会继续饮用通道。3.1.2@Input 和 @Output一个Spring Cloud Stream应用可以有任意数目的input和output通道，后者通过@Input and @Output方法在进口中定义。 1234567891011public interface Barista &#123; @Input SubscribableChannel orders(); @Output MessageChannel hotDrinks(); @Output MessageChannel coldDrinks();&#125;1234567891011 将该接口作为@EnableBinding的参数，会相应的触发三个名为orders, hotDrinks, 和 coldDrinks的绑定好的通道。 12345@EnableBinding(Barista.class)public class CafeConfiguration &#123; ...&#125;12345 定制通道名字使用@Input 和 @Output注解，可以自己指定通道的名字，如下所示： 12345public interface Barista &#123; ... @Input("inboundOrders") SubscribableChannel orders();&#125;12345 这个例子中，创建的绑定队列会被命名为inboundOrders。Source, Sink, and Processor在大多数用例中，包含一个输入通道或者一个输出通道或者二者都包含，为了更简单的定位，Spring Cloud Stream创造性的提供了三个预定义的接口。Source用于有单个输出（outbound）通道的应用。 12345678public interface Source &#123; String OUTPUT = "output"; @Output(Source.OUTPUT) MessageChannel output();&#125;12345678 Sink用于有单个输入（inbound）通道的应用。 12345678public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;12345678 Processor用于单个应用同时包含输入和输出通道的情况。 12public interface Processor extends Source, Sink &#123;&#125;12 Spring Cloud Stream对这三个接口没有提供任何特殊处理。他们只是用于创造性的提供。 3.1.3访问绑定通道 1.注入已绑定接口对于每一个已绑定的接口， Spring Cloud Stream会生成一个bean实现该接口。唤起这些由@Input或者 @Output注解的方法生成的bean，其中一个bean会返回相应的通道。下面例子中，当hello方法被唤起的时候，bean会在output通道上发送一个消息。在注入的Source bean上提供唤醒output()来检索到目标通道。 1234567891011121314@Componentpublic class SendingBean &#123; private Source source; @Autowired public SendingBean(Source source) &#123; this.source = source; &#125; public void sayHello(String name) &#123; source.output().send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 2.直接注入到通道绑定的通道也可以直接注入。 1234567891011121314@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; output.send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 如果通道名称是在声明的注解上指定的，则不能使用方法名称，而要使用通道名称。举例如下： 12345public interface CustomSource &#123; ... @Output("customOutput") MessageChannel output();&#125;12345 通道会按照下面方式注入： 123456789101112131415@Componentpublic class SendingBean &#123; @Autowired private MessageChannel output; @Autowired @Qualifier("customOutput") public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; customOutput.send(MessageBuilder.withPayload(body).build()); &#125;&#125;123456789101112131415 3.1.4生产和消费消息 可以使用Spring Integration 的注解或者Spring Cloud Stream的 @StreamListener 注解来实现一个Spring Cloud Stream应用。@StreamListener注解模仿其他spring消息注解（例如@MessageMapping, @JmsListener, @RabbitListener等），但是它增加了内容类型管理和类型强制特性。1.原生Spring Integration支持因为 Spring Cloud Stream是基于Spring Integration构建，Stream完全继承了Integration的基础设施以及构件本身。例如，可以将Source的output通道连接到一个MessageSource： 123456789101112@EnableBinding(Source.class)public class TimerSource &#123; @Value("$&#123;format&#125;") private String format; @Bean @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay = "$&#123;fixedDelay&#125;", maxMessagesPerPoll = "1")) public MessageSource&lt;String&gt; timerMessageSource() &#123; return () -&gt; new GenericMessage&lt;&gt;(new SimpleDateFormat(format).format(new Date())); &#125;&#125;123456789101112 或者可以在transformer中使用处理器的通道。 1234567@EnableBinding(Processor.class)public class TransformProcessor &#123; @Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT) public Object transform(String message) &#123; return message.toUpper(); &#125;&#125;1234567 2.使用 @StreamListener进行自动内容类型处理作为原生Spring Integration的补充，Spring Cloud Stream提供了自己的@StreamListener注解，该注解模仿spring的其它消息注解（如@MessageMapping, @JmsListener, @RabbitListener等）。@StreamListener注解提供了一种更简单的模型来处理输入消息，尤其是处理包含内容类型管理和类型强制的用例的情况。Spring Cloud Stream提供了一个扩展的MessageConverter机制，该机制提供绑定通道实现数据处理，本例子中，数据会分发给带@StreamListener注解的方法。下面例子展示了处理外部Vote事件的应用： 1234567891011@EnableBinding(Sink.class)public class VoteHandler &#123; @Autowired VotingService votingService; @StreamListener(Sink.INPUT) public void handle(Vote vote) &#123; votingService.record(vote); &#125;&#125;1234567891011 在输入消息内容头为application/json的情况下，@StreamListener和Spring Integration的@ServiceActivator之间会体现出差异。使用@StreamListener的情况下，MessageConverter机制会使用contentType头将string负载解析为Vote对象（也就是如果传输的是对象，应该选用@StreamListener注解）。在其它Spring Messaging方法中，消息机制可以使用@Payload, @Headers 和 @Header这些注解。 注：对于那些有返回数据的方法，必须使用@SendTo注解来指定返回数据的输出绑定目标。 123456789101112@EnableBinding(Processor.class)public class TransformProcessor &#123; @Autowired VotingService votingService; @StreamListener(Processor.INPUT) @SendTo(Processor.OUTPUT) public VoteResult handle(Vote vote) &#123; return votingService.record(vote); &#125;&#125;123456789101112 注：在RabbitMQ中，内容类型头可以由外部应用设定。 3.1.5聚合Aggregation Spring Cloud Stream可以支持多种应用的聚合，可以实现多种应用输入输出通道直接连接，而无需额外代价。在1.0版本中，只有以下类型应用支持聚合： sources：带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Source sinks：带有名为input的单一输入通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Sink processors：带有名为input的单一输入通道和带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定type org.springframework.cloud.stream.messaging.Processor. 可以通过创建一系列相互连接的应用将它们聚合到一起，其中，序列中一个元素的输出通道与下一个元素的输入通道连接在一起。序列可以由一个cource或者一个processor开始，可以包含任意数目的processors，并由processors或者sink结束。取决于开始和结束元素的特性，序列可以有一个或者多个可绑定的通道，如下： 如果序列由source开始，sink结束，应用之间直接通信并且不会绑定通道 如果序列由processor开始，它的输入通道会变成聚合的input通道并进行相应的绑定 如果序列由processor结束，它的输出通道会变成聚合的output通道并进行相应的绑定 使用AggregateApplicationBuilder功能类来实现聚合，如下例子所示。考虑一个包含source,processor 和 sink的工程，它们可以示包含在工程中，或者包含在工程的依赖中。 1234567891011@SpringBootApplication@EnableBinding(Sink.class)public class SinkApplication &#123; private static Logger logger = LoggerFactory.getLogger(SinkModuleDefinition.class); @ServiceActivator(inputChannel=Sink.INPUT) public void loggerSink(Object payload) &#123; logger.info("Received: " + payload); &#125;&#125;1234567891011 123456789@SpringBootApplication@EnableBinding(Processor.class)public class ProcessorApplication &#123; @Transformer public String loggerSink(String payload) &#123; return payload.toUpperCase(); &#125;&#125;123456789 12345678910@SpringBootApplication@EnableBinding(Source.class)public class SourceApplication &#123; @Bean @InboundChannelAdapter(value = Source.OUTPUT) public String timerMessageSource() &#123; return new SimpleDateFormat().format(new Date()); &#125;&#125;12345678910 每一个配置可用于运行一个独立的组件，在这个例子中，它们可以这样实现聚合： 12345678910@SpringBootApplicationpublic class SampleAggregateApplication &#123; public static void main(String[] args) &#123; new AggregateApplicationBuilder() .from(SourceApplication.class).args("--fixedDelay=5000") .via(ProcessorApplication.class) .to(SinkApplication.class).args("--debug=true").run(args); &#125;&#125;12345678910 序列的开始组件被提供作为from()方法的参数，序列的结束组件被提供作为to()方法的参数，中间处理器组件则作为via()方法的参数。同一类型的多个processors可以链在一起（例如，可以使用不同配置的管道传输方式）。对于每一个组件，编译器可以为Spring Boot 提供运行时参数。 3.1.6RxJava支持 4.绑定器（Binders）Spring Cloud Stream提供绑定抽象用于与外部中间件中的物理目标进行连接。本章主要介绍Binder SPI背后的主要概念，主要组件以及实现细节。 4.1生产者和消费者任何往通道中发布消息的组件都可称作生产者。通道可以通过代理的Binder实现与外部消息代理进行绑定。调用bindProducer()方法，第一个参数是代理名称，第二个参数是生产者向其中发送消息的本地通道目标名称，第三个参数包含通道创建的适配器的属性信息（比如：分片key表达式）。任何从通道中接收消息的组件都可称作消费者。与生产者一起，消费者通道可以与外部消息代理进行绑定。调用bindConsumer()方法，第一个参数是目标名称，第二个参数提供了消费者逻辑组的名称。]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈 Spring Cloud]]></title>
    <url>%2F2017%2F11%2F13%2F%E6%B5%85%E8%B0%88-Spring-Cloud%2F</url>
    <content type="text"><![CDATA[背景2008年以后，国内互联网行业飞速发展，我们对软件系统的需求已经不再是过去”能用就行”这种很low的档次了，像抢红包、双十一这样的活动不断逼迫我们去突破软件系统的性能上限，传统的IT企业”能用就行”的开发思想已经不能满足互联网高并发、大流量的性能要求。系统架构走向分布式已经是服务器开发领域解决该问题唯一的出路，然而分布式系统由于天生的复杂度，并不像开发单体应用一样把框架一堆就能搞定，因此各大互联网公司都在投入技术力量研发自己的基础设施。这里面比较有名的如阿里的开源项目dubbo, Netflix开发的一系列服务框架。在这种“百花齐放”、重复造轮子的状况下，必然要出现一种统一的标准来简化分布式系统的开发，Spring Cloud应运而生。 Spring Cloud是什么SpringCloud架构Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 Spring Cloud正是对Netflix的多个开源组件进一步的封装而成，同时又实现了和云端平台，和Spring Boot开发框架很好的集成。 Spring Cloud是一个相对比较新的微服务框架，2016年才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。 Spring Cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。 Spring Cloud组成 Spring Cloud的子项目，大致可分成两类，一类是对现有成熟框架”Spring Boot化”的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色。对于我们想快速实践微服务的开发者来说，第一类子项目就已经足够使用，如：Spring Cloud Netflix，是对Netflix开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST客户端、请求路由等。该项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。 通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。 Spring Cloud Eureka 服务发现服务中心，云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是SpringCloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。 Spring Cloud Eureka提供在分布式环境下的服务发现，服务注册的功能。 一个RESTful服务，用来定位运行在AWS地区（Region）中的中间层服务。由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 Spring Cloud Ribbon 客户端负载均衡Ribbon，主要提供客户侧的软件负载均衡算法。 Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略： 简单轮询负载均衡 加权响应时间负载均衡 区域感知轮询负载均衡 随机负载均衡 Ribbon中还包括以下功能： 易于与服务发现组件（比如Netflix的Eureka）集成 使用Archaius完成运行时配置 使用JMX暴露运维指标，使用Servo发布 多种可插拔的序列化选择 异步和批处理操作（即将推出） 自动SLA框架（即将推出） 系统管理/指标控制台（即将推出） Spring Cloud Config俗称的配置中心，配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。就是以后大家武器、枪火什么的东西都集中放到一起，别随便自己带，方便以后统一管理、升级装备。 将配置信息中央化保存, 配置Spring Cloud Bus可以实现动态修改配置文件。这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。 Spring Cloud Config就是我们通常意义上的配置中心。Spring Cloud Config-把应用原本放在本地文件的配置抽取出来放在中心服务器，本质是配置信息从本地迁移到云端。从而能够提供更好的管理、发布能力。 Spring Cloud Config分服务端和客户端，服务端负责将git（svn）中存储的配置文件发布成REST接口，客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化，从而主动去获取新的配置，这需要每个客户端通过POST方法触发各自的/refresh。 Spring cloud Hystrix 熔断器熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。 断路器(Cricuit Breaker)是一种能够在远程服务不可用时自动熔断(打开开关)，并在远程服务恢复时自动恢复(闭合开关)的设施，Spring Cloud通过Netflix的Hystrix组件提供断路器、资源隔离与自我修复功能。断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正，应用程序可以尝试调用操作。 断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。 Spring Cloud Zuul 服务网关，智能路由Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。 类似Nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。 Spring Netflix Archaius配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置， 原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。 Spring Cloud Bus事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。相当于水浒传中日行八百里的神行太保戴宗，确保各个小弟之间消息保持畅通。分布式消息队列，是对Kafka, MQ的封装；事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。 Spring cloud bus被国内很多都翻译为消息总线，也挺形象的。大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。 Spring Cloud Bus做配置更新的步骤: 提交代码触发post给客户端A发送bus/refresh客户端A接收到请求从Server端更新配置并且发送给Spring Cloud BusSpring Cloud bus接到消息并通知给其它客户端其它客户端接收到通知，请求Server端获取最新配置全部客户端均获取到最新的配置 Spring Cloud Security对Spring Security的封装，并能配合Netflix使用，安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 基于spring security的安全工具包，为你的应用程序添加安全控制。这个小弟很牛鼻专门负责整个帮派的安全问题，设置不同的门派访问特定的资源，不能把秘籍葵花宝典泄漏了。 Spring Cloud Zookeeper对Zookeeper的封装，使之能配置其它Spring Cloud的子项目使用；操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理，抱了Zookeeper的大腿。 Spring Cloud Stream数据流；数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的／工业级spring应用，使用spring integration提供与消息代理之间的连接。数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 一个业务会牵扯到多个任务，任务之间是通过事件触发的，这就是Spring Cloud stream要干的事了。 Spring Cloud Sleuth服务跟踪；日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。 Spring Cloud Feign 使用HTTP请求远程服务在Spring Cloud Netflix栈中，各个微服务都是以HTTP接口的形式暴露自身服务的，因此在调用远程服务时就必须使用HTTP客户端。我们可以使用JDK原生的URLConnection、Apache的Http Client、Netty的异步HTTP Client, Spring的RestTemplate。但是，用起来最方便、最优雅的还是要属Feign了。 Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。 通过Feign， 我们能把HTTP远程调用对开发者完全透明，得到与调用本地方法一致的编码体验。这一点与阿里Dubbo中暴露远程服务的方式类似，区别在于Dubbo是基于私有二进制协议，而Feign本质上还是个HTTP客户端。如果是在用Spring Cloud Netflix搭建微服务，那么Feign无疑是最佳选择。 Spring Cloud for Cloud FoundryCloud Foundry是VMware推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题 其实就是与CloudFoundry进行集成的一套解决方案，抱了Cloud Foundry的大腿。 Spring Cloud ClusterSpring Cloud Cluster将取代Spring Integration。提供在分布式系统中的集群所需要的基础功能支持，如：选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现。 如果把不同的帮派组织成统一的整体，Spring Cloud Cluster已经帮你提供了很多方便组织成统一的工具。 Spring Cloud ConsulConsul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件,由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源. Consul 支持健康检查,并允许 HTTP 和 DNS 协议调用 API 存储键值对. Spring Cloud Consul 封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Data FlowData flow 是一个用于开发和执行大范围数据处理其模式包括ETL，批量运算和持续运算的统一编程模型和托管服务。 对于在现代运行环境中可组合的微服务程序来说，Spring Cloud data flow是一个原生云可编配的服务。使用Spring Cloud data flow，开发者可以为像数据抽取，实时分析，和数据导入/导出这种常见用例创建和编配数据通道 （data pipelines）。 Spring Cloud data flow 是基于原生云对 spring XD的重新设计，该项目目标是简化大数据应用的开发。Spring XD 的流处理和批处理模块的重构分别是基于 spring boot的stream 和 task/batch 的微服务程序。这些程序现在都是自动部署单元而且他们原生的支持像 Cloud Foundry、Apache YARN、Apache Mesos和Kubernetes 等现代运行环境。 Spring Cloud data flow 为基于微服务的分布式流处理和批处理数据通道提供了一系列模型和最佳实践。 Spring Cloud TaskSpring Cloud Task 主要解决短命微服务的任务管理，任务调度的工作，比如说某些定时任务晚上就跑一次，或者某项数据分析临时就跑几次。 Spring Cloud ConnectorsSpring Cloud Connectors 简化了连接到服务的过程和从云平台获取操作的过程，有很强的扩展性，可以利用Spring Cloud Connectors来构建你自己的云平台。 便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。 Spring Cloud StartersSpring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。 Spring Cloud CLI基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Netflix TurbineTurbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。 和Spring Boot 是什么关系Spring boot 是 Spring 的一套快速配置脚手架，可以基于spring boot 快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring boot专注于快速、方便集成的单个个体，Spring Cloud是关注全局的服务治理框架；spring boot使用了默认大于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置，Spring Cloud很大的一部分是基于Spring boot来实现,可以不基于Spring boot吗？不可以。 Spring boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring boot，属于依赖的关系。 Spring -&gt; Spring Boot &gt; Spring Cloud 这样的关系。 Spring Cloud的优势微服务的框架那么多比如：dubbo、Kubernetes，为什么就要使用Spring Cloud的呢？ 产出于Spring大家族，Spring在企业级开发框架中无人能敌，来头很大，可以保证后续的更新、完善。比如dubbo现在就差不多死了有Spring Boot 这个独立干将可以省很多事，大大小小的活spring boot都搞的挺不错。 作为一个微服务治理的大家伙，考虑的很全面，几乎服务治理的方方面面都考虑到了，方便开发开箱即用。Spring Cloud 活跃度很高，教程很丰富，遇到问题很容易找到解决方案轻轻松松几行代码就完成了熔断、均衡负责、服务中心的各种平台功能Spring Cloud 也有一个缺点，只能使用Java开发,不适合小型独立的项目。 个人总结上面的一些组件介绍是综合了网上给出的介绍和自己的一些理解来写的,在实际工作中也用到了大多的组件。后续会结合自己的使用情况来总结每个组件的详细内容以及具体的使用情况。 ##]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
</search>
