<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker搭建redis集群]]></title>
    <url>%2F2017%2F11%2F15%2Fdocker%E6%90%AD%E5%BB%BAredis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[docker 构建 redis 集群由于最近项目用到redis,考虑到redis的高可用故用docker搭建redis集群镜像。把原先散落各处的redis服务器统一管理起来，并且保障高可用和故障自动迁移。 redis 集群分类:大家都知道redis集群有两种，一种是redis sentinel，高可用集群，同时只有一个master，各实例数据保持一致；一种是redis cluster，分布式集群，同时有多个master，数据分片部署在各个master上。基于我们的需求和redis本身技术的成熟度，本次要搭建的是redis sentinel。 关于它的介绍： Redis 的 Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下四个任务： 不时地监控redis是否按照预期良好地运行 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave 的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的 新地址。 哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。 制作镜像整个集群可以分为一个master，N个slave，M个sentinel，本次以2个slave和3个sentinel为例： 增加redis.conf 12345678910##redis.conf##redis-0,默认为masterport $redis_port##授权密码，请各个配置保持一致##暂且禁用指令重命名##rename-command##开启AOF，禁用snapshotappendonly yes#slaveof redis-master $master_port #redis-master master主机域名slave-read-only yes 增加sentinel.conf 1234567port $sentinel_portdir "/tmp"sentinel monitor mymaster redis-master $master_port 2##选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长。sentinel config-epoch mymaster 1sentinel leader-epoch mymaster 1sentinel current-epoch 1 增加启动脚本，根据入参判断启动master，slave，sentinel 123456789101112131415161718192021cd /dataredis_role=$1echo $redis_roleif [ $redis_role = "master" ] ; then echo "master" sed -i "s/\$redis_port/$redis_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "slave" ] ; then echo "slave" sed -i "s/\$redis_port/$redis_port/g" redis.conf sed -i "s/#slaveof/slaveof/g" redis.conf sed -i "s/\$master_port/$master_port/g" redis.conf redis-server /data/redis.confelif [ $redis_role = "sentinel" ] ; then echo "sentinel" sed -i "s/\$sentinel_port/$sentinel_port/g" sentinel.conf sed -i "s/\$master_port/$master_port/g" sentinel.conf redis-sentinel /data/sentinel.confelse echo "unknow role!" fi #ifend 其中$redis_port和$master_port,$sentinel_port都是取自环境变量，通过Docker启动时候传入。 编写Dockerfile 123456789FROM redis:3-alpineMAINTAINER yanhl &lt;yanhl&gt;COPY redis.conf /data/redis.confCOPY sentinel.conf /data/sentinel.confCOPY start.sh /data/start.shRUN chmod +x /data/start.shRUN chown redis:redis /data/*ENTRYPOINT ["sh","/data/start.sh"] CMD ["master"] 选取redis-alpine镜像作为基础镜像，因为它非常小，只有9M，修改时区和把一些配置拷贝进去后，变更下权限和用户组，因为基础镜像是redis用户组。ENTRYPOINT和CMD组合，默认以master方式启动。build完成后，镜像只有15M。 启动采用docker-compose格式： 12345678910111213141516171819202122232425262728293031323334353637redis-master-host: environment: redis_port: '16379' labels: io.rancher.container.pull_image: always tty: true image: #镜像id stdin_open: true net: hostredis-slaves: environment: master_port: '16379' redis_port: '16380' labels: io.rancher.scheduler.affinity:container_label_soft_ne: name=slaves io.rancher.container.pull_image: always name: slaves tty: true command: - slave image: #镜像id stdin_open: true net: hostredis-sentinels: environment: master_port: '16379' sentinel_port: '16381' labels: io.rancher.container.pull_image: always name: sentinels io.rancher.scheduler.affinity:container_label_ne: name=sentinels tty: true command: - sentinel image: #镜像id stdin_open: true net: host 首先启动master，传入端口16379，host模式，在启动slave，成为16379 master 的slave，并且设置调度策略为尽可能分散的方式，sentinels也类似。 测试启动 redis集群： java访问redis 123456789@Test public void test() throws Exception &#123; // 保存字符串 int i=0; while (true) &#123; stringRedisTemplate.opsForValue().set("a" + i, "111"); i++; &#125; &#125; 此时停掉一台哨兵 可以正常存储 1redis.clients.jedis.JedisSentinelPool : Lost connection to Sentinel at 192.168.99.100:16383. Sleeping 5000ms and retrying. 停掉所有哨兵 1Invocation of init method failed; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: All sentinels down, cannot determine where is mymaster master is running... 停掉一台slave 其中一台哨兵日志 1237:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.954 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.795 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 16379 重新启动会重新从主服务器加载数据 1234567891011121314151617181920218:S 15 Nov 13:00:04.461 * DB loaded from append only file: 0.619 seconds8:S 15 Nov 13:00:04.461 * The server is now ready to accept connections on port 163818:S 15 Nov 13:00:04.461 * Connecting to MASTER 192.168.99.100:163798:S 15 Nov 13:00:04.461 * MASTER &lt;-&gt; SLAVE sync started8:S 15 Nov 13:00:04.461 * Non blocking connect for SYNC fired the event.8:S 15 Nov 13:00:04.461 * Master replied to PING, replication can continue...8:S 15 Nov 13:00:04.461 * Partial resynchronization not possible (no cached master)8:S 15 Nov 13:00:04.468 * Full resync from master: 6cc2e4e7bbb4680ac0a8d9f7e5390f96eb1b1d76:384084118:S 15 Nov 13:00:05.291 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master8:S 15 Nov 13:00:05.314 * MASTER &lt;-&gt; SLAVE sync: Flushing old data8:S 15 Nov 13:00:05.354 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory8:S 15 Nov 13:00:06.422 * MASTER &lt;-&gt; SLAVE sync: Finished with success8:S 15 Nov 13:00:06.424 * Background append only file rewriting started by pid 118:S 15 Nov 13:00:07.703 * AOF rewrite child asks to stop sending diffs.11:C 15 Nov 13:00:07.703 * Parent agreed to stop sending diffs. Finalizing AOF...11:C 15 Nov 13:00:07.703 * Concatenating 0.00 MB of AOF diff received from parent.11:C 15 Nov 13:00:07.703 * SYNC append only file rewrite performed11:C 15 Nov 13:00:07.703 * AOF rewrite: 8 MB of memory used by copy-on-write8:S 15 Nov 13:00:07.739 * Background AOF rewrite terminated with success8:S 15 Nov 13:00:07.740 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)8:S 15 Nov 13:00:07.740 * Background AOF rewrite finished successfully 挂掉master 哨兵日志 哨兵会投票重新选取master 12345678910111213141516177:X 15 Nov 12:41:31.885 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.7:X 15 Nov 12:41:31.887 # Sentinel ID is 558ea99046801b4451dd49945d405f63e125f11e7:X 15 Nov 12:41:31.887 # +monitor master mymaster 192.168.99.100 16379 quorum 27:X 15 Nov 12:41:31.887 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.929 * +sentinel sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:33.985 * +sentinel sentinel dd903d8391315dd23c23ff2f9c5c0a2f57e93ac6 192.168.99.100 16384 @ mymaster 192.168.99.100 163797:X 15 Nov 12:41:41.922 * +slave slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 12:50:35.809 # +sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.517 * +reboot slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:00:04.584 # -sdown slave 192.168.99.100:16381 192.168.99.100 16381 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.005 # +sdown master mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.119 # +new-epoch 27:X 15 Nov 13:04:19.119 # +vote-for-leader 8acf7f07765409e85e932c3baea249537f24f94c 27:X 15 Nov 13:04:19.611 # +config-update-from sentinel 8acf7f07765409e85e932c3baea249537f24f94c 192.168.99.100 16385 @ mymaster 192.168.99.100 163797:X 15 Nov 13:04:19.611 # +switch-master mymaster 192.168.99.100 16379 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16380 192.168.99.100 16380 @ mymaster 192.168.99.100 163817:X 15 Nov 13:04:19.611 * +slave slave 192.168.99.100:16379 192.168.99.100 16379 @ mymaster 192.168.99.100 16381 启动master 发现成为了一个从服务器 1234567891011121314151617181920212223242526276:M 15 Nov 13:08:18.767 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.6:M 15 Nov 13:08:18.767 # Server started, Redis version 3.2.116:M 15 Nov 13:08:18.767 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.6:M 15 Nov 13:08:18.767 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.6:M 15 Nov 13:08:21.409 * DB loaded from append only file: 2.642 seconds6:M 15 Nov 13:08:21.409 * The server is now ready to accept connections on port 163796:S 15 Nov 13:08:28.852 * SLAVE OF 192.168.99.100:16381 enabled (user request from 'id=2 addr=192.168.99.100:59528 fd=8 name= age=10 idle=0 flags=x db=0 sub=0 psub=0 multi=3 qbuf=0 qbuf-free=32768 obl=36 oll=0 omem=0 events=r cmd=exec')6:S 15 Nov 13:08:28.853 # CONFIG REWRITE executed with success.6:S 15 Nov 13:08:29.457 * Connecting to MASTER 192.168.99.100:163816:S 15 Nov 13:08:29.457 * MASTER &lt;-&gt; SLAVE sync started6:S 15 Nov 13:08:29.457 * Non blocking connect for SYNC fired the event.6:S 15 Nov 13:08:29.458 * Master replied to PING, replication can continue...6:S 15 Nov 13:08:29.458 * Partial resynchronization not possible (no cached master)6:S 15 Nov 13:08:29.463 * Full resync from master: 8cf78a3d6fe25eb719901e129627cc5f7556c6d4:525026:S 15 Nov 13:08:30.107 * MASTER &lt;-&gt; SLAVE sync: receiving 10532180 bytes from master6:S 15 Nov 13:08:30.136 * MASTER &lt;-&gt; SLAVE sync: Flushing old data6:S 15 Nov 13:08:30.573 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory6:S 15 Nov 13:08:31.579 * MASTER &lt;-&gt; SLAVE sync: Finished with success6:S 15 Nov 13:08:31.581 * Background append only file rewriting started by pid 96:S 15 Nov 13:08:32.494 * AOF rewrite child asks to stop sending diffs.9:C 15 Nov 13:08:32.495 * Parent agreed to stop sending diffs. Finalizing AOF...9:C 15 Nov 13:08:32.495 * Concatenating 0.00 MB of AOF diff received from parent.9:C 15 Nov 13:08:32.495 * SYNC append only file rewrite performed9:C 15 Nov 13:08:32.496 * AOF rewrite: 2 MB of memory used by copy-on-write6:S 15 Nov 13:08:32.584 * Background AOF rewrite terminated with success6:S 15 Nov 13:08:32.584 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)6:S 15 Nov 13:08:32.584 * Background AOF rewrite finished successfully 测试通过。]]></content>
      <categories>
        <category>docker</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-stream-rabbitmq]]></title>
    <url>%2F2017%2F11%2F14%2Fspring-cloud-stream-rabbitmq%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 使用 rabbitmq 在使用spring cloud 构建微服务的时候用到的消息队列rabbitmq 综合了一下感觉用spring cloud stream 整合比较简单后期如果更换其它消息队列也比较简单 spring cloud stream 整合rabbitmq 概述 Spring Cloud Stream（以下简称SCS）是一个用于构建消息驱动微服务的框架。简单来说，通过SCS我们可以快速地在微服务之间传递异步消息，这对于一些刚起步时需求简单的消息应用是很方便的。 入门尽管很方便，但必要的准备工作还是要做的。SCS本身并不提供消息服务器，因此我们还是要安装像RabbitMQ或Kafka这样的消息服务器，本文会使用RabbitMQ来做讲解，具体如何安装Erlang和RabbitMQ这里不再赘述。安装好以后可以暂时不对RabbitMQ做配置。但要记得运行rabbitmq-plugins enable rabbitmq_management来激活管理平台以方便后续使用 。 生产者创建一个rabbitmq-producer微服务，默认端口8080 创建一个接口作为通道，举例： 123456789//生产者//创建一个rabbitmq-producer微服务，默认端口8080；//创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String OUTPUT = "test"; @Output(OUTPUT) MessageChannel output();&#125; @Output注解代表这是一个输出通道，而通道名就是我们定义的test，一个接口中可以定义多个输入和输出通道。实际上SCS本身提供了三个预定义接口通道，即Source.class单向输出通道，Sink.class单向输入通道，以及继承了它们两个的Processor.class，你可以在源码org.springframework.cloud.stream.messaging包中找到它们。但它们都只是简单示例，真正开发时我们肯定还是要自定义接口作为通道； 1234567891011121314151617//创建用于发送消息的接口（或直接在启动类中编写）：@RestController@EnableBinding(MyChannel.class)public class SendController &#123; @Autowired private MyChannel sender; @RequestMapping("/send") public String send()&#123; try &#123; sender.output().send(MessageBuilder.withPayload("Hello World").build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125; &#125;&#125; 需要注意的是，@EnableBinding注解是必须要加的（即使你只使用JUnit测试），但并不是必须添加在启动类上，其实你可以把它放在任何一个Spring能够扫描到的类。但为了方便查找，还是推荐放在启动类或者消息类上。 生产者至此告一段落，接下来我们看一下消费者。 消费者 12345678//创建一个consumer微服务，为防止与生产者冲突，端口号设为8081；//和生产者一样，创建一个接口作为通道，举例：@Componentpublic interface MyChannel &#123; String INPUT = "test"; @Input(INPUT) SubscribableChannel input();&#125; @Input注解代表这是一个输入通道，通道名需要与生产者对应才能接收消息，因此我们也定义为test； 创建用于接收消息的类（或直接在启动类中编写）： 12345678@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;String&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; @StreamListener注解用于监听通道，由于我们在生产者发送的是一个”Hello World”字符串，因此在这里我们用string来接收它，注意Message用的是org.springframework.messaging.Message；与生产者一样，在启动类上添加@EnableBinding(MyChannel.class)。 测试 首先启动消费者微服务，如果你激活了RabbitMQ管理平台，那么此时就可以在上面看到test通道的相关信息了，包括Exchange和Queue 访问消息提供者的接口 http://localhost:8082/send在监听方会有消息 修改配置 至此我们就完成了简单的消息发送与接收服务，是不是感觉很快就能起飞了呢？手动配置在开头我提到可以暂时不对RabbitMQ做配置，这是为了我们可以快速开发调试。但现实中我们不可能不去修改RabbitMQ的配置（哪怕只是改改密码，毕竟guest相当于裸奔），那么如何让SCS去匹配修改过的配置呢？单就YAML配置来说，有两种方式（使用@Configuration类做配置的朋友请自行对照）： 直接配置spring.rabbitmq，比如我使用另外一个用户连接 12345spring: rabbitmq: username: “用户名” password: ”密码“ virtual-host: /test 使用spring.cloud.stream.binders和spring.cloud.stream.bindings组合配置，同样是上面的情况： 123456789101112131415spring: cloud: stream: bindings: test: binder: rabbit binders: rabbit: type: rabbit environment: spring: rabbitmq: username: ”用户名“ password: ”密码“ virtual-host: /test 乍一看感觉好麻烦呀，而且environment下面的配置不就是上面spring.rabbitmq的配置吗？ 实际上这种写法是有它的好处的，首先我们注意到，binders里面可以配置不同环境的binder，而通过bindings我们可以把channel和binder绑定起来。 假设我这个微服务现在要连两个RabbitMQ，那么我们就可以这样配置： 1234567891011121314151617181920212223242526272829spring: cloud: stream: bindings: test1: binder: rabbit1 test2: binder: rabbit2 binders: rabbit1: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5672 username: password: virtual-host: /test1 rabbit2: type: rabbit environment: spring: rabbitmq: host: 10.1.27.14 port: 5673 username: password: virtual-host: /test2 注：spring.cloud.stream.bindings.里面有许多有用的配置，比如destination、group等等。” 进阶好了简单的消息发送与接收已经实现了 如何像消息队列传递一个对象呢？ 上一节中我们发送的消息是一个字符串，那如果我想发送POJO怎么办呢？是直接发送和接收就可以了吗？下面我们可以试验一下： 首先创建一个User POJO，然后修改生产者的send()方法： 12345678910111213@GetMapping("/send")public String send() &#123; try &#123; User user = new User(); user.setId("1"); user.setName("yhl"); sender.output().send(MessageBuilder.withPayload(user).build()); return "success"; &#125; catch (Exception e) &#123; e.printStackTrace(); return "fail"; &#125;&#125; 修改消费者sc-stream-consumer的receive()方法： 123456789@Componentpublic class Receiver &#123; @StreamListener(MyChannel.INPUT) public void receive(Message&lt;User&gt; message)&#123; System.out.println(message); System.out.println(message.getPayload()); &#125;&#125; 访问send 结果 接收方接到了一个user对象 如果你的User是分别在生产者和消费者中定义的，并且包路径不同，那么会报错反序列化失败。原因是SCS会默认将POJO转换成二进制发送，并且携带包路径等信息； 如果生产者和消费者使用的User是同一定义，或分别定义但包路径相同，那么就不会报错。 看起来略微有点不爽，那么有没有别的转换方式呢？ 有，而且官方还提供了很多： 下面我会举例用JSON字符串来传递POJO，其实只要在生产者中加上一条配置即可： 123456spring cloud: stream: bindings: test: content-type: application/json 此时消费者sc-stream-consumer接收的消息实体实际上是字符串了，我们可以用Message来测试一下： 此时收到的就是json数据了 既然接收的是JSON字符串了，那Spring怎么可能不提供自动反射呢XD，再次把消息实体换回User就行了。 负载均衡实际生产中，我们一般都会启动多个消费者实例来做负载均衡，既然是负载均衡，我们肯定希望一条消息在一组负载均衡实例中只被其中一个消费者接收。那么SCS是如何处理这种情况的呢？ 假设我们现在已经启动了生产者和消费者实例各一个，然后再修改消费者的端口为8082，再启动一个消费者实例。 随后发送消息测试，我们会发现两个消费者实例都接收到了消息： 这显然不是我们希望的，那么现在就来分析一下为什么会出现这种情况。 关键点在headers中的amqp_consumerQueue这个属性上，我们看到8081和8082的amqp_consumerQueue前面都是test.anonymous，但后面却是不一样的。这其实表示他们被分到了不同的匿名组（即group），而同一条消息会被test中的每个组都接收到。这个也很好理解，我们把group比喻成现实中的公司各部门，现在我要发一个通知，我会发给所有的部门，但同一部门中只要有一个人收到了，我就认为这个部门收到了通知。 所以只要把要负载均衡的实例分在同一个group下就好了，我们给消费者添加如下配置： 123456spring: cloud: stream: bindings: test: group: yhl 有一个test.yhl 队列这时调用发送者会发现两个消费者循环接受消息。]]></content>
      <categories>
        <category>消息队列</category>
        <category>rabbitMq</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloudStream]]></title>
    <url>%2F2017%2F11%2F14%2FSpringCloudStream%2F</url>
    <content type="text"><![CDATA[Spring cloud stream 翻译 （还没翻译完） 原文地址： https://docs.spring.io/spring-cloud-stream/docs/current-SNAPSHOT/reference/htmlsingle/#_introducing_spring_cloud_stream 1.简介Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的工业级spring应用，使用spring integration提供与消息代理之间的连接。本文提供不同代理中的中间件配置，介绍了持久化发布订阅机制，以及消费组以及分割的概念。将注解@EnableBinding加到应用上就可以实现与消息代理的连接，@StreamListener注解加到方法上，使之可以接收处理流的事件。 1234567891011121314151617@SpringBootApplicationpublic class StreamApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(StreamApplication.class, args); &#125;&#125;@EnableBinding(Sink.class)public class TimerSource &#123; ... @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125;123456789101112131415161718 @EnableBinding注解使用一个或者多个接口作为参数（本例子中，参数是单独的Sink接口）。接口声明了输入和／或输出通道。 Spring Cloud Stream提供了Source, Sink, 和 Processor三个接口；你也可以定义你自己的接口。下面是Sink接口的定义： 123456public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;123456 @Input注解定义了一个输入通道，应用通过该输入通道接收进入应用的消息；@Output注解定义了一个输出通道，发布的消息通过该通道离开应用。input和output注解可以使用通道名称作为参数；如果没有名称，会使用带注解的方法的名字作为参数（也就是说，如果没有定义单独的名字，这里的通道名就是方法名input）。Spring Cloud Stream会为你创建一个接口的实现(这里注意，一定要在application里面加上@EnableBinding注解，不然会出现自动注入失败，因为缺少这个注解的话stream就不会创建接口的实例)。你可以通过自动装配在应用中使用它，如下面测试用例所示： 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = StreamApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125;1234567891011121314 2.主要概念Spring Cloud Stream提供了很多抽象和基础组件来简化消息驱动型微服务应用。包含以下内容： Spring Cloud Stream的应用模型 绑定抽象 持久化发布／订阅支持 消费者组支持 分片支持（Partitioning Support） 可插拔绑定api 应用模型 2.1应用模型Spring Cloud Stream由一个中间件中立的核组成。应用通过Spring Cloud Stream插入的input和output通道与外界交流。通道通过指定中间件的Binder实现与外部代理连接。 2.1.1 胖JAR测试的话，Spring Cloud Stream可以在ide中运行一个单独的实例。在生产环境中，可以通过Maven 或者 Gradle提供的Spring Boot 工具创建可执行JAR（或者胖JAR）。 2.2绑定抽象Spring Cloud Stream提供对 Kafka, Rabbit MQ,Redis, 和 Gemfire的绑定实现。Spring Cloud Stream使用Spring Boot做配置，绑定抽象使得stream可以灵活的连接到中间件。比如，开发者可以在运行时动态的选择通道连接的目标（可以是kafka主题或者RabbitMQ 交换机）。该配置可以通过spring boot支持的任何配置形式实现。在sink的例子中，将属性spring.cloud.stream.bindings.input.destination设置为raw-sensor-data，程序会从命名为raw-sensor-data的kafka主题中读取数据，或者从一个绑定到raw-sensor-data的rabbitmq交换机的队列中读取数据（这里的input是通道名，raw-sensor-data则是exchange的名字，通过使用同一个名字，可以将输入输出通道进行绑定）。Spring Cloud Stream自动检测和使用在class path中找到的binder。可以在build的时候引入不同的binder来使用不同类型的中间件。更复杂的情况下，可以在应用中打包多个binder使之按需选择，甚至可以在运行时根据不同的通道选择不同的binder。 2.3持久化发布／订阅支持应用间通信遵照发布-订阅模型，消息通过共享主题进行广播。下图所示，显示了交互的Spring Cloud Stream 应用的典型布局。sensor传给http端点的数据传给名为raw-sensor-data的目标。发布订阅模型简化了生产者和消费者的复杂程度，并且新的应用可以在不对当前数据流造成影响的情况下加入到拓扑中。由于发布－订阅模型并非一个新的概念，Spring Cloud Stream将其作为应用模型中的可选项。通过使用原生中间件支持，Spring Cloud Stream也简化了不同平台之间使用发布－订阅模型的复杂程度。 2.4消费者组由于发布－订阅模型使得共享主题的应用之间连接更简便，创建给定应用的不同实例来进行弹性扩张的能力也同样重要。如果存在多个应用实例，那么同一应用的额不同实例便会成为相互竞争的消费者，其中应该只有一个实例处理给定消息。Spring Cloud Stream通过消费者组的概念给这种情况进行建模。每一个单独的消费者可以使用spring.cloud.stream.bindings.input.group属性来指定一个组名字。下图中展示的消费者们，这一属性被设置为spring.cloud.stream.bindings.input.group=hdfsWrite或者spring.cloud.stream.bindings.input.group=average。所有订阅给定目标的组都会收到发布消息的一个拷贝，但是每一个组内只有一个成员会收到该消息。默认情况下，如果没有指定组，Spring Cloud Stream 会将该应用指定给一个匿名的独立的单成员消费者组，后者与所有其他组都处于一个发布－订阅关系中。持久性与Spring Cloud Stream中的可选应用模型一样，消费者组订阅是持久的。也就是说，一个绑定的实现确保组的订阅者是持久的，一旦组中至少有一个成员创建了订阅，这个组就会收到消息，即使组中所有的应用都被停止了，组仍然会收到消息。注：自然情况下，匿名订阅者是非持久化的。对于某些绑定实现（如rabbitmq），可以创建非持久化（non－durable）组订阅。一般来说，将应用绑定到给定目标的时候，最好指定一个消费者组。扩展Spring Cloud Stream应用的时候，对于它的每一个输入绑定，都必须要指定一个消费者组。 这样可以防止应用实例收到重复的消息。（除非存在重复收到的需求，但实际上很少会有这样的需求）。 2.5分片支持（Partitioning Support）Spring Cloud Stream对给定应用的多个实例之间分隔数据予以支持。在分隔方案中，物理交流媒介（如：代理主题）被视为分隔成了多个片（partitions）。一个或者多个生产者应用实例给多个消费者应用实例发送消息并确保相同特征的数据被同一消费者实例处理。Spring Cloud Stream对分割的进程实例实现进行了抽象。因此分片可以用于自带分隔的代理（如kafka）或者不带分隔的代理（如rabbitmq）。分割在有状态处理中是一个很重要的概念，在性能和一致性上，分割都是重要的概念。例如，在时间窗平均计算的例子中，给定传感器测量结果应该都由同一应用实例进行计算。注：如果要设置分割处理方案，需要配置数据处理和数据消费端点。 3.编程模型这一部分描述Spring Cloud Stream的编程模型。Spring Cloud Stream提供很多预先定一的注解来声明约束输入和输出通道以及如何监听这些通道。 3.1声明和绑定通道3.1.1通过@EnableBinding触发绑定将@EnableBinding应用到spring应用的一个配置类中，可以将spring应用变成Spring Cloud Stream应用。@EnableBinding注解本身就包含@Configuration注解，并且会触发Spring Cloud Stream 基本配置。@EnableBinding注解可以接收一个或多个接口类作为对象，后者包含代表了可绑定构件（一般来说是消息通道）的方法。注：在Spring Cloud Stream1.0中，仅有的可绑定构件是Spring 消息 MessageChannel以及它的扩展SubscribableChannel 和 PollableChannel. 未来版本会使用相同的机制扩展对其他类型构件的支持。在本文档中，会继续饮用通道。3.1.2@Input 和 @Output一个Spring Cloud Stream应用可以有任意数目的input和output通道，后者通过@Input and @Output方法在进口中定义。 1234567891011public interface Barista &#123; @Input SubscribableChannel orders(); @Output MessageChannel hotDrinks(); @Output MessageChannel coldDrinks();&#125;1234567891011 将该接口作为@EnableBinding的参数，会相应的触发三个名为orders, hotDrinks, 和 coldDrinks的绑定好的通道。 12345@EnableBinding(Barista.class)public class CafeConfiguration &#123; ...&#125;12345 定制通道名字使用@Input 和 @Output注解，可以自己指定通道的名字，如下所示： 12345public interface Barista &#123; ... @Input("inboundOrders") SubscribableChannel orders();&#125;12345 这个例子中，创建的绑定队列会被命名为inboundOrders。Source, Sink, and Processor在大多数用例中，包含一个输入通道或者一个输出通道或者二者都包含，为了更简单的定位，Spring Cloud Stream创造性的提供了三个预定义的接口。Source用于有单个输出（outbound）通道的应用。 12345678public interface Source &#123; String OUTPUT = "output"; @Output(Source.OUTPUT) MessageChannel output();&#125;12345678 Sink用于有单个输入（inbound）通道的应用。 12345678public interface Sink &#123; String INPUT = "input"; @Input(Sink.INPUT) SubscribableChannel input();&#125;12345678 Processor用于单个应用同时包含输入和输出通道的情况。 12public interface Processor extends Source, Sink &#123;&#125;12 Spring Cloud Stream对这三个接口没有提供任何特殊处理。他们只是用于创造性的提供。 3.1.3访问绑定通道 1.注入已绑定接口对于每一个已绑定的接口， Spring Cloud Stream会生成一个bean实现该接口。唤起这些由@Input或者 @Output注解的方法生成的bean，其中一个bean会返回相应的通道。下面例子中，当hello方法被唤起的时候，bean会在output通道上发送一个消息。在注入的Source bean上提供唤醒output()来检索到目标通道。 1234567891011121314@Componentpublic class SendingBean &#123; private Source source; @Autowired public SendingBean(Source source) &#123; this.source = source; &#125; public void sayHello(String name) &#123; source.output().send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 2.直接注入到通道绑定的通道也可以直接注入。 1234567891011121314@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; output.send(MessageBuilder.withPayload(body).build()); &#125;&#125;1234567891011121314 如果通道名称是在声明的注解上指定的，则不能使用方法名称，而要使用通道名称。举例如下： 12345public interface CustomSource &#123; ... @Output("customOutput") MessageChannel output();&#125;12345 通道会按照下面方式注入： 123456789101112131415@Componentpublic class SendingBean &#123; @Autowired private MessageChannel output; @Autowired @Qualifier("customOutput") public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; customOutput.send(MessageBuilder.withPayload(body).build()); &#125;&#125;123456789101112131415 3.1.4生产和消费消息 可以使用Spring Integration 的注解或者Spring Cloud Stream的 @StreamListener 注解来实现一个Spring Cloud Stream应用。@StreamListener注解模仿其他spring消息注解（例如@MessageMapping, @JmsListener, @RabbitListener等），但是它增加了内容类型管理和类型强制特性。1.原生Spring Integration支持因为 Spring Cloud Stream是基于Spring Integration构建，Stream完全继承了Integration的基础设施以及构件本身。例如，可以将Source的output通道连接到一个MessageSource： 123456789101112@EnableBinding(Source.class)public class TimerSource &#123; @Value("$&#123;format&#125;") private String format; @Bean @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay = "$&#123;fixedDelay&#125;", maxMessagesPerPoll = "1")) public MessageSource&lt;String&gt; timerMessageSource() &#123; return () -&gt; new GenericMessage&lt;&gt;(new SimpleDateFormat(format).format(new Date())); &#125;&#125;123456789101112 或者可以在transformer中使用处理器的通道。 1234567@EnableBinding(Processor.class)public class TransformProcessor &#123; @Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT) public Object transform(String message) &#123; return message.toUpper(); &#125;&#125;1234567 2.使用 @StreamListener进行自动内容类型处理作为原生Spring Integration的补充，Spring Cloud Stream提供了自己的@StreamListener注解，该注解模仿spring的其它消息注解（如@MessageMapping, @JmsListener, @RabbitListener等）。@StreamListener注解提供了一种更简单的模型来处理输入消息，尤其是处理包含内容类型管理和类型强制的用例的情况。Spring Cloud Stream提供了一个扩展的MessageConverter机制，该机制提供绑定通道实现数据处理，本例子中，数据会分发给带@StreamListener注解的方法。下面例子展示了处理外部Vote事件的应用： 1234567891011@EnableBinding(Sink.class)public class VoteHandler &#123; @Autowired VotingService votingService; @StreamListener(Sink.INPUT) public void handle(Vote vote) &#123; votingService.record(vote); &#125;&#125;1234567891011 在输入消息内容头为application/json的情况下，@StreamListener和Spring Integration的@ServiceActivator之间会体现出差异。使用@StreamListener的情况下，MessageConverter机制会使用contentType头将string负载解析为Vote对象（也就是如果传输的是对象，应该选用@StreamListener注解）。在其它Spring Messaging方法中，消息机制可以使用@Payload, @Headers 和 @Header这些注解。 注：对于那些有返回数据的方法，必须使用@SendTo注解来指定返回数据的输出绑定目标。 123456789101112@EnableBinding(Processor.class)public class TransformProcessor &#123; @Autowired VotingService votingService; @StreamListener(Processor.INPUT) @SendTo(Processor.OUTPUT) public VoteResult handle(Vote vote) &#123; return votingService.record(vote); &#125;&#125;123456789101112 注：在RabbitMQ中，内容类型头可以由外部应用设定。 3.1.5聚合Aggregation Spring Cloud Stream可以支持多种应用的聚合，可以实现多种应用输入输出通道直接连接，而无需额外代价。在1.0版本中，只有以下类型应用支持聚合： sources：带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Source sinks：带有名为input的单一输入通道的应用。典型情况下，该应用带有包含一个以下类型的绑定org.springframework.cloud.stream.messaging.Sink processors：带有名为input的单一输入通道和带有名为output的单一输出通道的应用。典型情况下，该应用带有包含一个以下类型的绑定type org.springframework.cloud.stream.messaging.Processor. 可以通过创建一系列相互连接的应用将它们聚合到一起，其中，序列中一个元素的输出通道与下一个元素的输入通道连接在一起。序列可以由一个cource或者一个processor开始，可以包含任意数目的processors，并由processors或者sink结束。取决于开始和结束元素的特性，序列可以有一个或者多个可绑定的通道，如下： 如果序列由source开始，sink结束，应用之间直接通信并且不会绑定通道 如果序列由processor开始，它的输入通道会变成聚合的input通道并进行相应的绑定 如果序列由processor结束，它的输出通道会变成聚合的output通道并进行相应的绑定 使用AggregateApplicationBuilder功能类来实现聚合，如下例子所示。考虑一个包含source,processor 和 sink的工程，它们可以示包含在工程中，或者包含在工程的依赖中。 1234567891011@SpringBootApplication@EnableBinding(Sink.class)public class SinkApplication &#123; private static Logger logger = LoggerFactory.getLogger(SinkModuleDefinition.class); @ServiceActivator(inputChannel=Sink.INPUT) public void loggerSink(Object payload) &#123; logger.info("Received: " + payload); &#125;&#125;1234567891011 123456789@SpringBootApplication@EnableBinding(Processor.class)public class ProcessorApplication &#123; @Transformer public String loggerSink(String payload) &#123; return payload.toUpperCase(); &#125;&#125;123456789 12345678910@SpringBootApplication@EnableBinding(Source.class)public class SourceApplication &#123; @Bean @InboundChannelAdapter(value = Source.OUTPUT) public String timerMessageSource() &#123; return new SimpleDateFormat().format(new Date()); &#125;&#125;12345678910 每一个配置可用于运行一个独立的组件，在这个例子中，它们可以这样实现聚合： 12345678910@SpringBootApplicationpublic class SampleAggregateApplication &#123; public static void main(String[] args) &#123; new AggregateApplicationBuilder() .from(SourceApplication.class).args("--fixedDelay=5000") .via(ProcessorApplication.class) .to(SinkApplication.class).args("--debug=true").run(args); &#125;&#125;12345678910 序列的开始组件被提供作为from()方法的参数，序列的结束组件被提供作为to()方法的参数，中间处理器组件则作为via()方法的参数。同一类型的多个processors可以链在一起（例如，可以使用不同配置的管道传输方式）。对于每一个组件，编译器可以为Spring Boot 提供运行时参数。 3.1.6RxJava支持 4.绑定器（Binders）Spring Cloud Stream提供绑定抽象用于与外部中间件中的物理目标进行连接。本章主要介绍Binder SPI背后的主要概念，主要组件以及实现细节。 4.1生产者和消费者任何往通道中发布消息的组件都可称作生产者。通道可以通过代理的Binder实现与外部消息代理进行绑定。调用bindProducer()方法，第一个参数是代理名称，第二个参数是生产者向其中发送消息的本地通道目标名称，第三个参数包含通道创建的适配器的属性信息（比如：分片key表达式）。任何从通道中接收消息的组件都可称作消费者。与生产者一起，消费者通道可以与外部消息代理进行绑定。调用bindConsumer()方法，第一个参数是目标名称，第二个参数提供了消费者逻辑组的名称。]]></content>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈 Spring Cloud]]></title>
    <url>%2F2017%2F11%2F13%2F%E6%B5%85%E8%B0%88-Spring-Cloud%2F</url>
    <content type="text"><![CDATA[背景2008年以后，国内互联网行业飞速发展，我们对软件系统的需求已经不再是过去”能用就行”这种很low的档次了，像抢红包、双十一这样的活动不断逼迫我们去突破软件系统的性能上限，传统的IT企业”能用就行”的开发思想已经不能满足互联网高并发、大流量的性能要求。系统架构走向分布式已经是服务器开发领域解决该问题唯一的出路，然而分布式系统由于天生的复杂度，并不像开发单体应用一样把框架一堆就能搞定，因此各大互联网公司都在投入技术力量研发自己的基础设施。这里面比较有名的如阿里的开源项目dubbo, Netflix开发的一系列服务框架。在这种“百花齐放”、重复造轮子的状况下，必然要出现一种统一的标准来简化分布式系统的开发，Spring Cloud应运而生。 Spring Cloud是什么SpringCloud架构Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 Spring Cloud正是对Netflix的多个开源组件进一步的封装而成，同时又实现了和云端平台，和Spring Boot开发框架很好的集成。 Spring Cloud是一个相对比较新的微服务框架，2016年才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。 Spring Cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用、同时能够快速和云平台资源进行对接。 Spring Cloud组成 Spring Cloud的子项目，大致可分成两类，一类是对现有成熟框架”Spring Boot化”的封装和抽象，也是数量最多的项目；第二类是开发了一部分分布式系统的基础设施的实现，如Spring Cloud Stream扮演的就是kafka, ActiveMQ这样的角色。对于我们想快速实践微服务的开发者来说，第一类子项目就已经足够使用，如：Spring Cloud Netflix，是对Netflix开发的一套分布式服务框架的封装，包括服务的发现和注册，负载均衡、断路器、REST客户端、请求路由等。该项目是Spring Cloud的子项目之一，主要内容是对Netflix公司一系列开源产品的包装，它为Spring Boot应用提供了自配置的Netflix OSS整合。 通过一些简单的注解，开发者就可以快速的在应用中配置一下常用模块并构建庞大的分布式系统。它主要提供的模块包括：服务发现（Eureka），断路器（Hystrix），智能路由（Zuul），客户端负载均衡（Ribbon）等。 Spring Cloud Eureka 服务发现服务中心，云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。这个可是SpringCloud最牛鼻的小弟，服务中心，任何小弟需要其它小弟支持什么都需要从这里来拿，同样的你有什么独门武功的都赶紧过报道，方便以后其它小弟来调用；它的好处是你不需要直接找各种什么小弟支持，只需要到服务中心来领取，也不需要知道提供支持的其它小弟在哪里，还是几个小弟来支持的，反正拿来用就行，服务中心来保证稳定性和质量。 Spring Cloud Eureka提供在分布式环境下的服务发现，服务注册的功能。 一个RESTful服务，用来定位运行在AWS地区（Region）中的中间层服务。由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 Spring Cloud Ribbon 客户端负载均衡Ribbon，主要提供客户侧的软件负载均衡算法。 Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略： 简单轮询负载均衡 加权响应时间负载均衡 区域感知轮询负载均衡 随机负载均衡 Ribbon中还包括以下功能： 易于与服务发现组件（比如Netflix的Eureka）集成 使用Archaius完成运行时配置 使用JMX暴露运维指标，使用Servo发布 多种可插拔的序列化选择 异步和批处理操作（即将推出） 自动SLA框架（即将推出） 系统管理/指标控制台（即将推出） Spring Cloud Config俗称的配置中心，配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。就是以后大家武器、枪火什么的东西都集中放到一起，别随便自己带，方便以后统一管理、升级装备。 将配置信息中央化保存, 配置Spring Cloud Bus可以实现动态修改配置文件。这个还是静态的，得配合Spring Cloud Bus实现动态的配置更新。 Spring Cloud Config就是我们通常意义上的配置中心。Spring Cloud Config-把应用原本放在本地文件的配置抽取出来放在中心服务器，本质是配置信息从本地迁移到云端。从而能够提供更好的管理、发布能力。 Spring Cloud Config分服务端和客户端，服务端负责将git（svn）中存储的配置文件发布成REST接口，客户端可以从服务端REST接口获取配置。但客户端并不能主动感知到配置的变化，从而主动去获取新的配置，这需要每个客户端通过POST方法触发各自的/refresh。 Spring cloud Hystrix 熔断器熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。比如突然某个小弟生病了，但是你还需要它的支持，然后调用之后它半天没有响应，你却不知道，一直在等等这个响应；有可能别的小弟也正在调用你的武功绝技，那么当请求多之后，就会发生严重的阻塞影响老大的整体计划。这个时候Hystrix就派上用场了，当Hystrix发现某个小弟不在状态不稳定立马马上让它下线，让其它小弟来顶上来，或者给你说不用等了这个小弟今天肯定不行，该干嘛赶紧干嘛去别在这排队了。 断路器(Cricuit Breaker)是一种能够在远程服务不可用时自动熔断(打开开关)，并在远程服务恢复时自动恢复(闭合开关)的设施，Spring Cloud通过Netflix的Hystrix组件提供断路器、资源隔离与自我修复功能。断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正，应用程序可以尝试调用操作。 断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。 Spring Cloud Zuul 服务网关，智能路由Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。当其它门派来找大哥办事的时候一定要先经过zuul,看下有没有带刀子什么的给拦截回去，或者是需要找那个小弟的直接给带过去。 类似Nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。 Spring Netflix Archaius配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。可以实现动态获取配置， 原理是每隔60s（默认，可配置）从配置源读取一次内容，这样修改了配置文件后不需要重启服务就可以使修改后的内容生效，前提使用archaius的API来读取。 Spring Cloud Bus事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。相当于水浒传中日行八百里的神行太保戴宗，确保各个小弟之间消息保持畅通。分布式消息队列，是对Kafka, MQ的封装；事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。 Spring cloud bus被国内很多都翻译为消息总线，也挺形象的。大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实本质是利用了MQ的广播机制在分布式的系统中传播消息，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。 Spring Cloud Bus做配置更新的步骤: 提交代码触发post给客户端A发送bus/refresh客户端A接收到请求从Server端更新配置并且发送给Spring Cloud BusSpring Cloud bus接到消息并通知给其它客户端其它客户端接收到通知，请求Server端获取最新配置全部客户端均获取到最新的配置 Spring Cloud Security对Spring Security的封装，并能配合Netflix使用，安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 基于spring security的安全工具包，为你的应用程序添加安全控制。这个小弟很牛鼻专门负责整个帮派的安全问题，设置不同的门派访问特定的资源，不能把秘籍葵花宝典泄漏了。 Spring Cloud Zookeeper对Zookeeper的封装，使之能配置其它Spring Cloud的子项目使用；操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 操作Zookeeper的工具包，用于使用zookeeper方式的服务发现和配置管理，抱了Zookeeper的大腿。 Spring Cloud Stream数据流；数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud Stream是创建消息驱动微服务应用的框架。Spring Cloud Stream是基于spring boot创建，用来建立单独的／工业级spring应用，使用spring integration提供与消息代理之间的连接。数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 一个业务会牵扯到多个任务，任务之间是通过事件触发的，这就是Spring Cloud stream要干的事了。 Spring Cloud Sleuth服务跟踪；日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。 Spring Cloud Feign 使用HTTP请求远程服务在Spring Cloud Netflix栈中，各个微服务都是以HTTP接口的形式暴露自身服务的，因此在调用远程服务时就必须使用HTTP客户端。我们可以使用JDK原生的URLConnection、Apache的Http Client、Netty的异步HTTP Client, Spring的RestTemplate。但是，用起来最方便、最优雅的还是要属Feign了。 Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 我们可以做到使用HTTP请求远程服务时能与调用本地方法一样的编码体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。 通过Feign， 我们能把HTTP远程调用对开发者完全透明，得到与调用本地方法一致的编码体验。这一点与阿里Dubbo中暴露远程服务的方式类似，区别在于Dubbo是基于私有二进制协议，而Feign本质上还是个HTTP客户端。如果是在用Spring Cloud Netflix搭建微服务，那么Feign无疑是最佳选择。 Spring Cloud for Cloud FoundryCloud Foundry是VMware推出的业界第一个开源PaaS云平台，它支持多种框架、语言、运行时环境、云平台及应用服务，使开发人员能够在几秒钟内进行应用程序的部署和扩展，无需担心任何基础架构的问题 其实就是与CloudFoundry进行集成的一套解决方案，抱了Cloud Foundry的大腿。 Spring Cloud ClusterSpring Cloud Cluster将取代Spring Integration。提供在分布式系统中的集群所需要的基础功能支持，如：选举、集群的状态一致性、全局锁、tokens等常见状态模式的抽象和实现。 如果把不同的帮派组织成统一的整体，Spring Cloud Cluster已经帮你提供了很多方便组织成统一的工具。 Spring Cloud ConsulConsul 是一个支持多数据中心分布式高可用的服务发现和配置共享的服务软件,由 HashiCorp 公司用 Go 语言开发, 基于 Mozilla Public License 2.0 的协议进行开源. Consul 支持健康检查,并允许 HTTP 和 DNS 协议调用 API 存储键值对. Spring Cloud Consul 封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Data FlowData flow 是一个用于开发和执行大范围数据处理其模式包括ETL，批量运算和持续运算的统一编程模型和托管服务。 对于在现代运行环境中可组合的微服务程序来说，Spring Cloud data flow是一个原生云可编配的服务。使用Spring Cloud data flow，开发者可以为像数据抽取，实时分析，和数据导入/导出这种常见用例创建和编配数据通道 （data pipelines）。 Spring Cloud data flow 是基于原生云对 spring XD的重新设计，该项目目标是简化大数据应用的开发。Spring XD 的流处理和批处理模块的重构分别是基于 spring boot的stream 和 task/batch 的微服务程序。这些程序现在都是自动部署单元而且他们原生的支持像 Cloud Foundry、Apache YARN、Apache Mesos和Kubernetes 等现代运行环境。 Spring Cloud data flow 为基于微服务的分布式流处理和批处理数据通道提供了一系列模型和最佳实践。 Spring Cloud TaskSpring Cloud Task 主要解决短命微服务的任务管理，任务调度的工作，比如说某些定时任务晚上就跑一次，或者某项数据分析临时就跑几次。 Spring Cloud ConnectorsSpring Cloud Connectors 简化了连接到服务的过程和从云平台获取操作的过程，有很强的扩展性，可以利用Spring Cloud Connectors来构建你自己的云平台。 便于云端应用程序在各种PaaS平台连接到后端，如：数据库和消息代理服务。 Spring Cloud StartersSpring Boot式的启动项目，为Spring Cloud提供开箱即用的依赖管理。 Spring Cloud CLI基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 Netflix TurbineTurbine是聚合服务器发送事件流数据的一个工具，用来监控集群下hystrix的metrics情况。 和Spring Boot 是什么关系Spring boot 是 Spring 的一套快速配置脚手架，可以基于spring boot 快速开发单个微服务，Spring Cloud是一个基于Spring Boot实现的云应用开发工具；Spring boot专注于快速、方便集成的单个个体，Spring Cloud是关注全局的服务治理框架；spring boot使用了默认大于配置的理念，很多集成方案已经帮你选择好了，能不配置就不配置，Spring Cloud很大的一部分是基于Spring boot来实现,可以不基于Spring boot吗？不可以。 Spring boot可以离开Spring Cloud独立使用开发项目，但是Spring Cloud离不开Spring boot，属于依赖的关系。 Spring -&gt; Spring Boot &gt; Spring Cloud 这样的关系。 Spring Cloud的优势微服务的框架那么多比如：dubbo、Kubernetes，为什么就要使用Spring Cloud的呢？ 产出于Spring大家族，Spring在企业级开发框架中无人能敌，来头很大，可以保证后续的更新、完善。比如dubbo现在就差不多死了有Spring Boot 这个独立干将可以省很多事，大大小小的活spring boot都搞的挺不错。 作为一个微服务治理的大家伙，考虑的很全面，几乎服务治理的方方面面都考虑到了，方便开发开箱即用。Spring Cloud 活跃度很高，教程很丰富，遇到问题很容易找到解决方案轻轻松松几行代码就完成了熔断、均衡负责、服务中心的各种平台功能Spring Cloud 也有一个缺点，只能使用Java开发,不适合小型独立的项目。 个人总结上面的一些组件介绍是综合了网上给出的介绍和自己的一些理解来写的,在实际工作中也用到了大多的组件。后续会结合自己的使用情况来总结每个组件的详细内容以及具体的使用情况。 ##]]></content>
      <categories>
        <category>spring cloud</category>
      </categories>
      <tags>
        <tag>spring cloud</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
</search>
